@article{ahlquistModelbasedClusteringTypologies2012,
  title = {Model-Based {{Clustering}} and {{Typologies}} in the {{Social
           Sciences}}},
  author = {Ahlquist, John S. and Breunig, Christian},
  year = {2012/ed},
  journal = {Political Analysis},
  volume = {20},
  number = {1},
  pages = {92--112},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpr039},
  urldate = {2023-03-27},
  abstract = {Social scientists spend considerable energy constructing
              typologies and discussing their roles in measurement. Less
              discussed is the role of typologies in evaluating and revising
              theoretical arguments. We argue that unsupervised machine learning
              tools can be profitably applied to the development and testing of
              theory-based typologies. We review recent advances in mixture
              models as applied to cluster analysis and argue that these tools
              are particularly important in the social sciences where it is
              common to claim that high-dimensional objects group together in
              meaningful clusters. Model-based clustering (MBC) grounds analysis
              in probability theory, permitting the evaluation of uncertainty and
              application of information-based model selection tools. We show
              that the MBC approach forces analysts to consider dimensionality
              problems that more traditional clustering tools obscure. We apply
              MBC to the ``varieties of capitalism,'' a typology receiving
              significant attention in political science and economic sociology.
              We find weak and conflicting evidence for the theory's expected
              grouping. We therefore caution against the current practice of
              including typology-derived dummy variables in regression and
              case-comparison research designs.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/DMLRJS3M/Ahlquist and Breunig - 2012 -
          Model-based Clustering and Typologies in the Socia.pdf},
}

@article{ahlquistModelbasedClusteringTypologies2012a,
  title = {Model-Based {{Clustering}} and {{Typologies}} in the {{Social
           Sciences}}},
  author = {Ahlquist, John S. and Breunig, Christian},
  year = {2012},
  journal = {Political Analysis},
  volume = {20},
  number = {1},
  pages = {92--112},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpr039},
  urldate = {2023-03-29},
  abstract = {Social scientists spend considerable energy constructing
              typologies and discussing their roles in measurement. Less
              discussed is the role of typologies in evaluating and revising
              theoretical arguments. We argue that unsupervised machine learning
              tools can be profitably applied to the development and testing of
              theory-based typologies. We review recent advances in mixture
              models as applied to cluster analysis and argue that these tools
              are particularly important in the social sciences where it is
              common to claim that high-dimensional objects group together in
              meaningful clusters. Model-based clustering (MBC) grounds analysis
              in probability theory, permitting the evaluation of uncertainty and
              application of information-based model selection tools. We show
              that the MBC approach forces analysts to consider dimensionality
              problems that more traditional clustering tools obscure. We apply
              MBC to the ``varieties of capitalism,'' a typology receiving
              significant attention in political science and economic sociology.
              We find weak and conflicting evidence for the theory's expected
              grouping. We therefore caution against the current practice of
              including typology-derived dummy variables in regression and
              case-comparison research designs.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/R7L7IEFP/Ahlquist and Breunig - 2012 -
          Model-based Clustering and Typologies in the Socia.pdf},
}

@book{baileyTypologiesTaxonomiesIntroduction1994,
  title = {Typologies and {{Taxonomies}}: {{An Introduction}} to {{
           Classification Techniques}}},
  shorttitle = {Typologies and {{Taxonomies}}},
  author = {Bailey, Kenneth D.},
  year = {1994},
  month = jun,
  publisher = {{SAGE}},
  abstract = {How do we group different subjects on a variety of variables?
              Should we use a classification procedure in which only the concepts
              are classified (typology), one in which only empirical entities are
              classified (taxonomy), or some combination of both? In this clearly
              written book, Bailey addresses these questions and shows how
              classification methods can be used to improve research. Beginning
              with an exploration of the advantages and disadvantages of
              classification procedures including those typologies that can be
              constructed without the use of a computer, the book covers such
              topics as clustering procedures (including agglomerative and
              divisive methods), the relationship among various classification
              techniques (including the relationship of monothetic, qualitative
              typologies to polythetic, quantitative taxonomies), a comparison of
              clustering methods and how these methods compare with related
              statistical techniques such as factor analysis, multidimensional
              scaling and systems analysis, and lists classification resources.
              This volume also discusses software packages for use in clustering
              techniques.},
  googlebooks = {1TaYulGjhLYC},
  isbn = {978-0-8039-5259-1},
  langid = {english},
  keywords = {Reference / Research,Social Science / Methodology,Social Science /
              Research},
}

@article{barberaAutomatedTextClassification2021,
  title = {Automated {{Text Classification}} of {{News Articles}}: {{A Practical
           Guide}}},
  shorttitle = {Automated {{Text Classification}} of {{News Articles}}},
  author = {Barber{\'a}, Pablo and Boydstun, Amber E. and Linn, Suzanna and
            McMahon, Ryan and Nagler, Jonathan},
  year = {2021},
  month = jan,
  journal = {Political Analysis},
  volume = {29},
  number = {1},
  pages = {19--42},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2020.8},
  urldate = {2023-03-17},
  abstract = {Automated text analysis methods have made possible the
              classification of large corpora of text by measures such as topic
              and tone. Here, we provide a guide to help researchers navigate the
              consequential decisions they need to make before any measure can be
              produced from the text. We consider, both theoretically and
              empirically, the effects of such choices using as a running example
              efforts to measure the tone of New York Times coverage of the
              economy. We show that two reasonable approaches to corpus selection
              yield radically different corpora and we advocate for the use of
              keyword searches rather than predefined subject categories provided
              by news archives. We demonstrate the benefits of coding using
              article segments instead of sentences as units of analysis. We show
              that, given a fixed number of codings, it is better to increase the
              number of unique documents coded rather than the number of coders
              for each document. Finally, we find that supervised machine
              learning algorithms outperform dictionaries on a number of
              criteria. Overall, we intend this guide to serve as a reminder to
              analysts that thoughtfulness and human validation are key to
              text-as-data methods, particularly in an age when it is all too
              easy to computationally classify texts without attending to the
              methodological choices therein.},
  langid = {english},
  keywords = {automated content analysis,content analysis,statistical analysis
              of texts},
  file = {/Users/matpi832/Zotero/storage/ML6P4HRN/Barber√° et al. - 2021 -
          Automated Text Classification of News Articles A .pdf},
}

@article{barberaWhoLeadsWho2019,
  title = {Who {{Leads}}? {{Who Follows}}? {{Measuring Issue Attention}} and {{
           Agenda Setting}} by {{Legislators}} and the {{Mass Public Using Social
           Media Data}}},
  shorttitle = {Who {{Leads}}?},
  author = {Barber{\'a}, Pablo and Casas, Andreu and Nagler, Jonathan and Egan,
            Patrick J. and Bonneau, Richard and Jost, John T. and Tucker, Joshua
            A.},
  year = {2019},
  month = nov,
  journal = {American Political Science Review},
  volume = {113},
  number = {4},
  pages = {883--901},
  publisher = {{Cambridge University Press}},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055419000352},
  urldate = {2023-03-17},
  abstract = {Are legislators responsive to the priorities of the public?
              Research demonstrates a strong correspondence between the issues
              about which the public cares and the issues addressed by
              politicians, but conclusive evidence about who leads whom in
              setting the political agenda has yet to be uncovered. We answer
              this question with fine-grained temporal analyses of Twitter
              messages by legislators and the public during the 113th US
              Congress. After employing an unsupervised method that classifies
              tweets sent by legislators and citizens into topics, we use vector
              autoregression models to explore whose priorities more strongly
              predict the relationship between citizens and politicians. We find
              that legislators are more likely to follow, than to lead,
              discussion of public issues, results that hold even after
              controlling for the agenda-setting effects of the media. We also
              find, however, that legislators are more likely to be responsive to
              their supporters than to the general public.},
  langid = {english},
}

@incollection{basuActiveSemiSupervisionPairwise2004,
  title = {Active {{Semi-Supervision}} for {{Pairwise Constrained Clustering}}},
  booktitle = {Proceedings of the 2004 {{SIAM International Conference}} on {{
               Data Mining}} ({{SDM}})},
  author = {Basu, Sugato and Banerjee, Arindam and Mooney, Raymond J.},
  year = {2004},
  month = apr,
  series = {Proceedings},
  pages = {333--344},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972740.31},
  urldate = {2023-04-24},
  abstract = {Semi-supervised clustering uses a small amount of supervised data
              to aid unsupervised learning. One typical approach specifies a
              limited number of must-link and cannot-link constraints between
              pairs of examples. This paper presents a pairwise constrained
              clustering framework and a new method for actively selecting
              informative pairwise constraints to get improved clustering
              performance. The clustering and active learning methods are both
              easily scalable to large datasets, and can handle very high
              dimensional data. Experimental and theoretical results confirm that
              this active querying of pairwise constraints significantly improves
              the accuracy of clustering when given a relatively small amount of
              supervision.},
  isbn = {978-0-89871-568-2},
}

@inproceedings{basuActiveSemiSupervisionPairwise2004a,
  title = {Active {{Semi-Supervision}} for {{Pairwise Constrained Clustering}}},
  booktitle = {Proceedings of the 2004 {{SIAM International Conference}} on {{
               Data Mining}}},
  author = {Basu, Sugato and Banerjee, Arindam and Mooney, Raymond J.},
  year = {2004},
  month = apr,
  pages = {333--344},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972740.31},
  urldate = {2023-04-24},
  abstract = {Semi-supervised clustering uses a small amount of supervised data
              to aid unsupervised learning. One typical approach specifies a
              limited number of must-link and cannotlink constraints between
              pairs of examples. This paper presents a pairwise constrained
              clustering framework and a new method for actively selecting
              informative pairwise constraints to get improved clustering
              performance. The clustering and active learning methods are both
              easily scalable to large datasets, and can handle very high
              dimensional data. Experimental and theoretical results confirm that
              this active querying of pairwise constraints significantly improves
              the accuracy of clustering when given a relatively small amount of
              supervision.},
  isbn = {978-0-89871-568-2 978-1-61197-274-0},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/A78DVNCV/Basu et al. - 2004 - Active
          Semi-Supervision for Pairwise Constrained C.pdf},
}

@inproceedings{basuProbabilisticFrameworkSemisupervised2004,
  title = {A Probabilistic Framework for Semi-Supervised Clustering},
  booktitle = {Proceedings of the Tenth {{ACM SIGKDD}} International Conference
               on {{Knowledge}} Discovery and Data Mining},
  author = {Basu, Sugato and Bilenko, Mikhail and Mooney, Raymond J.},
  year = {2004},
  month = aug,
  series = {{{KDD}} '04},
  pages = {59--68},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1014052.1014062},
  urldate = {2023-04-24},
  abstract = {Unsupervised clustering can be significantly improved using
              supervision in the form of pairwise constraints, i.e., pairs of
              instances labeled as belonging to same or different clusters. In
              recent years, a number of algorithms have been proposed for
              enhancing clustering quality by employing such supervision. Such
              methods use the constraints to either modify the objective function
              , or to learn the distance measure. We propose a probabilistic
              model for semi-supervised clustering based on Hidden Markov Random
              Fields (HMRFs) that provides a principled framework for
              incorporating supervision into prototype-based clustering. The
              model generalizes a previous approach that combines constraints and
              Euclidean distance learning, and allows the use of a broad range of
              clustering distortion measures, including Bregman divergences (e.g.
              , Euclidean distance and I-divergence) and directional similarity
              measures (e.g., cosine similarity). We present an algorithm that
              performs partitional semi-supervised clustering of data by
              minimizing an objective function derived from the posterior energy
              of the HMRF model. Experimental results on several text data sets
              demonstrate the advantages of the proposed framework.},
  isbn = {978-1-58113-888-7},
  keywords = {distance metric learning,hidden Markov random fields,
              semi-supervised clustering},
  file = {/Users/matpi832/Zotero/storage/GRWXX87G/Basu et al. - 2004 - A
          probabilistic framework for semi-supervised clus.pdf},
}

@article{bilsOverreactingPosturingHow2023,
  title = {Overreacting and {{Posturing}}: {{How Accountability}} and {{Ideology
           Shape Executive Policies}}},
  shorttitle = {Overreacting and {{Posturing}}},
  author = {Bils, Peter},
  year = {2023},
  month = apr,
  journal = {Quarterly Journal of Political Science},
  volume = {18},
  number = {2},
  publisher = {{Now Publishers, Inc.}},
  issn = {1554-0626, 1554-0634},
  doi = {10.1561/100.00020177},
  urldate = {2023-03-16},
  abstract = {Overreacting and Posturing: How Accountability and Ideology Shape
              Executive Policies},
  langid = {english},
}

@article{blondelFastUnfoldingCommunities2008,
  title = {Fast Unfolding of Communities in Large Networks},
  author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte, Renaud
            and Lefebvre, Etienne},
  year = {2008},
  month = oct,
  journal = {Journal of Statistical Mechanics: Theory and Experiment},
  volume = {2008},
  number = {10},
  pages = {P10008},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/2008/10/P10008},
  urldate = {2023-03-22},
  abstract = {We propose a simple method to extract the community structure of
              large networks. Our method is a heuristic method that is based on
              modularity optimization. It is shown to outperform all other known
              community detection methods in terms of computation time. Moreover,
              the quality of the communities detected is very good, as measured
              by the so-called modularity. This is shown first by identifying
              language communities in a Belgian mobile phone network of 2 million
              customers and by analysing a web graph of 118 million nodes and
              more than one billion links. The accuracy of our algorithm is also
              verified on ad hoc modular networks.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/J5CN7TSU/Blondel et al. - 2008 - Fast
          unfolding of communities in large networks.pdf},
}

@article{blondelFastUnfoldingCommunities2008a,
  title = {Fast Unfolding of Communities in Large Networks},
  author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte, Renaud
            and Lefebvre, Etienne},
  year = {2008},
  month = oct,
  journal = {Journal of Statistical Mechanics: Theory and Experiment},
  volume = {2008},
  number = {10},
  eprint = {0803.0476},
  primaryclass = {cond-mat, physics:physics},
  pages = {P10008},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/2008/10/P10008},
  urldate = {2023-03-22},
  abstract = {We propose a simple method to extract the community structure of
              large networks. Our method is a heuristic method that is based on
              modularity optimization. It is shown to outperform all other known
              community detection method in terms of computation time. Moreover,
              the quality of the communities detected is very good, as measured
              by the so-called modularity. This is shown first by identifying
              language communities in a Belgian mobile phone network of 2.6
              million customers and by analyzing a web graph of 118 million nodes
              and more than one billion links. The accuracy of our algorithm is
              also verified on ad-hoc modular networks.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Data
              Structures and Algorithms,Condensed Matter - Statistical Mechanics,
              Physics - Physics and Society},
  file = {/Users/matpi832/Zotero/storage/KMU6AQAW/Blondel et al. - 2008 - Fast
          unfolding of communities in large networks.pdf},
}

@article{caiReviewSemisupervisedClustering2023,
  title = {A Review on Semi-Supervised Clustering},
  author = {Cai, Jianghui and Hao, Jing and Yang, Haifeng and Zhao, Xujun and
            Yang, Yuqing},
  year = {2023},
  month = jun,
  journal = {Information Sciences},
  volume = {632},
  pages = {164--200},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2023.02.088},
  urldate = {2023-04-24},
  abstract = {Semi-supervised clustering (SSC), a technique integrating
              semi-supervised learning and clustering analysis, incorporates the
              given prior information (e.g., class labels and pairwise
              constraints) into clustering to guide the clustering process and
              improve the performance. In recent years, a large number of
              valuable works have emerged, focusing on theoretical research and
              application in different fields. In this paper, a detailed review
              of SSC is provided from a new perspective. Firstly, all SSC studies
              are organized as partition-based SSC, hierarchical-based SSC,
              density-based SSC, graph-based SSC, neural network-based SSC,
              Nonnegative Matrix Factorization-based SSC and random subspace
              technique-based SSC. Thus, the semi-supervised researches can be
              in-depth discussed in each clustering idea. Secondly, the general
              overviews are detailed in each category respectively, including the
              performance, the suitable scenarios and the way to add supervising
              information. Thirdly, the recent successful applications of SSC are
              summarized according to different backgrounds such as medical,
              biological, business, journalism, financial and so on. Based on
              this, some application caveats and development trends of SSC are
              particularly given in the end. This comprehensive review and
              analysis of SSC can provide an overall outline, the scope of
              research topics, and a relative complete analysis of existing SSC
              methods for researchers.},
  langid = {english},
  keywords = {Constraints K-means,Constraints spectral clustering,NMF-based
              semi-supervised clustering,Random subspace-based semi-supervised
              clustering,Semi-supervised clustering,Semi-supervised fuzzy
              clustering},
  file = {/Users/matpi832/Zotero/storage/5HWEMN9K/Cai et al. - 2023 - A review
          on semi-supervised
          clustering.pdf;/Users/matpi832/Zotero/storage/2GN63UKE/S0020025523002840.html
          },
}

@article{cantuFingerprintsFraudEvidence2019,
  title = {The {{Fingerprints}} of {{Fraud}}: {{Evidence}} from {{Mexico}}'s
           1988 {{Presidential Election}}},
  shorttitle = {The {{Fingerprints}} of {{Fraud}}},
  author = {Cant{\'u}, Francisco},
  year = {2019},
  month = aug,
  journal = {American Political Science Review},
  volume = {113},
  number = {3},
  pages = {710--726},
  publisher = {{Cambridge University Press}},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055419000285},
  urldate = {2023-03-17},
  abstract = {This paper investigates the opportunities for non-democratic
              regimes to rely on fraud by documenting the alteration of vote
              tallies during the 1988 presidential election in Mexico. In
              particular, I study how the alteration of vote returns came after
              an electoral reform that centralized the vote-counting process.
              Using an original image database of the vote-tally sheets for that
              election and applying Convolutional Neural Networks (CNN) to
              analyze the sheets, I find evidence of blatant alterations in about
              a third of the tallies in the country. This empirical analysis
              shows that altered tallies were more prevalent in polling stations
              where the opposition was not present and in states controlled by
              governors with grassroots experience of managing the electoral
              operation. This research has implications for understanding the
              ways in which autocrats control elections as well as for
              introducing a new methodology to audit the integrity of vote
              tallies.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/4MPSF6RH/Cant√∫ - 2019 - The
          Fingerprints of Fraud Evidence from Mexico‚Äôs .pdf},
}

@article{carlsenComputationalGroundedTheory2022,
  title = {Computational Grounded Theory Revisited: {{From}} Computer-Led to
           Computer-Assisted Text Analysis},
  shorttitle = {Computational Grounded Theory Revisited},
  author = {Carlsen, Hjalmar Bang and Ralund, Snorre},
  year = {2022},
  month = jan,
  journal = {Big Data \& Society},
  volume = {9},
  number = {1},
  pages = {20539517221080146},
  publisher = {{SAGE Publications Ltd}},
  issn = {2053-9517},
  doi = {10.1177/20539517221080146},
  urldate = {2023-03-21},
  abstract = {The size and variation in both meaning-making and populations that
              characterize much contemporary text data demand research processes
              that support both discovery, interpretation and measurement. We
              assess one dominant strategy within the social sciences that takes
              a computer-led approach to text analysis. The approach is coined
              computational grounded theory. This strategy, we argue, relies on a
              set of unwarranted assumptions, namely, that unsupervised models
              return natural clusters of meaning, that the researcher can
              understand text with limited immersion and that indirect validation
              is sufficient for ensuring unbiased and precise measurement. In
              response to this criticism, we develop a framework that is computer
              assisted. We argue that our reformulation of computational grounded
              theory better aligns with the principles within grounded theory,
              anthropological theory generation and ethnography.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/IL77L9Z5/Carlsen and Ralund - 2022 -
          Computational grounded theory revisited From comp.pdf},
}

@article{casasImagesThatMatter2019,
  title = {Images That {{Matter}}: {{Online Protests}} and the {{Mobilizing Role
           }} of {{Pictures}}},
  shorttitle = {Images That {{Matter}}},
  author = {Casas, Andreu and Williams, Nora Webb},
  year = {2019},
  month = jun,
  journal = {Political Research Quarterly},
  volume = {72},
  number = {2},
  pages = {360--375},
  publisher = {{SAGE Publications Inc}},
  issn = {1065-9129},
  doi = {10.1177/1065912918786805},
  urldate = {2023-03-17},
  abstract = {Do images affect online political mobilization? If so, how? These
              questions are of fundamental importance to scholars of social
              movements, contentious politics, and political behavior generally.
              However, little prior work has systematically addressed the role of
              images in mobilizing online participation in social movements. We
              first confirm that images have a positive mobilizing effect in the
              context of online protest activity. We then argue that images are
              mobilizing because they trigger stronger emotional reactions than
              text. Building on existing political psychology models, we theorize
              that images evoking enthusiasm, anger, and fear should be
              particularly mobilizing, while sadness should be demobilizing. We
              test the argument through a study of Twitter activity related to a
              Black Lives Matter protest. We find that both images in general and
              some of the proposed emotional attributes (enthusiasm and fear)
              contribute to online participation. The results hold when
              controlling for alternative theoretical mechanisms for why images
              should be mobilizing, and for the presence of frequent image
              features. Our paper provides evidence supporting the broad argument
              that images increase the likelihood of a protest to spread online
              while teasing out the mechanisms at play in a new media
              environment.},
  langid = {english},
}

@article{casasIntroductionSpecialIssue2022,
  title = {Introduction to the {{Special Issue}} on {{Images}} as {{Data}}},
  author = {Casas, Andreu and Williams, Nora Webb},
  year = {2022},
  month = feb,
  journal = {Computational Communication Research},
  volume = {4},
  number = {1},
  publisher = {{Amsterdam University Press}},
  issn = {2665-9085},
  doi = {10.5117/CCR2022.1.000.CASA},
  urldate = {2023-03-01},
  abstract = {Amsterdam University Press is a leading publisher of academic
              books, journals and textbooks in the Humanities and Social
              Sciences. Our aim is to make current research available to scholars
              , students, innovators, and the general public. AUP stands for
              scholarly excellence, global presence, and engagement with the
              international academic community.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/MSSARZ95/Casas and Williams - 2022 -
          Introduction to the Special Issue on Images as Dat.pdf},
}

@misc{CASMDeepLearningApproach,
  title = {{{CASM}}: {{A Deep-Learning Approach}} for {{Identifying Collective
           Action Events}} with {{Text}} and {{Image Data}} from {{Social Media}}
           - {{Han Zhang}}, {{Jennifer Pan}}, 2019},
  urldate = {2023-03-13},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/0081175019860244
                  },
  file = {/Users/matpi832/Zotero/storage/Z6XSZ4AJ/0081175019860244.html},
}

@inproceedings{chenIterativeDeepGraph2020,
  title = {Iterative {{Deep Graph Learning}} for {{Graph Neural Networks}}: {{
           Better}} and {{Robust Node Embeddings}}},
  shorttitle = {Iterative {{Deep Graph Learning}} for {{Graph Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed},
  year = {2020},
  volume = {33},
  pages = {19314--19326},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-03-02},
  abstract = {In this paper, we propose an end-to-end graph learning framework,
              namely \textbackslash textbf\{I\}terative \textbackslash textbf\{D
              \}eep \textbackslash textbf\{G\}raph \textbackslash textbf\{L\}
              earning (\textbackslash alg), for jointly and iteratively learning
              graph structure and graph embedding. The key rationale of
              \textbackslash alg is to learn a better graph structure based on
              better node embeddings, and vice versa (i.e., better node
              embeddings based on a better graph structure). Our iterative method
              dynamically stops when the learned graph structure approaches close
              enough to the graph optimized for the downstream prediction task.
              In addition, we cast the graph learning problem as a similarity
              metric learning problem and leverage adaptive graph regularization
              for controlling the quality of the learned graph. Finally,
              combining the anchor-based approximation technique, we further
              propose a scalable version of \textbackslash alg, namely
              \textbackslash salg, which significantly reduces the time and space
              complexity of \textbackslash alg without compromising the
              performance. Our extensive experiments on nine benchmarks show that
              our proposed \textbackslash alg models can consistently outperform
              or match the state-of-the-art baselines. Furthermore,
              \textbackslash alg can be more robust to adversarial graphs and
              cope with both transductive and inductive learning.},
  file = {/Users/matpi832/Zotero/storage/NR94A2EB/Chen et al. - 2020 - Iterative
          Deep Graph Learning for Graph Neural Net.pdf},
}

@article{chenVisualFramingScience2022,
  title = {Visual {{Framing}} of {{Science Conspiracy Videos}}},
  author = {Chen, Kaiping and Kim, Sang Jung and Gao, Qiantong and Raschka,
            Sebastian},
  year = {2022},
  month = may,
  journal = {Computational Communication Research},
  volume = {4},
  number = {1},
  pages = {98--134},
  urldate = {2023-03-01},
  abstract = {Recent years have witnessed an explosion of science conspiracy
              videos on the Internet, challenging science epistemology and public
              understanding of science. Scholars have started to examine the
              persuasion techniques used in conspiracy messages such as
              uncertainty and fear yet, little is understood about the visual
              narratives, especially how visual narratives differ in videos that
              debunk conspiracies versus those that propagate conspiracies. This
              paper addresses this gap in understanding visual framing in
              conspiracy videos through analyzing millions of frames from
              conspiracy and counter-conspiracy YouTube videos using
              computational methods. We found that conspiracy videos tended to
              use lower color variance and brightness, especially in thumbnails
              and earlier parts of the videos. This paper also demonstrates how
              researchers can integrate textual and visual features in machine
              learning modelsto study conspiracies on social mediaand discusses
              the implications of computational modeling for scholars interested
              in studying visual manipulation in the digital era. The analysis of
              visual and textual features presented in this paper could be useful
              for future studies focused on designing systems to identify
              conspiracy content on the Internet.},
  copyright = {Copyright (c) 2022 Kaiping Chen, Sang Jung Kim, Qiantong Gao,
               Sebastian Raschka},
  langid = {english},
  keywords = {color and brightness,computer vision,conspiracy,machine learning,
              text analysis,YouTube},
  file = {/Users/matpi832/Zotero/storage/T5X5LY3A/Chen et al. - 2022 - Visual
          Framing of Science Conspiracy Videos.pdf},
}

@article{costaOverlappingCommunitiesRoles2022,
  title = {Overlapping Communities and Roles in Networks with Node Attributes: {
           {Probabilistic}} Graphical Modeling, {{Bayesian}} Formulation and
           Variational Inference},
  shorttitle = {Overlapping Communities and Roles in Networks with Node
                Attributes},
  author = {Costa, Gianni and Ortale, Riccardo},
  year = {2022},
  month = jan,
  journal = {Artificial Intelligence},
  volume = {302},
  pages = {103580},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2021.103580},
  urldate = {2023-04-24},
  abstract = {Community and role discovery are key tasks in network analysis.
              The former unveils the organization of a network, whereas the
              latter highlights the social functions of nodes. The integration of
              community discovery and role analysis has been investigated, to
              gain a deeper understanding of topology, i.e., the social functions
              fulfilled by nodes to pursue community purposes. However, hitherto,
              node attributes and behavioral role patterns have been ignored in
              the combination of both tasks. In this manuscript, we study the
              seamless integration of community discovery and behavioral role
              analysis, in the domain of networks with node attributes. In
              particular, we focus on unifying the two tasks, by explicitly
              harnessing node attributes and behavioral role patterns in a
              principled manner. To this end, we propose two Bayesian
              probabilistic generative models of networks, whose novelty consists
              in the interrelationship of overlapping communities, roles, their
              behavioral patterns and node attributes. The devised models allow
              for a variety of exploratory, descriptive and predictive tasks.
              These are carried out through mean-field variational inference,
              which is in turn mathematically derived and implemented into a
              coordinate-ascent algorithm. A wide spectrum of experiments is
              designed, to validate the devised models against three classes of
              state-of-the-art competitors using various real-world benchmark
              data sets from different social networking services. Our models are
              found to be more accurate in community detection, link prediction
              and attribute prediction. Notably, the gain in accuracy is robust
              to perturbations in the form of noise or lack of observations in
              either network structure or node attributes. Beside accuracy,
              scalability is also comparatively investigated. Finally, a
              qualitative demonstration of the tasks enabled by our models is
              developed, in which node roles are intuitively explained through an
              unprecedented visual representation.},
  langid = {english},
  keywords = {Attribute prediction,Bayesian probabilistic network modeling,
              Community discovery,Link prediction,Role analysis},
  file = {/Users/matpi832/Zotero/storage/YFVLYHYE/Costa and Ortale - 2022 -
          Overlapping communities and roles in networks
          with.pdf;/Users/matpi832/Zotero/storage/6TS2G3VG/S0004370221001314.html
          },
}

@article{cranmerNavigatingRangeStatistical2017,
  title = {Navigating the {{Range}} of {{Statistical Tools}} for {{Inferential
           Network Analysis}}},
  author = {Cranmer, Skyler J. and Leifeld, Philip and McClurg, Scott D. and
            Rolfe, Meredith},
  year = {2017},
  journal = {American Journal of Political Science},
  volume = {61},
  number = {1},
  pages = {237--251},
  issn = {1540-5907},
  doi = {10.1111/ajps.12263},
  urldate = {2023-03-02},
  abstract = {The last decade has seen substantial advances in statistical
              techniques for the analysis of network data, as well as a major
              increase in the frequency with which these tools are used. These
              techniques are designed to accomplish the same broad goal,
              statistically valid inference in the presence of highly
              interdependent relationships, but important differences remain
              between them. We review three approaches commonly used for
              inferential network analysis\textemdash the quadratic assignment
              procedure, exponential random graph models, and latent space
              network models\textemdash highlighting the strengths and weaknesses
              of the techniques relative to one another. An illustrative example
              using climate change policy network data shows that all three
              network models outperform standard logit estimates on multiple
              criteria. This article introduces political scientists to a class
              of network techniques beyond simple descriptive measures of network
              structure, and it helps researchers choose which model to use in
              their own research.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/C8WL7JX4/Cranmer et al. - 2017 -
          Navigating the Range of Statistical Tools for
          Infe.pdf;/Users/matpi832/Zotero/storage/42PHFGSW/ajps.html},
}

@article{daneshSurveyClusteringLarge,
  title = {A Survey of Clustering Large Probabilistic Graphs: {{Techniques}},
           Evaluations, and Applications},
  shorttitle = {A Survey of Clustering Large Probabilistic Graphs},
  author = {Danesh, Malihe and Dorrigiv, Morteza and Yaghmaee, Farzin},
  journal = {Expert Systems},
  volume = {n/a},
  number = {n/a},
  pages = {e13248},
  issn = {1468-0394},
  doi = {10.1111/exsy.13248},
  urldate = {2023-03-06},
  abstract = {Given the growth of uncertainty in the real world, analysing
              probabilistic graphs is crucial. Clustering is one of the most
              fundamental methods of mining probabilistic graphs to discover the
              hidden patterns in them. This survey examines an extensive and
              organized analysis of the clustering techniques of large
              probabilistic graphs proposed in the literature. First, the
              definition of probabilistic graphs and modelling them are
              introduced. Second, the clustering of such graphs and their
              challenges, such as uncertainty of edges, high dimensions, and the
              impossibility of applying certain graph clustering techniques
              directly, are expressed. Then, a taxonomy of clustering approaches
              is discussed in two main categories: threshold-based and possible
              worlds-based methods. The techniques presented in each category are
              explained and examined. Here, these methods are evaluated on real
              datasets, and their performance is compared with each other.
              Finally, the survey is summarized by describing some of the
              applications of probabilistic graph clustering and future research
              directions.},
  langid = {english},
  keywords = {clustering,possible worlds-based methods,probabilistic graph,
              threshold-based methods},
  file = {/Users/matpi832/Zotero/storage/B3ZUZ5LB/Danesh et al. - A survey of
          clustering large probabilistic
          graphs.pdf;/Users/matpi832/Zotero/storage/5A85XEZU/exsy.html},
}

@article{dennyTextPreprocessingUnsupervised2018,
  title = {Text {{Preprocessing For Unsupervised Learning}}: {{Why It Matters}},
           {{When It Misleads}}, {{And What To Do About It}}},
  shorttitle = {Text {{Preprocessing For Unsupervised Learning}}},
  author = {Denny, Matthew J. and Spirling, Arthur},
  year = {2018},
  month = apr,
  journal = {Political Analysis},
  volume = {26},
  number = {2},
  pages = {168--189},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2017.44},
  urldate = {2023-03-08},
  abstract = {Despite the popularity of unsupervised techniques for political
              science text-as-data research, the importance and implications of
              preprocessing decisions in this domain have received scant
              systematic attention. Yet, as we show, such decisions have profound
              effects on the results of real models for real data. We argue that
              substantive theory is typically too vague to be of use for feature
              selection, and that the supervised literature is not necessarily a
              helpful source of advice. To aid researchers working in
              unsupervised settings, we introduce a statistical procedure and
              software that examines the sensitivity of findings under alternate
              preprocessing regimes. This approach complements a researcher's
              substantive understanding of a problem by providing a
              characterization of the variability changes in preprocessing
              choices may induce when analyzing a particular dataset. In making
              scholars aware of the degree to which their results are likely to
              be sensitive to their preprocessing decisions, it aids replication
              efforts.},
  langid = {english},
  keywords = {descriptive statistics,statistical analysis of texts,unsupervised
              learning},
  file = {/Users/matpi832/Zotero/storage/GRPCS3SB/Denny and Spirling - 2018 -
          Text Preprocessing For Unsupervised Learning Why .pdf},
}

@inproceedings{dueckNonmetricAffinityPropagation2007,
  title = {Non-Metric Affinity Propagation for Unsupervised Image Categorization
           },
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer
               Vision}}},
  author = {Dueck, Delbert and Frey, Brendan J.},
  year = {2007},
  month = oct,
  pages = {1--8},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2007.4408853},
  abstract = {Unsupervised categorization of images or image parts is often
              needed for image and video summarization or as a preprocessing step
              in supervised methods for classification, tracking and
              segmentation. While many metric-based techniques have been applied
              to this problem in the vision community, often, the most natural
              measures of similarity (e.g., number of matching SIFT features)
              between pairs of images or image parts is non-metric. Unsupervised
              categorization by identifying a subset of representative exemplars
              can be efficiently performed with the recently-proposed 'affinity
              propagation' algorithm. In contrast to k-centers clustering, which
              iteratively refines an initial randomly-chosen set of exemplars,
              affinity propagation simultaneously considers all data points as
              potential exemplars and iteratively exchanges messages between data
              points until a good solution emerges. When applied to the Olivetti
              face data set using a translation-invariant non-metric similarity,
              affinity propagation achieves a much lower reconstruction error and
              nearly halves the classification error rate, compared to
              state-of-the-art techniques. For the more challenging problem of
              unsupervised categorization of images from the CaltechlOl data set,
              we derived non-metric similarities between pairs of images by
              matching SIFT features. Affinity propagation successfully
              identifies meaningful categories, which provide a natural
              summarization of the training images and can be used to classify
              new input images.},
  keywords = {Clustering algorithms,Data preprocessing,Educational institutions,
              Error analysis,Euclidean distance,Face detection,Image
              reconstruction,Image segmentation,Iterative algorithms,Machine
              learning},
  file = {/Users/matpi832/Zotero/storage/VU7JZVE8/Dueck and Frey - 2007 -
          Non-metric affinity propagation for unsupervised i.pdf},
}

@article{duqueRecognizingInternationalStatus2018,
  title = {Recognizing {{International Status}}: {{A Relational Approach}}},
  shorttitle = {Recognizing {{International Status}}},
  author = {Duque, Marina G},
  year = {2018},
  month = sep,
  journal = {International Studies Quarterly},
  volume = {62},
  number = {3},
  pages = {577--592},
  issn = {0020-8833},
  doi = {10.1093/isq/sqy001},
  urldate = {2023-03-20},
  abstract = {How do states achieve status? Although we rely on status to
              explain important phenomena in international politics\textemdash
              such as wars and the foreign policy of emerging powers\textemdash
              we still do not understand what status is or where it comes from.
              Previous research treats status as a function of state attributes,
              such as wealth and military capability. Following Weber, I argue
              that status depends on social recognition: it concerns
              identification processes in which an actor gains admission into a
              club once they follow the rules of membership. Therefore,
              systematic social processes, which cannot be reduced to state
              attributes, influence status. In particular, status is
              self-reinforcing. Moreover, social closure influences status
              \textemdash which implies that (1) a state's existing relations
              influence its ability to achieve status and (2) states recognize
              similar states rather than states with the most impressive
              portfolio of certain attributes. To investigate the determinants of
              international status, I move beyond ranking states based on
              attributes to examine quantitatively how status emerges from state
              relations. Leveraging inferential network analysis, I examine state
              practices that express recognition\textemdash specifically, the
              network of embassies. The analysis indicates that self-reinforcing
              dynamics and social closure, rather than state attributes directly,
              drive status recognition.},
  file = {/Users/matpi832/Zotero/storage/LTQB4MEC/4962448.html},
}

@misc{egamiHowMakeCausal2018,
  title = {How to {{Make Causal Inferences Using Texts}}},
  author = {Egami, Naoki and Fong, Christian J. and Grimmer, Justin and Roberts,
            Margaret E. and Stewart, Brandon M.},
  year = {2018},
  month = feb,
  number = {arXiv:1802.02163},
  eprint = {1802.02163},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1802.02163},
  urldate = {2023-03-17},
  abstract = {New text as data techniques offer a great promise: the ability to
              inductively discover measures that are useful for testing social
              science theories of interest from large collections of text. We
              introduce a conceptual framework for making causal inferences with
              discovered measures as a treatment or outcome. Our framework
              enables researchers to discover high-dimensional textual
              interventions and estimate the ways that observed treatments affect
              text-based outcomes. We argue that nearly all text-based causal
              inferences depend upon a latent representation of the text and we
              provide a framework to learn the latent representation. But
              estimating this latent representation, we show, creates new risks:
              we may introduce an identification problem or overfit. To address
              these risks we describe a split-sample framework and apply it to
              estimate causal effects from an experiment on immigration attitudes
              and a study on bureaucratic response. Our work provides a rigorous
              foundation for text-based causal inferences.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Statistics - Machine
              Learning,Statistics - Methodology},
  file = {/Users/matpi832/Zotero/storage/38T3IMN8/Egami et al. - 2018 - How to
          Make Causal Inferences Using
          Texts.pdf;/Users/matpi832/Zotero/storage/8WXSQWCQ/Egami et al. - 2018 -
          How to Make Causal Inferences Using
          Texts.pdf;/Users/matpi832/Zotero/storage/S5UXE6Z6/1802.html},
}

@article{estivill-castroWhyManyClustering2002,
  title = {Why so Many Clustering Algorithms: A Position Paper},
  shorttitle = {Why so Many Clustering Algorithms},
  author = {{Estivill-Castro}, Vladimir},
  year = {2002},
  month = jun,
  journal = {ACM SIGKDD Explorations Newsletter},
  volume = {4},
  number = {1},
  pages = {65--75},
  issn = {1931-0145},
  doi = {10.1145/568574.568575},
  urldate = {2023-04-28},
  abstract = {We argue that there are many clustering algorithms, because the
              notion of "cluster" cannot be precisely defined. Clustering is in
              the eye of the beholder, and as such, researchers have proposed
              many induction principles and models whose corresponding
              optimization problem can only be approximately solved by an even
              larger number of algorithms. Therefore, comparing clustering
              algorithms, must take into account a careful understanding of the
              inductive principles involved.},
  keywords = {clustering,clustering criterion,inductive principle},
}

@inproceedings{fongDiscoveryTreatmentsText2016,
  title = {Discovery of {{Treatments}} from {{Text Corpora}}},
  author = {Fong, Christian and Grimmer, Justin},
  year = {2016},
  month = jan,
  pages = {1600--1609},
  doi = {10.18653/v1/P16-1151},
  file = {/Users/matpi832/Zotero/storage/5XCKDX2T/Fong and Grimmer - 2016 -
          Discovery of Treatments from Text Corpora.pdf},
}

@misc{FrameworkUnsupervisedSemisupervisedanalysis,
  title = {A Framework for the Unsupervised and Semi-Supervisedanalysis of
           Visual Frames},
  journal = {Dropbox},
  urldate = {2023-03-01},
  abstract = {Shared with Dropbox},
  howpublished = {https://www.dropbox.com/s/otps2cqpqtqb3js/PA\_BoVW\_main\_V4
                  \_RnR.pdf?dl=0},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/LLIT9YCA/A framework for the
          unsupervised and
          semi-supervis.pdf;/Users/matpi832/Zotero/storage/QJGL2CSG/PA_BoVW_main_V4_RnR.html
          },
}

@article{gerlachNetworkApproachTopic2018,
  title = {A Network Approach to Topic Models},
  author = {Gerlach, Martin and Peixoto, Tiago P. and Altmann, Eduardo G.},
  year = {2018},
  month = jul,
  journal = {Science Advances},
  volume = {4},
  number = {7},
  pages = {eaaq1360},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.aaq1360},
  urldate = {2023-03-25},
  abstract = {One of the main computational and scientific challenges in the
              modern age is to extract useful information from unstructured
              texts. Topic models are one popular machine-learning approach that
              infers the latent topical structure of a collection of documents.
              Despite their success\textemdash particularly of the most widely
              used variant called latent Dirichlet allocation (LDA)\textemdash
              and numerous applications in sociology, history, and linguistics,
              topic models are known to suffer from severe conceptual and
              practical problems, for example, a lack of justification for the
              Bayesian priors, discrepancies with statistical properties of real
              texts, and the inability to properly choose the number of topics.
              We obtain a fresh view of the problem of identifying topical
              structures by relating it to the problem of finding communities in
              complex networks. We achieve this by representing text corpora as
              bipartite networks of documents and words. By adapting existing
              community-detection methods (using a stochastic block model (SBM)
              with nonparametric priors), we obtain a more versatile and
              principled framework for topic modeling (for example, it
              automatically detects the number of topics and hierarchically
              clusters both the words and documents). The analysis of artificial
              and real corpora demonstrates that our SBM approach leads to better
              topic models than LDA in terms of statistical model selection. Our
              work shows how to formally relate methods from community detection
              and topic modeling, opening the possibility of cross-fertilization
              between these two fields.},
  file = {/Users/matpi832/Zotero/storage/TSG66C7W/Gerlach et al. - 2018 - A
          network approach to topic models.pdf},
}

@article{grimmerGeneralPurposeComputerassisted2011,
  title = {General Purpose Computer-Assisted Clustering and Conceptualization},
  author = {Grimmer, Justin and King, Gary},
  year = {2011},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {7},
  pages = {2643--2650},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1018067108},
  urldate = {2023-03-13},
  abstract = {We develop a computer-assisted method for the discovery of
              insightful conceptualizations, in the form of clusterings (i.e.,
              partitions) of input objects. Each of the numerous fully automated
              methods of cluster analysis proposed in statistics, computer
              science, and biology optimize a different objective function.
              Almost all are well defined, but how to determine before the fact
              which one, if any, will partition a given set of objects in an
              ``insightful'' or ``useful'' way for a given user is unknown and
              difficult, if not logically impossible. We develop a metric space
              of partitions from all existing cluster analysis methods applied to
              a given dataset (along with millions of other solutions we add
              based on combinations of existing clusterings) and enable a user to
              explore and interact with it and quickly reveal or prompt useful or
              insightful conceptualizations. In addition, although it is uncommon
              to do so in unsupervised learning problems, we offer and implement
              evaluation designs that make our computer-assisted approach
              vulnerable to being proven suboptimal in specific data types. We
              demonstrate that our approach facilitates more efficient and
              insightful discovery of useful information than expert human coders
              or many existing fully automated methods.},
  file = {/Users/matpi832/Zotero/storage/4ML77YEE/Grimmer and King - 2011 -
          General purpose computer-assisted clustering and c.pdf},
}

@article{grimmerMachineLearningSocial2021,
  title = {Machine {{Learning}} for {{Social Science}}: {{An Agnostic Approach}}
           },
  shorttitle = {Machine {{Learning}} for {{Social Science}}},
  author = {Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
  year = {2021},
  journal = {Annual Review of Political Science},
  volume = {24},
  number = {1},
  pages = {395--419},
  doi = {10.1146/annurev-polisci-053119-015921},
  urldate = {2023-03-09},
  abstract = {Social scientists are now in an era of data abundance, and machine
              learning tools are increasingly used to extract meaning from data
              sets both massive and small. We explain how the inclusion of
              machine learning in the social sciences requires us to rethink not
              only applications of machine learning methods but also best
              practices in the social sciences. In contrast to the traditional
              tasks for machine learning in computer science and statistics, when
              machine learning is applied to social scientific data, it is used
              to discover new concepts, measure the prevalence of those concepts,
              assess causal effects, and make predictions. The abundance of data
              and resources facilitates the move away from a deductive social
              science to a more sequential, interactive, and ultimately inductive
              approach to inference. We explain how an agnostic approach to
              machine learning methods focused on the social science tasks
              facilitates progress across a wide range of questions.},
  keywords = {machine learning,research design,text as data},
  file = {/Users/matpi832/Zotero/storage/AQPEUSBC/Grimmer et al. - 2021 -
          Machine Learning for Social Science An Agnostic A.pdf},
}

@article{grimmerTextDataPromise2013,
  title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{Automatic
           Content Analysis Methods}} for {{Political Texts}}},
  shorttitle = {Text as {{Data}}},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  year = {2013/ed},
  journal = {Political Analysis},
  volume = {21},
  number = {3},
  pages = {267--297},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mps028},
  urldate = {2023-03-08},
  abstract = {Politics and political conflict often occur in the written and
              spoken word. Scholars have long recognized this, but the massive
              costs of analyzing even moderately sized collections of texts have
              hindered their use in political science research. Here lies the
              promise of automated text analysis: it substantially reduces the
              costs of analyzing large collections of text. We provide a guide to
              this exciting new area of research and show how, in many instances,
              the methods have already obtained part of their promise. But there
              are pitfalls to using automated methods\textemdash they are no
              substitute for careful thought and close reading and require
              extensive and problem-specific validation. We survey a wide range
              of new methods, provide guidance on how to validate the output of
              the models, and clarify misconceptions and errors in the
              literature. To conclude, we argue that for automated text methods
              to become a standard tool for political scientists, methodologists
              must contribute new methods and new methods of validation.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/BQU43ZSN/Grimmer and Stewart - 2013 -
          Text as Data The Promise and Pitfalls of Automati.pdf},
}

@inproceedings{grimmerUnreliabilityMeasuresIntercoder2015,
  title = {The {{Unreliability}} of {{Measures}} of {{Intercoder Reliability}} ,
           and {{What}} to Do {{About}} It},
  author = {Grimmer, Justin and King, Gary and Superti, Chiara},
  year = {2015},
  urldate = {2023-03-08},
  abstract = {In both automated and traditional text analysis, human coders are
              regularly tasked with categorizing documents. Researchers then
              evaluate the success of this crucial step in the research process
              via one of many measures of intercoder reliability, such as
              Cronbachs alpha. They then improve coding practices until this
              measure reaches some arbitrary threshold, at which point remaining
              disagreements are resolved in arbitrary ways and ignored in
              subsequent analyses. We show that this common practice can generate
              severely biased estimates and misleading conclusions. The problem
              is the focus on measures of intercoder reliability which, except at
              the extreme, are unrelated to the quantities of interest, such as
              the proportion of documents in each category. We thus develop an
              approach that enables scholars to directly incorporate coding
              uncertainty into statistical estimation. The method offers an
              interval estimate which we prove contains the true proportion of
              documents in each category, under reasonable assumptions. We then
              extend this method to situations with multiple coders, when one
              coder is trusted more than another, and when the resulting document
              codes are used as inputs to another statistical model. We offer
              easy-to-use software that implements all our suggestions. {${_\ast}
              $}Department of Political Science, Stanford University,
              JustinGrimmer.org, jgrimmer@stanford.edu. \textdagger Institute for
              Quantitative Social Science, Harvard University; GaryKing.org,
              king@harvard.edu, (617) 500-7570. \textdaggerdbl Institute for
              Quantitative Social Science, Harvard University,
              scholar.harvard.edu/csuperti, csuperti@fas.harvard.edu 1},
  file = {/Users/matpi832/Zotero/storage/JIQIZ2SL/Grimmer et al. - 2015 - The
          Unreliability of Measures of Intercoder Reliab.pdf},
}

@misc{guerinCNNFeaturesAre2018,
  title = {{{CNN}} Features Are Also Great at Unsupervised Classification},
  author = {Gu{\'e}rin, Joris and Gibaru, Olivier and Thiery, St{\'e}phane and
            Nyiri, Eric},
  year = {2018},
  month = sep,
  number = {arXiv:1707.01700},
  eprint = {1707.01700},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1707.01700},
  urldate = {2023-03-21},
  abstract = {This paper aims at providing insight on the transferability of
              deep CNN features to unsupervised problems. We study the impact of
              different pretrained CNN feature extractors on the problem of image
              set clustering for object classification as well as fine-grained
              classification. We propose a rather straightforward pipeline
              combining deep-feature extraction using a CNN pretrained on
              ImageNet and a classic clustering algorithm to classify sets of
              images. This approach is compared to state-of-the-art algorithms in
              image-clustering and provides better results. These results
              strengthen the belief that supervised training of deep CNN on large
              datasets, with a large variability of classes, extracts better
              features than most carefully designed engineering approaches, even
              for unsupervised tasks. We also validate our approach on a robotic
              application, consisting in sorting and storing objects smartly
              based on clustering.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science -
              Computer Vision and Pattern Recognition,Computer Science - Machine
              Learning},
  file = {/Users/matpi832/Zotero/storage/UHBCXG3Q/Gu√©rin et al. - 2018 - CNN
          features are also great at unsupervised
          classi.pdf;/Users/matpi832/Zotero/storage/ZZ63CU4M/1707.html},
}

@article{hohmannQuantifyingIdeologicalPolarization2023,
  title = {Quantifying Ideological Polarization on a Network Using Generalized {
           {Euclidean}} Distance},
  author = {Hohmann, Marilena and Devriendt, Karel and Coscia, Michele},
  year = {2023},
  month = mar,
  journal = {Science Advances},
  volume = {9},
  number = {9},
  pages = {eabq2044},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abq2044},
  urldate = {2023-03-02},
  abstract = {An intensely debated topic is whether political polarization on
              social media is on the rise. We can investigate this question only
              if we can quantify polarization, by taking into account how extreme
              the opinions of the people are, how much they organize into echo
              chambers, and how these echo chambers organize in the network.
              Current polarization estimates are insensitive to at least one of
              these factors: They cannot conclusively clarify the opening
              question. Here, we propose a measure of ideological polarization
              that can capture the factors we listed. The measure is based on the
              generalized Euclidean distance, which estimates the distance
              between two vectors on a network, e.g., representing people's
              opinion. This measure can fill the methodological gap left by the
              state of the art and leads to useful insights when applied to
              real-world debates happening on social media and to data from the
              U.S. Congress.},
  file = {/Users/matpi832/Zotero/storage/IVR7R8PJ/Hohmann et al. - 2023 -
          Quantifying ideological polarization on a network .pdf},
}

@article{hongComputingDistributionFunction2013,
  title = {On Computing the Distribution Function for the {{Poisson}} Binomial
           Distribution},
  author = {Hong, Yili},
  year = {2013},
  month = mar,
  journal = {Computational Statistics \& Data Analysis},
  volume = {59},
  pages = {41--51},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2012.10.006},
  urldate = {2023-03-06},
  abstract = {The Poisson binomial distribution is the distribution of the sum
              of independent and non-identically distributed random indicators.
              Each indicator follows a Bernoulli distribution and the individual
              probabilities of success vary. When all success probabilities are
              equal, the Poisson binomial distribution is a binomial
              distribution. The Poisson binomial distribution has many
              applications in different areas such as reliability, actuarial
              science, survey sampling, econometrics, etc. The computing of the
              cumulative distribution function (cdf) of the Poisson binomial
              distribution, however, is not straightforward. Approximation
              methods such as the Poisson approximation and normal approximations
              have been used in literature. Recursive formulae also have been
              used to compute the cdf in some areas. In this paper, we present a
              simple derivation for an exact formula with a closed-form
              expression for the cdf of the Poisson binomial distribution. The
              derivation uses the discrete Fourier transform of the
              characteristic function of the distribution. We develop an
              algorithm that efficiently implements the exact formula. Numerical
              studies were conducted to study the accuracy of the developed
              algorithm and approximation methods. We also studied the
              computational efficiency of different methods. The paper is
              concluded with a discussion on the use of different methods in
              practice and some suggestions for practitioners.},
  langid = {english},
  keywords = {-out-of- system,Characteristic function,Longevity risk,Normal
              approximation,Sum of independent random indicators,Warranty returns
              },
  file = {/Users/matpi832/Zotero/storage/LK3X5D2R/Hong - 2013 - On computing the
          distribution function for the
          Poi.pdf;/Users/matpi832/Zotero/storage/WLI7DBG7/S0167947312003568.html},
}

@article{huWhatWeInstagram2014,
  title = {What We Instagram: 8th {{International Conference}} on {{Weblogs}}
           and {{Social Media}}, {{ICWSM}} 2014},
  shorttitle = {What We Instagram},
  author = {Hu, Yuheng and Manikonda, Lydia and Kambhampati, Subbarao},
  year = {2014},
  month = jan,
  journal = {Proceedings of the 8th International Conference on Weblogs and
             Social Media, ICWSM 2014},
  series = {Proceedings of the 8th {{International Conference}} on {{Weblogs}}
            and {{Social Media}}, {{ICWSM}} 2014},
  pages = {595--598},
  publisher = {{The AAAI Press}},
  urldate = {2023-03-21},
  abstract = {Instagram is a relatively new form of communication where users
              can easily share their updates by taking photos and tweaking them
              using filters. It has seen rapid growth in the number of users as
              well as uploads since it was launched in October 2010. In spite of
              the fact that it is the most popular photo capturing and sharing
              application, it has attracted relatively less attention from the
              research community. In this paper, we present both qualitative and
              quantitative analysis on Instagram. We use computer vision
              techniques to examine the photo content. Based on that, we identify
              the different types of active users on Instagram using clustering.
              Our results reveal several insights about Instagram which were
              never studied before, that include: 1) Eight popular photos
              categories, 2) Five distinct types of Instagram users in terms of
              their posted photos, and 3) A user's audience (number of followers)
              is independent of his/her shared photos on Instagram. To our
              knowledge, this is the first in-depth study of content and users on
              Instagram.},
  file = {/Users/matpi832/Zotero/storage/SPR2Z2FV/Hu et al. - 2014 - What we
          instagram 8th International Conference on.pdf},
}

@article{jerzakImprovedMethodAutomated2023,
  title = {An {{Improved Method}} of {{Automated Nonparametric Content Analysis}
           } for {{Social Science}}},
  author = {Jerzak, Connor T. and King, Gary and Strezhnev, Anton},
  year = {2023},
  month = jan,
  journal = {Political Analysis},
  volume = {31},
  number = {1},
  pages = {42--58},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2021.36},
  urldate = {2023-03-16},
  abstract = {Some scholars build models to classify documents into chosen
              categories. Others, especially social scientists who tend to focus
              on population characteristics, instead usually estimate the
              proportion of documents in each category\textemdash using either
              parametric ``classify-and-count'' methods or ``direct''
              nonparametric estimation of proportions without individual
              classification. Unfortunately, classify-and-count methods can be
              highly model-dependent or generate more bias in the proportions
              even as the percent of documents correctly classified increases.
              Direct estimation avoids these problems, but can suffer when the
              meaning of language changes between training and test sets or is
              too similar across categories. We develop an improved direct
              estimation approach without these issues by including and
              optimizing continuous text features, along with a form of matching
              adapted from the causal inference literature. Our approach
              substantially improves performance in a diverse collection of 73
              datasets. We also offer easy-to-use software that implements all
              ideas discussed herein.},
  langid = {english},
  keywords = {natural language processing,non-parametric statistics,
              quantification},
  file = {/Users/matpi832/Zotero/storage/LN5CPX8M/Jerzak et al. - 2023 - An
          Improved Method of Automated Nonparametric Cont.pdf},
}

@article{jooImageDataAutomated2022,
  title = {Image as {{Data}}: {{Automated Content Analysis}} for {{Visual
           Presentations}} of {{Political Actors}} and {{Events}}},
  shorttitle = {Image as {{Data}}},
  author = {Joo, Jungseock and {Steinert-Threlkeld}, Zachary C.},
  year = {2022},
  month = feb,
  journal = {Computational Communication Research},
  volume = {4},
  number = {1},
  publisher = {{Amsterdam University Press}},
  issn = {2665-9085},
  doi = {10.5117/CCR2022.1.001.JOO},
  urldate = {2023-03-01},
  abstract = {Abstract Images matter because they help individuals evaluate
              policies, primarily through emotional resonance, and can help
              researchers from a variety of fields measure otherwise difficult to
              estimate quantities. The lack of scalable analytic methods, however
              , has prevented researchers from incorporating large scale image
              data in studies. This article offers an in-depth overview of
              automated methods for image analysis and explains their usage and
              implementation. It elaborates on how these methods and results can
              be validated and interpreted and discusses ethical concerns. Two
              examples then highlight approaches to systematically understanding
              visual presentations of political actors and events from large
              scale image datasets collected from social media. The first study
              examines gender and party differences in the self-presentation of
              the U.S. politicians through their Facebook photographs, using an
              off-the-shelf computer vision model, Google's Label Detection API.
              The second study develops image classifiers based on convolutional
              neural networks to detect custom labels from images of protesters
              shared on Twitter to understand how protests are framed on social
              media. These analyses demonstrate advantages of computer vision and
              deep learning as a novel analytic tool that can expand the scope
              and size of traditional visual analysis to thousands of features
              and millions of images. The paper also provides comprehensive
              technical details and practices to help guide political
              communication scholars and practitioners.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/JJQ96CS5/Joo and Steinert-Threlkeld -
          2022 - Image as Data Automated Content Analysis for Visu.pdf},
}

@incollection{kangUnderstandingPoliticalCommunication2020a,
  title = {Understanding {{Political Communication Styles}} in {{Televised
           Debates}} via {{Body Movements}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2020 {{Workshops}}},
  author = {Kang, Zhiqi and Indudhara, Christina and Mahorker, Kaushik and Bucy,
            Erik P. and Joo, Jungseock},
  editor = {Bartoli, Adrien and Fusiello, Andrea},
  year = {2020},
  volume = {12535},
  pages = {788--793},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-66415-2_55},
  urldate = {2023-03-21},
  abstract = {Televised political debates have received much attention by
              scholars in political communication and social psychology who study
              nonverbal cues in interpersonal communication and their impact on
              candidate evaluations. An abundance of political multimedia and new
              platforms have required leaders to develop an effective and unique
              communication ``style'' which may rely on nonverbal devices such as
              face and body. Emotions conveyed by expressive gestures of
              candidates during debates have been shown to elicit stronger
              reactions from the public than rhetorical statements alone.
              Candidates, for example, may exploit assertive and aggressive
              gestures to communicate their confidence and attract supporters.
              Existing studies, however, are based largely on manual coding of
              human gestures, which may not be scalable or reproducible. The main
              objectives of our paper are to investigate the role of body
              movements of candidates using a systematic and automated approach
              as well as understand the context and effects of gestures. For this
              analysis, we collected a dataset of political debate videos from
              the 2020 Democratic presidential primaries and analyzed facial
              expressions and gestures of candidates. Our preliminary analysis
              demonstrates that candidates employ gestures to varying extents,
              and the amount of body movement is correlated with emotions
              conveyed in the candidates' facial expressions. We discuss our
              dataset, preliminary results, and future directions in the
              following sections.},
  isbn = {978-3-030-66414-5 978-3-030-66415-2},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/5N58UR6P/Kang et al. - 2020 -
          Understanding Political Communication Styles in Te.pdf},
}

@article{kingComputerAssistedKeywordDocument2017,
  title = {Computer-{{Assisted Keyword}} and {{Document Set Discovery}} from {{
           Unstructured Text}}},
  author = {King, Gary and Lam, Patrick and Roberts, Margaret E.},
  year = {2017},
  journal = {American Journal of Political Science},
  volume = {61},
  number = {4},
  pages = {971--988},
  issn = {1540-5907},
  doi = {10.1111/ajps.12291},
  urldate = {2023-03-09},
  abstract = {The (unheralded) first step in many applications of automated text
              analysis involves selecting keywords to choose documents from a
              large text corpus for further study. Although all substantive
              results depend on this choice, researchers usually pick keywords in
              ad hoc ways that are far from optimal and usually biased. Most seem
              to think that keyword selection is easy, since they do Google
              searches every day, but we demonstrate that humans perform
              exceedingly poorly at this basic task. We offer a better approach,
              one that also can help with following conversations where
              participants rapidly innovate language to evade authorities, seek
              political advantage, or express creativity; generic web searching;
              eDiscovery; look-alike modeling; industry and intelligence
              analysis; and sentiment and topic analysis. We develop a
              computer-assisted (as opposed to fully automated or human-only)
              statistical approach that suggests keywords from available text
              without needing structured data as inputs. This framing poses the
              statistical problem in a new way, which leads to a widely
              applicable algorithm. Our specific approach is based on training
              classifiers, extracting information from (rather than correcting)
              their mistakes, and summarizing results with easy-to-understand
              Boolean search strings. We illustrate how the technique works with
              analyses of English texts about the Boston Marathon bombings,
              Chinese social media posts designed to evade censorship, and
              others.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/754QYSEJ/King et al. - 2017 -
          Computer-Assisted Keyword and Document Set
          Discove.pdf;/Users/matpi832/Zotero/storage/S48GY9BH/ajps.html},
}

@article{knoxTestingCausalTheories2022,
  title = {Testing {{Causal Theories}} with {{Learned Proxies}}},
  author = {Knox, Dean and Lucas, Christopher and Cho, Wendy K. Tam},
  year = {2022},
  journal = {Annual Review of Political Science},
  volume = {25},
  number = {1},
  pages = {419--441},
  doi = {10.1146/annurev-polisci-051120-111443},
  urldate = {2023-03-16},
  abstract = {Social scientists commonly use computational models to estimate
              proxies of unobserved concepts, then incorporate these proxies into
              subsequent tests of their theories. The consequences of this
              practice, which occurs in over two-thirds of recent computational
              work in political science, are underappreciated. Imperfect proxies
              can reflect noise and contamination from other concepts, producing
              biased point estimates and standard errors. We demonstrate how
              analysts can use causal diagrams to articulate theoretical concepts
              and their relationships to estimated proxies, then apply
              straightforward rules to assess which conclusions are rigorously
              supportable. We formalize and extend common heuristics for
              ``signing the bias''\textemdash a technique for reasoning about
              unobserved confounding\textemdash to scenarios with imperfect
              proxies. Using these tools, we demonstrate how, in
              often-encountered research settings, proxy-based analyses allow for
              valid tests for the existence and direction of theorized effects.
              We conclude with best-practice recommendations for the rapidly
              growing literature using learned proxies to test causal theories.},
  keywords = {causal inference,machine learning,measurement,proxies,supervised
              learning},
  file = {/Users/matpi832/Zotero/storage/2GADAYMD/Knox et al. - 2022 - Testing
          Causal Theories with Learned Proxies.pdf},
}

@article{kolliosClusteringLargeProbabilistic2013,
  title = {Clustering {{Large Probabilistic Graphs}}},
  author = {Kollios, George and Potamias, Michalis and Terzi, Evimaria},
  year = {2013},
  month = feb,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {25},
  number = {2},
  pages = {325--336},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2011.243},
  abstract = {We study the problem of clustering probabilistic graphs. Similar
              to the problem of clustering standard graphs, probabilistic graph
              clustering has numerous applications, such as finding complexes in
              probabilistic protein-protein interaction (PPI) networks and
              discovering groups of users in affiliation networks. We extend the
              edit-distance-based definition of graph clustering to probabilistic
              graphs. We establish a connection between our objective function
              and correlation clustering to propose practical approximation
              algorithms for our problem. A benefit of our approach is that our
              objective function is parameter-free. Therefore, the number of
              clusters is part of the output. We also develop methods for testing
              the statistical significance of the output clustering and study the
              case of noisy clusterings. Using a real protein-protein interaction
              network and ground-truth data, we show that our methods discover
              the correct number of clusters and identify established protein
              relationships. Finally, we show the practicality of our techniques
              using a large social network of Yahoo! users consisting of one
              billion edges.},
  keywords = {Approximation algorithms,Approximation methods,clustering
              algorithms,Clustering algorithms,Data mining,Partitioning
              algorithms,probabilistic databases,probabilistic graphs,
              Probabilistic logic,Uncertain data,Uncertainty},
  file = {/Users/matpi832/Zotero/storage/KQRLTK7B/Kollios et al. - 2013 -
          Clustering Large Probabilistic
          Graphs.pdf;/Users/matpi832/Zotero/storage/EY8DIXBS/6095551.html},
}

@article{kozlowskiGeometryCultureAnalyzing2019,
  title = {The {{Geometry}} of {{Culture}}: {{Analyzing}} the {{Meanings}} of {{
           Class}} through {{Word Embeddings}}},
  shorttitle = {The {{Geometry}} of {{Culture}}},
  author = {Kozlowski, Austin C. and Taddy, Matt and Evans, James A.},
  year = {2019},
  month = oct,
  journal = {American Sociological Review},
  volume = {84},
  number = {5},
  pages = {905--949},
  publisher = {{SAGE Publications Inc}},
  issn = {0003-1224},
  doi = {10.1177/0003122419877135},
  urldate = {2023-03-07},
  abstract = {We argue word embedding models are a useful tool for the study of
              culture using a historical analysis of shared understandings of
              social class as an empirical case. Word embeddings represent
              semantic relations between words as relationships between vectors
              in a high-dimensional space, specifying a relational model of
              meaning consistent with contemporary theories of culture.
              Dimensions induced by word differences (rich ? poor) in these
              spaces correspond to dimensions of cultural meaning, and the
              projection of words onto these dimensions reflects widely shared
              associations, which we validate with surveys. Analyzing text from
              millions of books published over 100 years, we show that the
              markers of class continuously shifted amidst the economic
              transformations of the twentieth century, yet the basic cultural
              dimensions of class remained remarkably stable. The notable
              exception is education, which became tightly linked to affluence
              independent of its association with cultivated taste.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/TSIU2ZXC/Kozlowski et al. - 2019 - The
          Geometry of Culture Analyzing the Meanings of.pdf},
}

@book{leeuwenHandbookVisualAnalysis2000,
  title = {The {{Handbook}} of {{Visual Analysis}}},
  author = {Leeuwen, Theo Van and Jewitt, Carey},
  year = {2000},
  month = oct,
  publisher = {{SAGE}},
  abstract = {The Handbook of Visual Analysis is a rich methodological resource
              for students, academics, researchers and professionals interested
              in investigating the visual representation of socially significant
              issues. The Handbook: {$\cdot$} Offers a wide-range of methods for
              visual analysis: content analysis, historical analysis,
              structuralist analysis, iconography, psychoanalysis, social
              semiotic analysis, film analysis and ethnomethodology {$\cdot$}
              Shows how each method can be applied for the purposes of specific
              research projects. {$\cdot$} Exemplifies each approach through
              detailed analyses of a variety of data, including, newspaper images
              , family photos, drawings, art works and cartoons. {$\cdot$}
              Includes examples from the authors{${'}$} own research and
              professional practice. The Handbook of Visual Analysis which
              demonstrates the importance of visual data within the social
              sciences offers an essential guide to those working in a range of
              disciplines including: media and communication studies, sociology,
              anthropology, education, psychoanalysis, and health studies.},
  isbn = {978-1-4462-0537-2},
  langid = {english},
  keywords = {Language Arts \& Disciplines / Communication Studies,Social
              Science / Anthropology / Cultural \& Social,Social Science /
              Popular Culture},
}

@inproceedings{loweObjectRecognitionLocal1999,
  title = {Object Recognition from Local Scale-Invariant Features},
  booktitle = {Proceedings of the {{Seventh IEEE International Conference}} on {
               {Computer Vision}}},
  author = {Lowe, D.G.},
  year = {1999},
  month = sep,
  volume = {2},
  pages = {1150-1157 vol.2},
  doi = {10.1109/ICCV.1999.790410},
  abstract = {An object recognition system has been developed that uses a new
              class of local image features. The features are invariant to image
              scaling, translation, and rotation, and partially invariant to
              illumination changes and affine or 3D projection. These features
              share similar properties with neurons in inferior temporal cortex
              that are used for object recognition in primate vision. Features
              are efficiently detected through a staged filtering approach that
              identifies stable points in scale space. Image keys are created
              that allow for local geometric deformations by representing blurred
              image gradients in multiple orientation planes and at multiple
              scales. The keys are used as input to a nearest neighbor indexing
              method that identifies candidate object matches. Final verification
              of each match is achieved by finding a low residual least squares
              solution for the unknown model parameters. Experimental results
              show that robust object recognition can be achieved in cluttered
              partially occluded images with a computation time of under 2
              seconds.},
  keywords = {Computer science,Electrical capacitance tomography,Filters,Image
              recognition,Layout,Lighting,Neurons,Object recognition,Programmable
              logic arrays,Reactive power},
  file = {/Users/matpi832/Zotero/storage/D5KTQLEN/Lowe - 1999 - Object
          recognition from local scale-invariant feat.pdf},
}

@article{luPervasivePresenceChinese2022,
  title = {The {{Pervasive Presence}} of {{Chinese Government Content}} on {{
           Douyin Trending Videos}}},
  author = {Lu, Yingdan and Pan, Jennifer},
  year = {2022},
  month = feb,
  journal = {Computational Communication Research},
  volume = {4},
  number = {1},
  publisher = {{Amsterdam University Press}},
  issn = {2665-9085},
  doi = {10.5117/CCR2022.2.002.LU},
  urldate = {2023-03-01},
  abstract = {Abstract As audiences have moved to digital media, so too have
              governments around the world. While previous research has focused
              on how authoritarian regimes employ strategies such as the use of
              fabricated accounts and content to boost their reach, this paper
              reveals two different tactics the Chinese government uses on Douyin
              , the Chinese version of the video-sharing platform TikTok, to
              compete for audience attention. We use a multi-modal approach that
              combines analysis of video, text, and meta-data to examine a novel
              dataset of Douyin videos. We find that a large share of trending
              videos are produced by accounts affiliated with the Chinese
              government. These videos contain visual characteristics designed to
              maximize attention such as high levels of brightness and entropy
              and very short duration, and are more visually similar to content
              produced by celebrities and ordinary users than to content from
              non-official media accounts. We also find that the majority of
              videos produced by regime-affiliated accounts do not fit
              traditional definitions of propaganda but rather contain stories
              and topics unrelated to any aspect of the government, the Chinese
              Communist Party, policies, or politics.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/VMNLESC9/CCR2022.2.002.html},
}

@misc{MachineLearningPredictions,
  title = {Machine {{Learning Predictions}} as {{Regression Covariates}} | {{
           Political Analysis}} | {{Cambridge Core}}},
  urldate = {2023-03-08},
  howpublished = {
                  https://www.cambridge.org/core/journals/political-analysis/article/abs/machine-learning-predictions-as-regression-covariates/462A74A46A97C20A17CF640BDA72B826
                  },
  file = {
          /Users/matpi832/Zotero/storage/TG57WGJY/462A74A46A97C20A17CF640BDA72B826.html
          },
}

@inproceedings{manikondaModelingUnderstandingVisual2017a,
  title = {Modeling and {{Understanding Visual Attributes}} of {{Mental Health
           Disclosures}} in {{Social Media}}},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}}
               in {{Computing Systems}}},
  author = {Manikonda, Lydia and De Choudhury, Munmun},
  year = {2017},
  month = may,
  pages = {170--181},
  publisher = {{ACM}},
  address = {{Denver Colorado USA}},
  doi = {10.1145/3025453.3025932},
  urldate = {2023-03-21},
  abstract = {Content shared on social media platforms has been identified to be
              valuable in gaining insights into people's mental health
              experiences. Although there has been widespread adoption of
              photo-sharing platforms such as Instagram in recent years, the role
              of visual imagery as a mechanism of self-disclosure is less
              understood. We study the nature of visual attributes manifested in
              images relating to mental health disclosures on Instagram.
              Employing computer vision techniques on a corpus of thousands of
              posts, we extract and examine three visual attributes: visual
              features (e.g., color), themes, and emotions in images. Our
              findings indicate the use of imagery for unique self-disclosure
              needs, quantitatively and qualitatively distinct from those shared
              via the textual modality: expressions of emotional distress, calls
              for help, and explicit display of vulnerability. We discuss the
              relationship of our findings to literature in visual sociology, in
              mental health self-disclosure, and implications for the design of
              health interventions.},
  isbn = {978-1-4503-4655-9},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/9AJ5AMZD/Manikonda and De Choudhury -
          2017 - Modeling and Understanding Visual Attributes of Me.pdf},
}

@article{nelsonComputationalGroundedTheory2020,
  title = {Computational {{Grounded Theory}}: {{A Methodological Framework}}},
  shorttitle = {Computational {{Grounded Theory}}},
  author = {Nelson, Laura K.},
  year = {2020},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {49},
  number = {1},
  pages = {3--42},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124117729703},
  urldate = {2023-03-21},
  abstract = {This article proposes a three-step methodological framework called
              computational grounded theory, which combines expert human
              knowledge and hermeneutic skills with the processing power and
              pattern recognition of computers, producing a more methodologically
              rigorous but interpretive approach to content analysis. The first,
              pattern detection step, involves inductive computational
              exploration of text, using techniques such as unsupervised machine
              learning and word scores to help researchers to see novel patterns
              in their data. The second, pattern refinement step, returns to an
              interpretive engagement with the data through qualitative deep
              reading or further exploration of the data. The third, pattern
              confirmation step, assesses the inductively identified patterns
              using further computational and natural language processing
              techniques. The result is an efficient, rigorous, and fully
              reproducible computational grounded theory. This framework can be
              applied to any qualitative text as data, including transcribed
              speeches, interviews, open-ended survey data, or ethnographic field
              notes, and can address many potential research questions.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/LPTAY962/Nelson - 2020 - Computational
          Grounded Theory A Methodological Fr.pdf},
}

@article{nelsonFutureCodingComparison2021,
  title = {The {{Future}} of {{Coding}}: {{A Comparison}} of {{Hand-Coding}} and
           {{Three Types}} of {{Computer-Assisted Text Analysis Methods}}},
  shorttitle = {The {{Future}} of {{Coding}}},
  author = {Nelson, Laura K. and Burk, Derek and Knudsen, Marcel and McCall,
            Leslie},
  year = {2021},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {50},
  number = {1},
  pages = {202--237},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124118769114},
  urldate = {2023-03-21},
  abstract = {Advances in computer science and computational linguistics have
              yielded new, and faster, computational approaches to structuring
              and analyzing textual data. These approaches perform well on tasks
              like information extraction, but their ability to identify complex,
              socially constructed, and unsettled theoretical concepts?a central
              goal of sociological content analysis?has not been tested. To fill
              this gap, we compare the results produced by three common
              computer-assisted approaches?dictionary, supervised machine
              learning (SML), and unsupervised machine learning?to those produced
              through a rigorous hand-coding analysis of inequality in the news
              (N = 1,253 articles). Although we find that SML methods perform
              best in replicating hand-coded results, we document and clarify the
              strengths and weaknesses of each approach, including how they can
              complement one another. We argue that content analysts in the
              social sciences would do well to keep all these approaches in their
              toolkit, deploying them purposefully according to the task at hand.
              },
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/76E5283T/Nelson et al. - 2021 - The
          Future of Coding A Comparison of Hand-Coding .pdf},
}

@inproceedings{ngBotBasedEmotionBehavior2021,
  title = {Bot-{{Based Emotion Behavior Differences}} in {{Images During Kashmir
           Black Day Event}}},
  booktitle = {Social, {{Cultural}}, and {{Behavioral Modeling}}},
  author = {Ng, Lynnette Hui Xian and Carley, Kathleen M.},
  editor = {Thomson, Robert and Hussain, Muhammad Nihal and Dancy, Christopher
            and Pyke, Aryn},
  year = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {184--194},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-80387-2_18},
  abstract = {A picture speaks a thousand words. Images are extremely effective
              at evoking emotions and presents a potentially damaging force to
              the health of digital discourse. While text-based emotion analysis
              has been studied, little work has examined the emotions images
              invoke on social media platforms. This work analyzes bot-based
              emotion behavior differences in the images surrounding the 2020
              Kashmir Black Day event. Through Twitter data, we observed at least
              half the agents in the conversation are bots, which dominate image
              conversations calling for action, e.g. ``Be The Voice of Kashmir''.
              Sadness and trust dominates the emotions in images. We further
              analyze a sub-dataset as a case study and discern the role of
              digital media in heightening online conflicts.},
  isbn = {978-3-030-80387-2},
  langid = {english},
  keywords = {Bot analysis,Emotion analysis,Social cybersecurity},
  file = {/Users/matpi832/Zotero/storage/VC2LYGYP/Ng and Carley - 2021 -
          Bot-Based Emotion Behavior Differences in Images D.pdf},
}

@misc{ngCoordinatedAWebImages2022,
  title = {Coordinated through {{aWeb}} of {{Images}}: {{Analysis}} of {{
           Image-based Influence Operations}} from {{China}}, {{Iran}}, {{Russia}
           }, and {{Venezuela}}},
  shorttitle = {Coordinated through {{aWeb}} of {{Images}}},
  author = {Ng, Lynnette Hui Xian and Moffitt, J. D. and Carley, Kathleen M.},
  year = {2022},
  month = jun,
  number = {arXiv:2206.03576},
  eprint = {2206.03576},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.03576},
  urldate = {2023-03-01},
  abstract = {State-sponsored online influence operations typically consist of
              coordinated accounts exploiting the online space to influence
              public opinion. Accounts associated with these operations use
              images and memes as part of their content generation and
              dissemination strategy to increase the effectiveness and engagement
              of the content. In this paper, we present a study of images from
              the PhoMemes 2022 Challenge originating from the countries China,
              Iran, Russia, and Venezuela. First, we analyze the coordination of
              images within and across each country by quantifying image
              similarity. Then, we construct Image-Image networks and image
              clusters to identify key themes in the image influence operations.
              We derive the corresponding Account-Account networks to visualize
              the interaction between participating accounts within each country.
              Finally, we interpret the image content and network structure in
              the broader context of the organization and structure of influence
              operations in each country.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Social and Information Networks},
  file = {/Users/matpi832/Zotero/storage/8T3NFIZQ/Ng et al. - 2022 - Coordinated
          through aWeb of Images Analysis of
          Im.pdf;/Users/matpi832/Zotero/storage/JAPG5UQN/2206.html},
}

@misc{PapersCodeHateCLIPper,
  title = {Papers with {{Code}} - {{Hate-CLIPper}}: {{Multimodal Hateful Meme
           Classification}} Based on {{Cross-modal Interaction}} of {{CLIP
           Features}}},
  shorttitle = {Papers with {{Code}} - {{Hate-CLIPper}}},
  urldate = {2023-03-07},
  abstract = {üèÜ SOTA for Meme Classification on Tamil Memes (Micro-F1 metric)},
  howpublished = {
                  https://paperswithcode.com/paper/hate-clipper-multimodal-hateful-meme
                  },
  langid = {english},
  file = {
          /Users/matpi832/Zotero/storage/MUNI4RG2/hate-clipper-multimodal-hateful-meme.html
          },
}

@inproceedings{parkImprovingUnsupervisedImage2021,
  title = {Improving {{Unsupervised Image Clustering With Robust Learning}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer
               Vision}} and {{Pattern Recognition}}},
  author = {Park, Sungwon and Han, Sungwon and Kim, Sundong and Kim, Danu and
            Park, Sungkyu and Hong, Seunghoon and Cha, Meeyoung},
  year = {2021},
  pages = {12278--12287},
  urldate = {2023-03-17},
  langid = {english},
}

@article{peelStatisticalInferenceLinks2022,
  title = {Statistical Inference Links Data and Theory in Network Science},
  author = {Peel, Leto and Peixoto, Tiago P. and De Domenico, Manlio},
  year = {2022},
  month = nov,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {6794},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-34267-9},
  urldate = {2023-02-27},
  abstract = {Abstract The number of network science applications across many
              different fields has been rapidly increasing. Surprisingly, the
              development of theory and domain-specific applications often occur
              in isolation, risking an effective disconnect between theoretical
              and methodological advances and the way network science is employed
              in practice. Here we address this risk constructively, discussing
              good practices to guarantee more successful applications and
              reproducible results. We endorse designing statistically grounded
              methodologies to address challenges in network science. This
              approach allows one to explain observational data in terms of
              generative models, naturally deal with intrinsic uncertainties, and
              strengthen the link between theory and applications.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/VVLMYISG/Peel et al. - 2022 -
          Statistical inference links data and theory in net.pdf},
}

@article{pengWhatMakesPoliticians2021,
  title = {What {{Makes Politicians}}' {{Instagram Posts Popular}}? {{Analyzing
           Social Media Strategies}} of {{Candidates}} and {{Office Holders}}
           with {{Computer Vision}}},
  shorttitle = {What {{Makes Politicians}}' {{Instagram Posts Popular}}?},
  author = {Peng, Yilang},
  year = {2021},
  month = jan,
  journal = {The International Journal of Press/Politics},
  volume = {26},
  number = {1},
  pages = {143--166},
  publisher = {{SAGE Publications Inc}},
  issn = {1940-1612},
  doi = {10.1177/1940161220964769},
  urldate = {2023-03-01},
  abstract = {Previous research on the success of politicians? messages on
              social media has so far focused on a limited number of platforms,
              especially Facebook and Twitter, and predominately studied the
              effects of textual content. This research reported here applies
              computer vision analysis to a total of 59,020 image posts published
              by 172 Instagram accounts of U.S. politicians, both candidates and
              office holders, and examines how visual attributes influence
              audience engagement such as likes and comments. In particular, this
              study introduces an unsupervised approach that combines transfer
              learning and clustering techniques to discover hidden categories
              from large-scale visual data. The results reveal that different
              self-personalization strategies in visual media, for example,
              images featuring politicians in private, nonpolitical settings,
              showing faces, and displaying emotions, generally increase audience
              engagement. Yet, a significant portion of politician?s Instagram
              posts still fell into the traditional, ?politics-as-usual? type of
              political communication, showing professional settings and
              activities. The analysis explains how self-personalization is
              embodied in specific visual portrayals and how different
              self-presentation strategies affect audience engagement on a
              popular but less studied social media platform.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/Q8KA5H7W/Peng - 2021 - What Makes
          Politicians‚Äô Instagram Posts Popular A.pdf},
}

@inproceedings{perozziDeepWalkOnlineLearning2014,
  title = {{{DeepWalk}}: {{Online Learning}} of {{Social Representations}}},
  shorttitle = {{{DeepWalk}}},
  booktitle = {Proceedings of the 20th {{ACM SIGKDD}} International Conference
               on {{Knowledge}} Discovery and Data Mining},
  author = {Perozzi, Bryan and {Al-Rfou}, Rami and Skiena, Steven},
  year = {2014},
  month = aug,
  eprint = {1403.6652},
  primaryclass = {cs},
  pages = {701--710},
  doi = {10.1145/2623330.2623732},
  urldate = {2023-03-02},
  abstract = {We present DeepWalk, a novel approach for learning latent
              representations of vertices in a network. These latent
              representations encode social relations in a continuous vector
              space, which is easily exploited by statistical models. DeepWalk
              generalizes recent advancements in language modeling and
              unsupervised feature learning (or deep learning) from sequences of
              words to graphs. DeepWalk uses local information obtained from
              truncated random walks to learn latent representations by treating
              walks as the equivalent of sentences. We demonstrate DeepWalk's
              latent representations on several multi-label network
              classification tasks for social networks such as BlogCatalog,
              Flickr, and YouTube. Our results show that DeepWalk outperforms
              challenging baselines which are allowed a global view of the
              network, especially in the presence of missing information.
              DeepWalk's representations can provide \$F\_1\$ scores up to 10\%
              higher than competing methods when labeled data is sparse. In some
              experiments, DeepWalk's representations are able to outperform all
              baseline methods while using 60\% less training data. DeepWalk is
              also scalable. It is an online learning algorithm which builds
              useful incremental results, and is trivially parallelizable. These
              qualities make it suitable for a broad class of real world
              applications such as network classification, and anomaly detection.
              },
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and
              Information Networks,H.2.8,I.2.6,I.5.1},
  file = {/Users/matpi832/Zotero/storage/7TC6SEDL/Perozzi et al. - 2014 -
          DeepWalk Online Learning of Social
          Representation.pdf;/Users/matpi832/Zotero/storage/BP5X5RCJ/1403.html},
}

@misc{quEvolutionHatefulMemes2022,
  title = {On the {{Evolution}} of ({{Hateful}}) {{Memes}} by {{Means}} of {{
           Multimodal Contrastive Learning}}},
  author = {Qu, Yiting and He, Xinlei and Pierson, Shannon and Backes, Michael
            and Zhang, Yang and Zannettou, Savvas},
  year = {2022},
  month = dec,
  number = {arXiv:2212.06573},
  eprint = {2212.06573},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.06573},
  urldate = {2023-03-01},
  abstract = {The dissemination of hateful memes online has adverse effects on
              social media platforms and the real world. Detecting hateful memes
              is challenging, one of the reasons being the evolutionary nature of
              memes; new hateful memes can emerge by fusing hateful connotations
              with other cultural ideas or symbols. In this paper, we propose a
              framework that leverages multimodal contrastive learning models, in
              particular OpenAI's CLIP, to identify targets of hateful content
              and systematically investigate the evolution of hateful memes. We
              find that semantic regularities exist in CLIP-generated embeddings
              that describe semantic relationships within the same modality
              (images) or across modalities (images and text). Leveraging this
              property, we study how hateful memes are created by combining
              visual elements from multiple images or fusing textual information
              with a hateful image. We demonstrate the capabilities of our
              framework for analyzing the evolution of hateful memes by focusing
              on antisemitic memes, particularly the Happy Merchant meme. Using
              our framework on a dataset extracted from 4chan, we find 3.3K
              variants of the Happy Merchant meme, with some linked to specific
              countries, persons, or organizations. We envision that our
              framework can be used to aid human moderators by flagging new
              variants of hateful memes so that moderators can manually verify
              them and mitigate the problem of hateful content online.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computers and Society,Computer Science -
              Cryptography and Security,Computer Science - Machine Learning,
              Computer Science - Social and Information Networks},
  file = {/Users/matpi832/Zotero/storage/MQI5ABP6/Qu et al. - 2022 - On the
          Evolution of (Hateful) Memes by Means of
          Mu.pdf;/Users/matpi832/Zotero/storage/5LU8DFIP/2212.html},
}

@article{quinnHowAnalyzePolitical2010,
  title = {How to {{Analyze Political Attention}} with {{Minimal Assumptions}}
           and {{Costs}}},
  author = {Quinn, Kevin M. and Monroe, Burt L. and Colaresi, Michael and
            Crespin, Michael H. and Radev, Dragomir R.},
  year = {2010},
  journal = {American Journal of Political Science},
  volume = {54},
  number = {1},
  pages = {209--228},
  issn = {1540-5907},
  doi = {10.1111/j.1540-5907.2009.00427.x},
  urldate = {2023-03-22},
  abstract = {Previous methods of analyzing the substance of political attention
              have had to make several restrictive assumptions or been
              prohibitively costly when applied to large-scale political texts.
              Here, we describe a topic model for legislative speech, a
              statistical learning model that uses word choices to infer topical
              categories covered in a set of speeches and to identify the topic
              of specific speeches. Our method estimates, rather than assumes,
              the substance of topics, the keywords that identify topics, and the
              hierarchical nesting of topics. We use the topic model to examine
              the agenda in the U.S. Senate from 1997 to 2004. Using a new
              database of over 118,000 speeches (70,000,000 words) from the
              Congressional Record, our model reveals speech topic categories
              that are both distinctive and meaningfully interrelated and a
              richer view of democratic agenda dynamics than had previously been
              possible.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/4FKILV46/Quinn et al. - 2010 - How to
          Analyze Political Attention with Minimal
          As.pdf;/Users/matpi832/Zotero/storage/78WFD9DE/j.1540-5907.2009.00427.html
          },
}

@misc{radfordLearningTransferableVisual2021,
  title = {Learning {{Transferable Visual Models From Natural Language
           Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh,
            Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and
            Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger,
            Gretchen and Sutskever, Ilya},
  year = {2021},
  month = feb,
  number = {arXiv:2103.00020},
  eprint = {2103.00020},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2103.00020},
  urldate = {2023-03-02},
  abstract = {State-of-the-art computer vision systems are trained to predict a
              fixed set of predetermined object categories. This restricted form
              of supervision limits their generality and usability since
              additional labeled data is needed to specify any other visual
              concept. Learning directly from raw text about images is a
              promising alternative which leverages a much broader source of
              supervision. We demonstrate that the simple pre-training task of
              predicting which caption goes with which image is an efficient and
              scalable way to learn SOTA image representations from scratch on a
              dataset of 400 million (image, text) pairs collected from the
              internet. After pre-training, natural language is used to reference
              learned visual concepts (or describe new ones) enabling zero-shot
              transfer of the model to downstream tasks. We study the performance
              of this approach by benchmarking on over 30 different existing
              computer vision datasets, spanning tasks such as OCR, action
              recognition in videos, geo-localization, and many types of
              fine-grained object classification. The model transfers
              non-trivially to most tasks and is often competitive with a fully
              supervised baseline without the need for any dataset specific
              training. For instance, we match the accuracy of the original
              ResNet-50 on ImageNet zero-shot without needing to use any of the
              1.28 million training examples it was trained on. We release our
              code and pre-trained model weights at
              https://github.com/OpenAI/CLIP.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,
              Computer Science - Machine Learning},
  file = {/Users/matpi832/Zotero/storage/ERIAH6BG/Radford et al. - 2021 -
          Learning Transferable Visual Models From Natural
          L.pdf;/Users/matpi832/Zotero/storage/PC7NKNLA/Radford et al. - 2021 -
          Learning Transferable Visual Models From Natural
          L.pdf;/Users/matpi832/Zotero/storage/LJR65YF3/2103.html},
}

@article{ralundMeasurementErrorModel2022,
  title = {Measurement Error and Model Instability in Automated Text Analysis:
           The Case of Topic Models},
  shorttitle = {Measurement Error and Model Instability in Automated Text
                Analysis},
  author = {Ralund, Snorre and Carlsen, Hjalmar Bang and Klemmensen, Robert and
            Lassen, David Dreyer},
  year = {2022},
  publisher = {{SocArXiv}},
  file = {/Users/matpi832/Zotero/storage/Z9WRGUGD/Ralund et al. - 2022 -
          Measurement error and model instability in automat.pdf},
}

@article{robertsStmPackageStructural2019,
  title = {Stm: {{An R Package}} for {{Structural Topic Models}}},
  shorttitle = {Stm},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
  year = {2019},
  month = oct,
  journal = {Journal of Statistical Software},
  volume = {91},
  pages = {1--40},
  issn = {1548-7660},
  doi = {10.18637/jss.v091.i02},
  urldate = {2023-03-03},
  abstract = {This paper demonstrates how to use the R package stm for
              structural topic modeling. The structural topic model allows
              researchers to flexibly estimate a topic model that includes
              document-level metadata. Estimation is accomplished through a fast
              variational approximation. The stm package provides many useful
              features, including rich ways to explore topics, estimate
              uncertainty, and visualize quantities of interest.},
  copyright = {Copyright (c) 2019 Margaret E. Roberts, Brandon M. Stewart,
               Dustin Tingley},
  langid = {english},
  keywords = {LDA,R,stm,structural topic model,text analysis},
  file = {/Users/matpi832/Zotero/storage/CLKT4XXB/Roberts et al. - 2019 - stm An
          R Package for Structural Topic Models.pdf},
}

@article{robertsStructuralTopicModels2014,
  title = {Structural {{Topic Models}} for {{Open-Ended Survey Responses}}},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin and
            Lucas, Christopher and {Leder-Luis}, Jetson and Gadarian, Shana
            Kushner and Albertson, Bethany and Rand, David G.},
  year = {2014},
  journal = {American Journal of Political Science},
  volume = {58},
  number = {4},
  pages = {1064--1082},
  issn = {1540-5907},
  doi = {10.1111/ajps.12103},
  urldate = {2023-03-08},
  abstract = {Collection and especially analysis of open-ended survey responses
              are relatively rare in the discipline and when conducted are almost
              exclusively done through human coding. We present an alternative,
              semiautomated approach, the structural topic model (STM) (Roberts,
              Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on
              recent developments in machine learning based analysis of textual
              data. A crucial contribution of the method is that it incorporates
              information about the document, such as the author's gender,
              political affiliation, and treatment assignment (if an experimental
              study). This article focuses on how the STM is helpful for survey
              researchers and experimentalists. The STM makes analyzing
              open-ended responses easier, more revealing, and capable of being
              used to estimate treatment effects. We illustrate these innovations
              with analysis of text from surveys and experiments.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/SUZZ8LTI/Roberts et al. - 2014 -
          Structural Topic Models for Open-Ended Survey
          Resp.pdf;/Users/matpi832/Zotero/storage/NKI7L9PW/ajps.html},
}

@article{rousseeuwSilhouettesGraphicalAid1987,
  title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and Validation
           of Cluster Analysis},
  shorttitle = {Silhouettes},
  author = {Rousseeuw, Peter J.},
  year = {1987},
  month = nov,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {20},
  pages = {53--65},
  issn = {0377-0427},
  doi = {10.1016/0377-0427(87)90125-7},
  urldate = {2023-03-09},
  abstract = {A new graphical display is proposed for partitioning techniques.
              Each cluster is represented by a so-called silhouette, which is
              based on the comparison of its tightness and separation. This
              silhouette shows which objects lie well within their cluster, and
              which ones are merely somewhere in between clusters. The entire
              clustering is displayed by combining the silhouettes into a single
              plot, allowing an appreciation of the relative quality of the
              clusters and an overview of the data configuration. The average
              silhouette width provides an evaluation of clustering validity, and
              might be used to select an `appropriate' number of clusters.},
  langid = {english},
  keywords = {classification,cluster analysis,clustering validity,Graphical
              display},
  file = {/Users/matpi832/Zotero/storage/JEVR47DS/Rousseeuw - 1987 - Silhouettes
          A graphical aid to the
          interpretation.pdf;/Users/matpi832/Zotero/storage/CGX7GK9M/0377042787901257.html
          },
}

@article{ruleLexicalShiftsSubstantive2015,
  title = {Lexical Shifts, Substantive Changes, and Continuity in {{State}} of
           the {{Union}} Discourse, 1790\textendash 2014},
  author = {Rule, Alix and Cointet, Jean-Philippe and Bearman, Peter S.},
  year = {2015},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {112},
  number = {35},
  pages = {10837--10844},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1512221112},
  urldate = {2023-03-02},
  abstract = {This study reveals that the entry into World War I in 1917 indexed
              the decisive transition to the modern period in American political
              consciousness, ushering in new objects of political discourse, a
              more rapid pace of change of those objects, and a fundamental
              reframing of the main tasks of governance. We develop a strategy
              for identifying meaningful categories in textual corpora that span
              long historic dur\'ees, where terms, concepts, and language use
              changes. Our approach is able to account for the fluidity of
              discursive categories over time, and to analyze their continuity by
              identifying the discursive stream as the object of interest.},
  file = {/Users/matpi832/Zotero/storage/H9UFJ4XX/Rule et al. - 2015 - Lexical
          shifts, substantive changes, and continuit.pdf},
}

@article{russakovskyImageNetLargeScale2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and
            Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy,
            Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander
            C. and {Fei-Fei}, Li},
  year = {2015},
  month = dec,
  journal = {International Journal of Computer Vision},
  volume = {115},
  number = {3},
  pages = {211--252},
  issn = {1573-1405},
  doi = {10.1007/s11263-015-0816-y},
  urldate = {2023-03-22},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a
              benchmark in object category classification and detection on
              hundreds of object categories and millions of images. The challenge
              has been run annually from 2010 to present, attracting
              participation from more than fifty institutions. This paper
              describes the creation of this benchmark dataset and the advances
              in object recognition that have been possible as a result. We
              discuss the challenges of collecting large-scale ground truth
              annotation, highlight key breakthroughs in categorical object
              recognition, provide a detailed analysis of the current state of
              the field of large-scale image classification and object detection,
              and compare the state-of-the-art computer vision accuracy with
              human accuracy. We conclude with lessons learned in the 5~years of
              the challenge, and propose future directions and improvements.},
  langid = {english},
  keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
}

@misc{schwemmerAutomatedImageAnalysis2022,
  title = {Automated {{Image Analysis}} for {{Studying Online Behaviour}}},
  author = {Schwemmer, Carsten and Unger, Sa{\"i}d and Heiberger, Raphael},
  year = {2022},
  month = apr,
  publisher = {{SocArXiv}},
  doi = {10.31235/osf.io/t62sd},
  urldate = {2023-03-01},
  abstract = {Digitization led to an enormous increase in the availability of
              visual data. As images are an important aspect of human
              communication, decades of social science research have analysed
              images, yet in mostly manual fashion with limited scaling
              capacities. In this work, we outline how recent advances in
              computer vision enable automated image analysis, allowing
              researchers to further unlock the potential of digital behavioural
              data. We introduce the field of computational social science and
              conduct a literature review of early studies using image
              recognition. We also highlight important aspects to be considered,
              such as computational demands and biases of computer vision models.
              Furthermore, in a case study, we examine the online behaviour of
              U.S. Members of Congress during the early COVID-19 pandemic in
              2020. In particular, we focus on sharing images showing face masks
              as they are a crucial aspect of health and safety measures during
              the pandemic. Using Instagram data and models for detecting face
              masks, we find that temporal dynamics and party affiliation play a
              substantial role in the likelihood of sharing images of people
              wearing face masks: images with masks are more often posted after
              the introduction of mask mandates and Democratic party members are
              more likely to share images with masks. In addition, we find
              somewhat weaker to no differences regarding the age and gender of
              politicians.},
  langid = {american},
  keywords = {Social and Behavioral Sciences,Sociology},
  file = {/Users/matpi832/Zotero/storage/GYBDIAUS/Schwemmer et al. - 2022 -
          Automated Image Analysis for Studying Online Behav.pdf},
}

@inproceedings{terragniOCTISComparingOptimizing2021,
  title = {{{OCTIS}}: {{Comparing}} and {{Optimizing Topic}} Models Is {{Simple}
           }!},
  shorttitle = {{{OCTIS}}},
  booktitle = {Proceedings of the 16th {{Conference}} of the {{European Chapter}
               } of the {{Association}} for {{Computational Linguistics}}: {{
               System Demonstrations}}},
  author = {Terragni, Silvia and Fersini, Elisabetta and Galuzzi, Bruno Giovanni
            and Tropeano, Pietro and Candelieri, Antonio},
  year = {2021},
  month = apr,
  pages = {263--270},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.eacl-demos.31},
  urldate = {2023-03-21},
  abstract = {In this paper, we present OCTIS, a framework for training,
              analyzing, and comparing Topic Models, whose optimal
              hyper-parameters are estimated using a Bayesian Optimization
              approach. The proposed solution integrates several state-of-the-art
              topic models and evaluation metrics. These metrics can be targeted
              as objective by the underlying optimization procedure to determine
              the best hyper-parameter configuration. OCTIS allows researchers
              and practitioners to have a fair comparison between topic models of
              interest, using several benchmark datasets and well-known
              evaluation metrics, to integrate novel algorithms, and to have an
              interactive visualization of the results for understanding the
              behavior of each model. The code is available at the following
              link: https://github.com/MIND-Lab/OCTIS.},
}

@article{torresLearningSeeConvolutional2022,
  title = {Learning to {{See}}: {{Convolutional Neural Networks}} for the {{
           Analysis}} of {{Social Science Data}}},
  shorttitle = {Learning to {{See}}},
  author = {Torres, Michelle and Cant{\'u}, Francisco},
  year = {2022},
  month = jan,
  journal = {Political Analysis},
  volume = {30},
  number = {1},
  pages = {113--131},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2021.9},
  urldate = {2023-03-08},
  abstract = {We provide an introduction of the functioning, implementation, and
              challenges of convolutional neural networks (CNNs) to classify
              visual information in social sciences. This tool can help scholars
              to make more efficient the tedious task of classifying images and
              extracting information from them. We illustrate the implementation
              and impact of this methodology by coding handwritten information
              from vote tallies. Our paper not only demonstrates the
              contributions of CNNs to both scholars and policy practitioners,
              but also presents the practical challenges and limitations of the
              method, providing advice on how to deal with these issues.},
  langid = {english},
  keywords = {computer vision,deep learning,Image analysis,neural network},
  file = {/Users/matpi832/Zotero/storage/PYBK4KQB/Torres and Cant√∫ - 2022 -
          Learning to See Convolutional Neural Networks for.pdf},
}

@article{uppalaContagionConfoundingCausality2023,
  title = {Contagion, {{Confounding}}, and {{Causality}}: {{Confronting}} the {{
           Three C}}'s of {{Observational Political Networks Research}}},
  shorttitle = {Contagion, {{Confounding}}, and {{Causality}}},
  author = {Uppala, Medha and Desmarais, Bruce A.},
  year = {2023},
  month = jan,
  journal = {Political Analysis},
  pages = {1--8},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2022.35},
  urldate = {2023-03-02},
  abstract = {Contagion across various types of connections is a central process
              in the study of many political phenomena (e.g., democratization,
              civil conflict, and voter turnout). Over the last decade, the
              methodological literature addressing the challenges in causally
              identifying contagion in networks has exploded. In one of the
              foundational works in this literature, Shalizi and Thomas (2011,
              Sociological Methods and Research 40, 211\textendash 239.) propose
              a permutation test for contagion in longitudinal network data that
              is not confounded by selection (e.g., homophily). We illustrate the
              properties of this test via simulation. We assess its statistical
              power under various conditions of the data, including the nature of
              the contagion, the structure of the network through which contagion
              occurs, and the number of time periods included in the data. We
              then apply this test to an example domain that is commonly
              considered in the context of observational research on contagion
              \textemdash the international spread of democracy. We find evidence
              of international contagion of democracy. We conclude with a
              discussion of the practical applicability of the Shalizi and Thomas
              test to the study of contagion in political networks.},
  langid = {english},
  keywords = {contagion,homophily,social networks},
  file = {/Users/matpi832/Zotero/storage/UF2CTHAD/Uppala and Desmarais - 2023 -
          Contagion, Confounding, and Causality Confronting.pdf},
}

@article{waggonerUnsupervisedMachineLearning2020,
  title = {Unsupervised {{Machine Learning}} for {{Clustering}} in {{Political}}
           and {{Social Research}}},
  author = {Waggoner, Philip D.},
  year = {2020},
  month = dec,
  journal = {Elements in Quantitative and Computational Methods for the Social
             Sciences},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108883955},
  urldate = {2023-03-21},
  abstract = {Cambridge Core - Research Methods In Politics - Unsupervised
              Machine Learning for Clustering in Political and Social Research},
  isbn = {9781108883955 9781108793384},
  langid = {english},
  file = {
          /Users/matpi832/Zotero/storage/3GHHXRBK/BF62D1E8F6DB3237D5CE524FBFCBA33A.html
          },
}

@article{wangCVAPValidationCluster2009,
  title = {{{CVAP}}: {{Validation}} for {{Cluster Analyses}}},
  shorttitle = {{{CVAP}}},
  author = {Wang, Kaijun and Wang, Baijie and Peng, Liuqing},
  year = {2009},
  journal = {Data Science Journal},
  volume = {8},
  pages = {88--93},
  doi = {10.2481/dsj.007-020},
  abstract = {Evaluation of clustering results (or cluster validation) is an
              important and necessary step in cluster analysis, but it is often
              time-consuming and complicated work. We present a visual cluster
              validation tool, the Cluster Validity Analysis Platform (CVAP), to
              facilitate cluster validation. The CVAP provides necessary methods
              (e.g., many validity indices, several clustering algorithms and
              procedures) and an analysis environment for clustering, evaluation
              of clustering results, estimation of the number of clusters, and
              performance comparison among different clustering algorithms. It
              can help users accomplish their clustering tasks faster and easier
              and help achieve good clustering quality when there is little prior
              knowledge about the cluster structure of a data set.},
  keywords = {Cluster validation,Validity indices,Visual cluster analysis
              environment},
  file = {/Users/matpi832/Zotero/storage/3K86PIK5/Wang et al. - 2009 - CVAP
          Validation for Cluster
          Analyses.pdf;/Users/matpi832/Zotero/storage/UJR9TBHY/ja.html},
}

@article{wilkersonLargeScaleComputerizedText2017,
  title = {Large-{{Scale Computerized Text Analysis}} in {{Political Science}}:
           {{Opportunities}} and {{Challenges}}},
  shorttitle = {Large-{{Scale Computerized Text Analysis}} in {{Political
                Science}}},
  author = {Wilkerson, John and Casas, Andreu},
  year = {2017},
  journal = {Annual Review of Political Science},
  volume = {20},
  number = {1},
  pages = {529--544},
  doi = {10.1146/annurev-polisci-052615-025542},
  urldate = {2023-03-08},
  abstract = {Text has always been an important data source in political
              science. What has changed in recent years is the feasibility of
              investigating large amounts of text quantitatively. The internet
              provides political scientists with more data than their mentors
              could have imagined, and the research community is providing
              accessible text analysis software packages, along with training and
              support. As a result, text-as-data research is becoming mainstream
              in political science. Scholars are tapping new data sources, they
              are employing more diverse methods, and they are becoming critical
              consumers of findings based on those methods. In this article, we
              first describe the four stages of a typical text-as-data project.
              We then review recent political science applications and explore
              one important methodological challenge\textemdash topic model
              instability\textemdash in greater detail.},
  keywords = {automatic coding,computational social sciences,machine learning,
              text as data},
  file = {/Users/matpi832/Zotero/storage/83JIAEFW/Wilkerson and Casas - 2017 -
          Large-Scale Computerized Text Analysis in Politica.pdf},
}

@article{williamsImagesDataSocial2020,
  title = {Images as {{Data}} for {{Social Science Research}}: {{An Introduction
           }} to {{Convolutional Neural Nets}} for {{Image Classification}}},
  shorttitle = {Images as {{Data}} for {{Social Science Research}}},
  author = {Williams, Nora Webb and Casas, Andreu and Wilkerson, John D.},
  year = {2020},
  month = jul,
  journal = {Elements in Quantitative and Computational Methods for the Social
             Sciences},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108860741},
  urldate = {2023-03-02},
  abstract = {Cambridge Core - Research Methods in Politics - Images as Data for
              Social Science Research},
  isbn = {9781108860741 9781108816854},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/VKRG8LTS/Williams et al. - 2020 -
          Images as Data for Social Science Research An
          Int.pdf;/Users/matpi832/Zotero/storage/M39DRY2R/0376EE8A7A21F5B47FC4EC24DF07EFE9.html
          },
}

@misc{wortsmanRobustFinetuningZeroshot2022,
  title = {Robust Fine-Tuning of Zero-Shot Models},
  author = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li,
            Mike and Kornblith, Simon and Roelofs, Rebecca and {Gontijo-Lopes},
            Raphael and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong,
            Hongseok and Schmidt, Ludwig},
  year = {2022},
  month = jun,
  number = {arXiv:2109.01903},
  eprint = {2109.01903},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2109.01903},
  urldate = {2023-03-02},
  abstract = {Large pre-trained models such as CLIP or ALIGN offer consistent
              accuracy across a range of data distributions when performing
              zero-shot inference (i.e., without fine-tuning on a specific
              dataset). Although existing fine-tuning methods substantially
              improve accuracy on a given target distribution, they often reduce
              robustness to distribution shifts. We address this tension by
              introducing a simple and effective method for improving robustness
              while fine-tuning: ensembling the weights of the zero-shot and
              fine-tuned models (WiSE-FT). Compared to standard fine-tuning,
              WiSE-FT provides large accuracy improvements under distribution
              shift, while preserving high accuracy on the target distribution.
              On ImageNet and five derived distribution shifts, WiSE-FT improves
              accuracy under distribution shift by 4 to 6 percentage points (pp)
              over prior work while increasing ImageNet accuracy by 1.6 pp.
              WiSE-FT achieves similarly large robustness gains (2 to 23 pp) on a
              diverse set of six further distribution shifts, and accuracy gains
              of 0.8 to 3.3 pp compared to standard fine-tuning on seven commonly
              used transfer learning datasets. These improvements come at no
              additional computational cost during fine-tuning or inference.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,
              Computer Science - Machine Learning},
  file = {/Users/matpi832/Zotero/storage/2EG3Z93L/Wortsman et al. - 2022 -
          Robust fine-tuning of zero-shot
          models.pdf;/Users/matpi832/Zotero/storage/GCXDFUM9/2109.html},
}

@article{xiUnderstandingPoliticalIdeology2020,
  title = {Understanding the {{Political Ideology}} of {{Legislators}} from {{
           Social Media Images}}},
  author = {Xi, Nan and Ma, Di and Liou, Marcus and {Steinert-Threlkeld},
            Zachary C. and Anastasopoulos, Jason and Joo, Jungseock},
  year = {2020},
  month = may,
  journal = {Proceedings of the International AAAI Conference on Web and Social
             Media},
  volume = {14},
  pages = {726--737},
  issn = {2334-0770},
  doi = {10.1609/icwsm.v14i1.7338},
  urldate = {2023-03-02},
  abstract = {In this paper, we seek to understand how politicians use images to
              express ideological rhetoric through Facebook images posted by
              members of the U.S. House and Senate. In the era of social media,
              politics has become saturated with imagery, a potent and
              emotionally salient form of political rhetoric which has been used
              by politicians and political organizations to influence public
              sentiment and voting behavior for well over a century. To date,
              however, little is known about how images are used as political
              rhetoric. Using deep learning techniques to automatically predict
              Republican or Democratic party affiliation solely from the Facebook
              photographs of the members of the 114th U.S. Congress, we
              demonstrate that predicted class probabilities from our model
              function as an accurate proxy of the political ideology of images
              along a left\textendash right (liberal\textendash conservative)
              dimension. After controlling for the gender and race of politicians
              , our method achieves an accuracy of 59.28\% from single
              photographs and 82.35\% when aggregating scores from multiple
              photographs (up to 150) of the same person. To better understand
              image content distinguishing liberal from conservative images, we
              also perform in-depth content analyses of the photographs. Our
              findings suggest that conservatives tend to use more images
              supporting status quo political institutions and hierarchy
              maintenance, featuring individuals from dominant social groups, and
              displaying greater happiness than liberals.},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial
               Intelligence},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/W6BG9B6C/Xi et al. - 2020 -
          Understanding the Political Ideology of Legislator.pdf},
}

@article{zannettouCharacterizingUseImages2020,
  title = {Characterizing the {{Use}} of {{Images}} in {{State-Sponsored
           Information Warfare Operations}} by {{Russian Trolls}} on {{Twitter}}},
  author = {Zannettou, Savvas and Caulfield, Tristan and Bradlyn, Barry and
            Cristofaro, Emiliano De and Stringhini, Gianluca and Blackburn,
            Jeremy},
  year = {2020},
  month = may,
  journal = {Proceedings of the International AAAI Conference on Web and Social
             Media},
  volume = {14},
  pages = {774--785},
  issn = {2334-0770},
  doi = {10.1609/icwsm.v14i1.7342},
  urldate = {2023-03-08},
  abstract = {State-sponsored organizations are increasingly linked to efforts
              aimed to exploit social media for information warfare and
              manipulating public opinion. Typically, their activities rely on a
              number of social network accounts they control, aka trolls, that
              post and interact with other users disguised as ``regular'' users.
              These accounts often use images and memes, along with textual
              content, in order to increase the engagement and the credibility of
              their posts.In this paper, we present the first study of images
              shared by state-sponsored accounts by analyzing a ground truth
              dataset of 1.8M images posted to Twitter by accounts controlled by
              the Russian Internet Research Agency. First, we analyze the content
              of the images as well as their posting activity. Then, using Hawkes
              Processes, we quantify their influence on popular Web communities
              like Twitter, Reddit, 4chan's Politically Incorrect board (/pol/),
              and Gab, with respect to the dissemination of images. We find that
              the extensive image posting activity of Russian trolls coincides
              with real-world events (e.g., the Unite the Right rally in
              Charlottesville), and shed light on their targets as well as the
              content disseminated via images. Finally, we show that the trolls
              were more effective in disseminating politics-related imagery than
              other images.},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial
               Intelligence},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/J6L7VC8K/Zannettou et al. - 2020 -
          Characterizing the Use of Images in State-Sponsore.pdf},
}

@article{zhangFrameworkDeepConstrained2021,
  title = {A Framework for Deep Constrained Clustering},
  author = {Zhang, Hongjing and Zhan, Tianyang and Basu, Sugato and Davidson,
            Ian},
  year = {2021},
  month = mar,
  journal = {Data Mining and Knowledge Discovery},
  volume = {35},
  number = {2},
  pages = {593--620},
  issn = {1573-756X},
  doi = {10.1007/s10618-020-00734-4},
  urldate = {2023-04-24},
  abstract = {The area of constrained clustering has been extensively explored
              by researchers and used by practitioners. Constrained clustering
              formulations exist for popular algorithms such as k-means, mixture
              models, and spectral clustering but have several limitations. A
              fundamental strength of deep learning is its flexibility, and here
              we explore a deep learning framework for constrained clustering and
              in particular explore how it can extend the field of constrained
              clustering. We show that our framework can not only handle standard
              together/apart constraints (without the well documented negative
              effects reported earlier) generated from labeled side information
              but more complex constraints generated from new types of side
              information such as continuous values and high-level domain
              knowledge. Furthermore, we propose an efficient training paradigm
              that is generally applicable to these four types of constraints. We
              validate the effectiveness of our approach by empirical results on
              both image and text datasets. We also study the robustness of our
              framework when learning with noisy constraints and show how
              different components of our framework contribute to the final
              performance. Our source code is available at:
              http://github.com/blueocean92.},
  langid = {english},
  keywords = {Constrained clustering,Deep learning,Representation learning,
              Semi-supervised learning},
  file = {/Users/matpi832/Zotero/storage/A5REE6YH/Zhang et al. - 2021 - A
          framework for deep constrained clustering.pdf},
}

@misc{zhangHowUsingMachine2021,
  title = {How {{Using Machine Learning Classification}} as a {{Variable}} in {{
           Regression Leads}} to {{Attenuation Bias}} and {{What}} to {{Do About
           It}}},
  author = {Zhang, Han},
  year = {2021},
  month = may,
  publisher = {{SocArXiv}},
  doi = {10.31235/osf.io/453jk},
  urldate = {2023-03-08},
  abstract = {Social scientists have increasingly been applying machine learning
              algorithms to "big data" to measure theoretical concepts they
              cannot easily measure before, and then been using these
              machine-predicted variables in a regression. This article first
              demonstrates that directly inserting binary predictions (i.e.,
              classification) without regard for prediction error will generally
              lead to attenuation biases of either slope coefficients or marginal
              effect estimates. We then propose several estimators to obtain
              consistent estimates of coefficients. The estimators require the
              existence of validation data, of which researchers have both
              machine prediction and true values. This validation data is either
              automatically available during training algorithms or can be easily
              obtained. Monte Carlo simulations demonstrate the effectiveness of
              the proposed estimators. Finally, we summarize the usage pattern of
              machine learning predictions in 18 recent publications in top
              social science journals, apply our proposed estimators to two of
              them, and offer some practical recommendations.},
  langid = {american},
  keywords = {Econometrics,Economics,Methodology,Models and Methods,Political
              Science,Social and Behavioral Sciences,Social Statistics,Sociology},
  file = {/Users/matpi832/Zotero/storage/IC7SKJQF/Zhang - 2021 - How Using
          Machine Learning Classification as a Var.pdf},
}

@article{zhangImageClusteringUnsupervised2022,
  title = {Image {{Clustering}}: {{An Unsupervised Approach}} to {{Categorize
           Visual Data}} in {{Social Science Research}}},
  shorttitle = {Image {{Clustering}}},
  author = {Zhang, Han and Peng, Yilang},
  year = {2022},
  month = apr,
  journal = {Sociological Methods \& Research},
  pages = {00491241221082603},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/00491241221082603},
  urldate = {2023-03-01},
  abstract = {Automated image analysis has received increasing attention in
              social scientific research, yet existing scholarship has mostly
              covered the application of supervised learning to classify images
              into predefined categories. This study focuses on the task of
              unsupervised image clustering, which aims to automatically discover
              categories from unlabelled image data. We first review the steps to
              perform image clustering and then focus on one key challenge in
              this task?finding intermediate representations of images. We
              present several methods of extracting intermediate image
              representations, including the bag-of-visual-words model,
              self-supervised learning, and transfer learning (in particular,
              feature extraction with pretrained models). We compare these
              methods using various visual datasets, including images related to
              protests in China from Weibo, images about climate change on
              Instagram, and profile images of the Russian Internet Research
              Agency on Twitter. In addition, we propose a systematic way to
              interpret and validate clustering solutions. Results show that
              transfer learning significantly outperforms the other methods. The
              dataset used in the pretrained model critically determines what
              categories the algorithms can discover.},
  langid = {english},
  file = {/Users/matpi832/Zotero/storage/DKMRGM2L/Zhang and Peng - 2022 - Image
          Clustering An Unsupervised Approach to Cate.pdf},
}
