@article{ahlquistModelbasedClusteringTypologies2012,
            title = {Model-Based {{Clustering}} and {{Typologies}} in the {{
                     Social Sciences}}},
            author = {Ahlquist, John S. and Breunig, Christian},
            year = {2012/ed},
            journal = {Political Analysis},
            volume = {20},
            number = {1},
            pages = {92--112},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1093/pan/mpr039},
            urldate = {2023-03-27},
            abstract = {Social scientists spend considerable energy constructing
                        typologies and discussing their roles in measurement.
                        Less discussed is the role of typologies in evaluating
                        and revising theoretical arguments. We argue that
                        unsupervised machine learning tools can be profitably
                        applied to the development and testing of theory-based
                        typologies. We review recent advances in mixture models
                        as applied to cluster analysis and argue that these tools
                        are particularly important in the social sciences where
                        it is common to claim that high-dimensional objects group
                        together in meaningful clusters. Model-based clustering
                        (MBC) grounds analysis in probability theory, permitting
                        the evaluation of uncertainty and application of
                        information-based model selection tools. We show that the
                        MBC approach forces analysts to consider dimensionality
                        problems that more traditional clustering tools obscure.
                        We apply MBC to the ``varieties of capitalism,'' a
                        typology receiving significant attention in political
                        science and economic sociology. We find weak and
                        conflicting evidence for the theory's expected grouping.
                        We therefore caution against the current practice of
                        including typology-derived dummy variables in regression
                        and case-comparison research designs.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/DMLRJS3M/Ahlquist and Breunig
                    - 2012 - Model-based Clustering and Typologies in the
                    Socia.pdf},
}

@article{ahlquistModelbasedClusteringTypologies2012a,
            title = {Model-Based {{Clustering}} and {{Typologies}} in the {{
                     Social Sciences}}},
            author = {Ahlquist, John S. and Breunig, Christian},
            year = {2012},
            journal = {Political Analysis},
            volume = {20},
            number = {1},
            pages = {92--112},
            issn = {1047-1987, 1476-4989},
            doi = {10.1093/pan/mpr039},
            urldate = {2023-03-29},
            abstract = {Social scientists spend considerable energy constructing
                        typologies and discussing their roles in measurement.
                        Less discussed is the role of typologies in evaluating
                        and revising theoretical arguments. We argue that
                        unsupervised machine learning tools can be profitably
                        applied to the development and testing of theory-based
                        typologies. We review recent advances in mixture models
                        as applied to cluster analysis and argue that these tools
                        are particularly important in the social sciences where
                        it is common to claim that high-dimensional objects group
                        together in meaningful clusters. Model-based clustering
                        (MBC) grounds analysis in probability theory, permitting
                        the evaluation of uncertainty and application of
                        information-based model selection tools. We show that the
                        MBC approach forces analysts to consider dimensionality
                        problems that more traditional clustering tools obscure.
                        We apply MBC to the ``varieties of capitalism,'' a
                        typology receiving significant attention in political
                        science and economic sociology. We find weak and
                        conflicting evidence for the theory's expected grouping.
                        We therefore caution against the current practice of
                        including typology-derived dummy variables in regression
                        and case-comparison research designs.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/R7L7IEFP/Ahlquist and Breunig
                    - 2012 - Model-based Clustering and Typologies in the
                    Socia.pdf},
}

@book{baileyTypologiesTaxonomiesIntroduction1994,
            title = {Typologies and {{Taxonomies}}: {{An Introduction}} to {{
                     Classification Techniques}}},
            shorttitle = {Typologies and {{Taxonomies}}},
            author = {Bailey, Kenneth D.},
            year = {1994},
            month = jun,
            publisher = {{SAGE}},
            abstract = {How do we group different subjects on a variety of
                        variables? Should we use a classification procedure in
                        which only the concepts are classified (typology), one in
                        which only empirical entities are classified (taxonomy),
                        or some combination of both? In this clearly written book
                        , Bailey addresses these questions and shows how
                        classification methods can be used to improve research.
                        Beginning with an exploration of the advantages and
                        disadvantages of classification procedures including
                        those typologies that can be constructed without the use
                        of a computer, the book covers such topics as clustering
                        procedures (including agglomerative and divisive methods)
                        , the relationship among various classification
                        techniques (including the relationship of monothetic,
                        qualitative typologies to polythetic, quantitative
                        taxonomies), a comparison of clustering methods and how
                        these methods compare with related statistical techniques
                        such as factor analysis, multidimensional scaling and
                        systems analysis, and lists classification resources.
                        This volume also discusses software packages for use in
                        clustering techniques.},
            googlebooks = {1TaYulGjhLYC},
            isbn = {978-0-8039-5259-1},
            langid = {english},
            keywords = {Reference / Research,Social Science / Methodology,Social
                        Science / Research},
}

@article{barberaAutomatedTextClassification2021,
            title = {Automated {{Text Classification}} of {{News Articles}}: {{A
                     Practical Guide}}},
            shorttitle = {Automated {{Text Classification}} of {{News Articles}}
                          },
            author = {Barber{\'a}, Pablo and Boydstun, Amber E. and Linn,
                      Suzanna and McMahon, Ryan and Nagler, Jonathan},
            year = {2021},
            month = jan,
            journal = {Political Analysis},
            volume = {29},
            number = {1},
            pages = {19--42},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1017/pan.2020.8},
            urldate = {2023-03-17},
            abstract = {Automated text analysis methods have made possible the
                        classification of large corpora of text by measures such
                        as topic and tone. Here, we provide a guide to help
                        researchers navigate the consequential decisions they
                        need to make before any measure can be produced from the
                        text. We consider, both theoretically and empirically,
                        the effects of such choices using as a running example
                        efforts to measure the tone of New York Times coverage of
                        the economy. We show that two reasonable approaches to
                        corpus selection yield radically different corpora and we
                        advocate for the use of keyword searches rather than
                        predefined subject categories provided by news archives.
                        We demonstrate the benefits of coding using article
                        segments instead of sentences as units of analysis. We
                        show that, given a fixed number of codings, it is better
                        to increase the number of unique documents coded rather
                        than the number of coders for each document. Finally, we
                        find that supervised machine learning algorithms
                        outperform dictionaries on a number of criteria. Overall,
                        we intend this guide to serve as a reminder to analysts
                        that thoughtfulness and human validation are key to
                        text-as-data methods, particularly in an age when it is
                        all too easy to computationally classify texts without
                        attending to the methodological choices therein.},
            langid = {english},
            keywords = {automated content analysis,content analysis,statistical
                        analysis of texts},
            file = {/Users/matpi832/Zotero/storage/ML6P4HRN/Barberá et al. -
                    2021 - Automated Text Classification of News Articles A .pdf},
}

@article{barberaWhoLeadsWho2019,
            title = {Who {{Leads}}? {{Who Follows}}? {{Measuring Issue Attention
                     }} and {{ Agenda Setting}} by {{Legislators}} and the {{Mass
                     Public Using Social Media Data}}},
            shorttitle = {Who {{Leads}}?},
            author = {Barber{\'a}, Pablo and Casas, Andreu and Nagler, Jonathan
                      and Egan, Patrick J. and Bonneau, Richard and Jost, John T.
                      and Tucker, Joshua A.},
            year = {2019},
            month = nov,
            journal = {American Political Science Review},
            volume = {113},
            number = {4},
            pages = {883--901},
            publisher = {{Cambridge University Press}},
            issn = {0003-0554, 1537-5943},
            doi = {10.1017/S0003055419000352},
            urldate = {2023-03-17},
            abstract = {Are legislators responsive to the priorities of the
                        public? Research demonstrates a strong correspondence
                        between the issues about which the public cares and the
                        issues addressed by politicians, but conclusive evidence
                        about who leads whom in setting the political agenda has
                        yet to be uncovered. We answer this question with
                        fine-grained temporal analyses of Twitter messages by
                        legislators and the public during the 113th US Congress.
                        After employing an unsupervised method that classifies
                        tweets sent by legislators and citizens into topics, we
                        use vector autoregression models to explore whose
                        priorities more strongly predict the relationship between
                        citizens and politicians. We find that legislators are
                        more likely to follow, than to lead, discussion of public
                        issues, results that hold even after controlling for the
                        agenda-setting effects of the media. We also find,
                        however, that legislators are more likely to be
                        responsive to their supporters than to the general
                        public.},
            langid = {english},
}

@incollection{basuActiveSemiSupervisionPairwise2004,
            title = {Active {{Semi-Supervision}} for {{Pairwise Constrained
                     Clustering}}},
            booktitle = {Proceedings of the 2004 {{SIAM International Conference
                         }} on {{ Data Mining}} ({{SDM}})},
            author = {Basu, Sugato and Banerjee, Arindam and Mooney, Raymond J.},
            year = {2004},
            month = apr,
            series = {Proceedings},
            pages = {333--344},
            publisher = {{Society for Industrial and Applied Mathematics}},
            doi = {10.1137/1.9781611972740.31},
            urldate = {2023-04-24},
            abstract = {Semi-supervised clustering uses a small amount of
                        supervised data to aid unsupervised learning. One typical
                        approach specifies a limited number of must-link and
                        cannot-link constraints between pairs of examples. This
                        paper presents a pairwise constrained clustering
                        framework and a new method for actively selecting
                        informative pairwise constraints to get improved
                        clustering performance. The clustering and active
                        learning methods are both easily scalable to large
                        datasets, and can handle very high dimensional data.
                        Experimental and theoretical results confirm that this
                        active querying of pairwise constraints significantly
                        improves the accuracy of clustering when given a
                        relatively small amount of supervision.},
            isbn = {978-0-89871-568-2},
}

@inproceedings{basuActiveSemiSupervisionPairwise2004a,
            title = {Active {{Semi-Supervision}} for {{Pairwise Constrained
                     Clustering}}},
            booktitle = {Proceedings of the 2004 {{SIAM International Conference
                         }} on {{ Data Mining}}},
            author = {Basu, Sugato and Banerjee, Arindam and Mooney, Raymond J.},
            year = {2004},
            month = apr,
            pages = {333--344},
            publisher = {{Society for Industrial and Applied Mathematics}},
            doi = {10.1137/1.9781611972740.31},
            urldate = {2023-04-24},
            abstract = {Semi-supervised clustering uses a small amount of
                        supervised data to aid unsupervised learning. One typical
                        approach specifies a limited number of must-link and
                        cannotlink constraints between pairs of examples. This
                        paper presents a pairwise constrained clustering
                        framework and a new method for actively selecting
                        informative pairwise constraints to get improved
                        clustering performance. The clustering and active
                        learning methods are both easily scalable to large
                        datasets, and can handle very high dimensional data.
                        Experimental and theoretical results confirm that this
                        active querying of pairwise constraints significantly
                        improves the accuracy of clustering when given a
                        relatively small amount of supervision.},
            isbn = {978-0-89871-568-2 978-1-61197-274-0},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/A78DVNCV/Basu et al. - 2004 -
                    Active Semi-Supervision for Pairwise Constrained C.pdf},
}

@inproceedings{basuProbabilisticFrameworkSemisupervised2004,
            title = {A Probabilistic Framework for Semi-Supervised Clustering},
            booktitle = {Proceedings of the Tenth {{ACM SIGKDD}} International
                         Conference on {{Knowledge}} Discovery and Data Mining},
            author = {Basu, Sugato and Bilenko, Mikhail and Mooney, Raymond J.},
            year = {2004},
            month = aug,
            series = {{{KDD}} '04},
            pages = {59--68},
            publisher = {{Association for Computing Machinery}},
            address = {{New York, NY, USA}},
            doi = {10.1145/1014052.1014062},
            urldate = {2023-04-24},
            abstract = {Unsupervised clustering can be significantly improved
                        using supervision in the form of pairwise constraints,
                        i.e., pairs of instances labeled as belonging to same or
                        different clusters. In recent years, a number of
                        algorithms have been proposed for enhancing clustering
                        quality by employing such supervision. Such methods use
                        the constraints to either modify the objective function ,
                        or to learn the distance measure. We propose a
                        probabilistic model for semi-supervised clustering based
                        on Hidden Markov Random Fields (HMRFs) that provides a
                        principled framework for incorporating supervision into
                        prototype-based clustering. The model generalizes a
                        previous approach that combines constraints and Euclidean
                        distance learning, and allows the use of a broad range of
                        clustering distortion measures, including Bregman
                        divergences (e.g. , Euclidean distance and I-divergence)
                        and directional similarity measures (e.g., cosine
                        similarity). We present an algorithm that performs
                        partitional semi-supervised clustering of data by
                        minimizing an objective function derived from the
                        posterior energy of the HMRF model. Experimental results
                        on several text data sets demonstrate the advantages of
                        the proposed framework.},
            isbn = {978-1-58113-888-7},
            keywords = {distance metric learning,hidden Markov random fields,
                        semi-supervised clustering},
            file = {/Users/matpi832/Zotero/storage/GRWXX87G/Basu et al. - 2004 -
                    A probabilistic framework for semi-supervised clus.pdf},
}

@article{bilsOverreactingPosturingHow2023,
            title = {Overreacting and {{Posturing}}: {{How Accountability}} and
                     {{Ideology Shape Executive Policies}}},
            shorttitle = {Overreacting and {{Posturing}}},
            author = {Bils, Peter},
            year = {2023},
            month = apr,
            journal = {Quarterly Journal of Political Science},
            volume = {18},
            number = {2},
            publisher = {{Now Publishers, Inc.}},
            issn = {1554-0626, 1554-0634},
            doi = {10.1561/100.00020177},
            urldate = {2023-03-16},
            abstract = {Overreacting and Posturing: How Accountability and
                        Ideology Shape Executive Policies},
            langid = {english},
}

@article{blondelFastUnfoldingCommunities2008,
            title = {Fast Unfolding of Communities in Large Networks},
            author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte
                      , Renaud and Lefebvre, Etienne},
            year = {2008},
            month = oct,
            journal = {Journal of Statistical Mechanics: Theory and Experiment},
            volume = {2008},
            number = {10},
            pages = {P10008},
            issn = {1742-5468},
            doi = {10.1088/1742-5468/2008/10/P10008},
            urldate = {2023-03-22},
            abstract = {We propose a simple method to extract the community
                        structure of large networks. Our method is a heuristic
                        method that is based on modularity optimization. It is
                        shown to outperform all other known community detection
                        methods in terms of computation time. Moreover, the
                        quality of the communities detected is very good, as
                        measured by the so-called modularity. This is shown first
                        by identifying language communities in a Belgian mobile
                        phone network of 2 million customers and by analysing a
                        web graph of 118 million nodes and more than one billion
                        links. The accuracy of our algorithm is also verified on
                        ad hoc modular networks.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/J5CN7TSU/Blondel et al. -
                    2008 - Fast unfolding of communities in large networks.pdf},
}

@article{blondelFastUnfoldingCommunities2008a,
            title = {Fast Unfolding of Communities in Large Networks},
            author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte
                      , Renaud and Lefebvre, Etienne},
            year = {2008},
            month = oct,
            journal = {Journal of Statistical Mechanics: Theory and Experiment},
            volume = {2008},
            number = {10},
            eprint = {0803.0476},
            primaryclass = {cond-mat, physics:physics},
            pages = {P10008},
            issn = {1742-5468},
            doi = {10.1088/1742-5468/2008/10/P10008},
            urldate = {2023-03-22},
            abstract = {We propose a simple method to extract the community
                        structure of large networks. Our method is a heuristic
                        method that is based on modularity optimization. It is
                        shown to outperform all other known community detection
                        method in terms of computation time. Moreover, the
                        quality of the communities detected is very good, as
                        measured by the so-called modularity. This is shown first
                        by identifying language communities in a Belgian mobile
                        phone network of 2.6 million customers and by analyzing a
                        web graph of 118 million nodes and more than one billion
                        links. The accuracy of our algorithm is also verified on
                        ad-hoc modular networks.},
            archiveprefix = {arxiv},
            langid = {english},
            keywords = {Computer Science - Computers and Society,Computer
                        Science - Data Structures and Algorithms,Condensed Matter
                        - Statistical Mechanics, Physics - Physics and Society},
            file = {/Users/matpi832/Zotero/storage/KMU6AQAW/Blondel et al. -
                    2008 - Fast unfolding of communities in large networks.pdf},
}

@article{caiReviewSemisupervisedClustering2023,
            title = {A Review on Semi-Supervised Clustering},
            author = {Cai, Jianghui and Hao, Jing and Yang, Haifeng and Zhao,
                      Xujun and Yang, Yuqing},
            year = {2023},
            month = jun,
            journal = {Information Sciences},
            volume = {632},
            pages = {164--200},
            issn = {0020-0255},
            doi = {10.1016/j.ins.2023.02.088},
            urldate = {2023-04-24},
            abstract = {Semi-supervised clustering (SSC), a technique
                        integrating semi-supervised learning and clustering
                        analysis, incorporates the given prior information (e.g.,
                        class labels and pairwise constraints) into clustering to
                        guide the clustering process and improve the performance.
                        In recent years, a large number of valuable works have
                        emerged, focusing on theoretical research and application
                        in different fields. In this paper, a detailed review of
                        SSC is provided from a new perspective. Firstly, all SSC
                        studies are organized as partition-based SSC,
                        hierarchical-based SSC, density-based SSC, graph-based
                        SSC, neural network-based SSC, Nonnegative Matrix
                        Factorization-based SSC and random subspace
                        technique-based SSC. Thus, the semi-supervised researches
                        can be in-depth discussed in each clustering idea.
                        Secondly, the general overviews are detailed in each
                        category respectively, including the performance, the
                        suitable scenarios and the way to add supervising
                        information. Thirdly, the recent successful applications
                        of SSC are summarized according to different backgrounds
                        such as medical, biological, business, journalism,
                        financial and so on. Based on this, some application
                        caveats and development trends of SSC are particularly
                        given in the end. This comprehensive review and analysis
                        of SSC can provide an overall outline, the scope of
                        research topics, and a relative complete analysis of
                        existing SSC methods for researchers.},
            langid = {english},
            keywords = {Constraints K-means,Constraints spectral clustering,
                        NMF-based semi-supervised clustering,Random
                        subspace-based semi-supervised clustering,Semi-supervised
                        clustering,Semi-supervised fuzzy clustering},
            file = {/Users/matpi832/Zotero/storage/5HWEMN9K/Cai et al. - 2023 -
                    A review on semi-supervised
                    clustering.pdf;/Users/matpi832/Zotero/storage/2GN63UKE/S0020025523002840.html
                    },
}

@article{cantuFingerprintsFraudEvidence2019,
            title = {The {{Fingerprints}} of {{Fraud}}: {{Evidence}} from {{
                     Mexico}}'s 1988 {{Presidential Election}}},
            shorttitle = {The {{Fingerprints}} of {{Fraud}}},
            author = {Cant{\'u}, Francisco},
            year = {2019},
            month = aug,
            journal = {American Political Science Review},
            volume = {113},
            number = {3},
            pages = {710--726},
            publisher = {{Cambridge University Press}},
            issn = {0003-0554, 1537-5943},
            doi = {10.1017/S0003055419000285},
            urldate = {2023-03-17},
            abstract = {This paper investigates the opportunities for
                        non-democratic regimes to rely on fraud by documenting
                        the alteration of vote tallies during the 1988
                        presidential election in Mexico. In particular, I study
                        how the alteration of vote returns came after an
                        electoral reform that centralized the vote-counting
                        process. Using an original image database of the
                        vote-tally sheets for that election and applying
                        Convolutional Neural Networks (CNN) to analyze the sheets
                        , I find evidence of blatant alterations in about a third
                        of the tallies in the country. This empirical analysis
                        shows that altered tallies were more prevalent in polling
                        stations where the opposition was not present and in
                        states controlled by governors with grassroots experience
                        of managing the electoral operation. This research has
                        implications for understanding the ways in which
                        autocrats control elections as well as for introducing a
                        new methodology to audit the integrity of vote tallies.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/4MPSF6RH/Cantú - 2019 - The
                    Fingerprints of Fraud Evidence from Mexico’s .pdf},
}

@article{carlsenComputationalGroundedTheory2022,
            title = {Computational Grounded Theory Revisited: {{From}}
                     Computer-Led to Computer-Assisted Text Analysis},
            shorttitle = {Computational Grounded Theory Revisited},
            author = {Carlsen, Hjalmar Bang and Ralund, Snorre},
            year = {2022},
            month = jan,
            journal = {Big Data \& Society},
            volume = {9},
            number = {1},
            pages = {20539517221080146},
            publisher = {{SAGE Publications Ltd}},
            issn = {2053-9517},
            doi = {10.1177/20539517221080146},
            urldate = {2023-03-21},
            abstract = {The size and variation in both meaning-making and
                        populations that characterize much contemporary text data
                        demand research processes that support both discovery,
                        interpretation and measurement. We assess one dominant
                        strategy within the social sciences that takes a
                        computer-led approach to text analysis. The approach is
                        coined computational grounded theory. This strategy, we
                        argue, relies on a set of unwarranted assumptions, namely
                        , that unsupervised models return natural clusters of
                        meaning, that the researcher can understand text with
                        limited immersion and that indirect validation is
                        sufficient for ensuring unbiased and precise measurement.
                        In response to this criticism, we develop a framework
                        that is computer assisted. We argue that our
                        reformulation of computational grounded theory better
                        aligns with the principles within grounded theory,
                        anthropological theory generation and ethnography.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/IL77L9Z5/Carlsen and Ralund -
                    2022 - Computational grounded theory revisited From comp.pdf},
}

@article{casasImagesThatMatter2019,
            title = {Images That {{Matter}}: {{Online Protests}} and the {{
                     Mobilizing Role }} of {{Pictures}}},
            shorttitle = {Images That {{Matter}}},
            author = {Casas, Andreu and Williams, Nora Webb},
            year = {2019},
            month = jun,
            journal = {Political Research Quarterly},
            volume = {72},
            number = {2},
            pages = {360--375},
            publisher = {{SAGE Publications Inc}},
            issn = {1065-9129},
            doi = {10.1177/1065912918786805},
            urldate = {2023-03-17},
            abstract = {Do images affect online political mobilization? If so,
                        how? These questions are of fundamental importance to
                        scholars of social movements, contentious politics, and
                        political behavior generally. However, little prior work
                        has systematically addressed the role of images in
                        mobilizing online participation in social movements. We
                        first confirm that images have a positive mobilizing
                        effect in the context of online protest activity. We then
                        argue that images are mobilizing because they trigger
                        stronger emotional reactions than text. Building on
                        existing political psychology models, we theorize that
                        images evoking enthusiasm, anger, and fear should be
                        particularly mobilizing, while sadness should be
                        demobilizing. We test the argument through a study of
                        Twitter activity related to a Black Lives Matter protest.
                        We find that both images in general and some of the
                        proposed emotional attributes (enthusiasm and fear)
                        contribute to online participation. The results hold when
                        controlling for alternative theoretical mechanisms for
                        why images should be mobilizing, and for the presence of
                        frequent image features. Our paper provides evidence
                        supporting the broad argument that images increase the
                        likelihood of a protest to spread online while teasing
                        out the mechanisms at play in a new media environment.},
            langid = {english},
}

@article{casasIntroductionSpecialIssue2022,
            title = {Introduction to the {{Special Issue}} on {{Images}} as {{
                     Data}}},
            author = {Casas, Andreu and Williams, Nora Webb},
            year = {2022},
            month = feb,
            journal = {Computational Communication Research},
            volume = {4},
            number = {1},
            publisher = {{Amsterdam University Press}},
            issn = {2665-9085},
            doi = {10.5117/CCR2022.1.000.CASA},
            urldate = {2023-03-01},
            abstract = {Amsterdam University Press is a leading publisher of
                        academic books, journals and textbooks in the Humanities
                        and Social Sciences. Our aim is to make current research
                        available to scholars , students, innovators, and the
                        general public. AUP stands for scholarly excellence,
                        global presence, and engagement with the international
                        academic community.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/MSSARZ95/Casas and Williams -
                    2022 - Introduction to the Special Issue on Images as Dat.pdf
                    },
}

@misc{CASMDeepLearningApproach,
            title = {{{CASM}}: {{A Deep-Learning Approach}} for {{Identifying
                     Collective Action Events}} with {{Text}} and {{Image Data}}
                     from {{Social Media}} - {{Han Zhang}}, {{Jennifer Pan}},
                     2019},
            urldate = {2023-03-13},
            howpublished = {
                            https://journals.sagepub.com/doi/full/10.1177/0081175019860244
                            },
            file = {
                    /Users/matpi832/Zotero/storage/Z6XSZ4AJ/0081175019860244.html
                    },
}

@inproceedings{chenIterativeDeepGraph2020,
            title = {Iterative {{Deep Graph Learning}} for {{Graph Neural
                     Networks}}: {{ Better}} and {{Robust Node Embeddings}}},
            shorttitle = {Iterative {{Deep Graph Learning}} for {{Graph Neural
                          Networks}}},
            booktitle = {Advances in {{Neural Information Processing Systems}}},
            author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed},
            year = {2020},
            volume = {33},
            pages = {19314--19326},
            publisher = {{Curran Associates, Inc.}},
            urldate = {2023-03-02},
            abstract = {In this paper, we propose an end-to-end graph learning
                        framework, namely \textbackslash textbf\{I\}terative
                        \textbackslash textbf\{D \}eep \textbackslash textbf\{G\}
                        raph \textbackslash textbf\{L\} earning (\textbackslash
                        alg), for jointly and iteratively learning graph
                        structure and graph embedding. The key rationale of
                        \textbackslash alg is to learn a better graph structure
                        based on better node embeddings, and vice versa (i.e.,
                        better node embeddings based on a better graph
                        structure). Our iterative method dynamically stops when
                        the learned graph structure approaches close enough to
                        the graph optimized for the downstream prediction task.
                        In addition, we cast the graph learning problem as a
                        similarity metric learning problem and leverage adaptive
                        graph regularization for controlling the quality of the
                        learned graph. Finally, combining the anchor-based
                        approximation technique, we further propose a scalable
                        version of \textbackslash alg, namely \textbackslash salg
                        , which significantly reduces the time and space
                        complexity of \textbackslash alg without compromising the
                        performance. Our extensive experiments on nine benchmarks
                        show that our proposed \textbackslash alg models can
                        consistently outperform or match the state-of-the-art
                        baselines. Furthermore, \textbackslash alg can be more
                        robust to adversarial graphs and cope with both
                        transductive and inductive learning.},
            file = {/Users/matpi832/Zotero/storage/NR94A2EB/Chen et al. - 2020 -
                    Iterative Deep Graph Learning for Graph Neural Net.pdf},
}

@article{chenVisualFramingScience2022,
            title = {Visual {{Framing}} of {{Science Conspiracy Videos}}},
            author = {Chen, Kaiping and Kim, Sang Jung and Gao, Qiantong and
                      Raschka, Sebastian},
            year = {2022},
            month = may,
            journal = {Computational Communication Research},
            volume = {4},
            number = {1},
            pages = {98--134},
            urldate = {2023-03-01},
            abstract = {Recent years have witnessed an explosion of science
                        conspiracy videos on the Internet, challenging science
                        epistemology and public understanding of science.
                        Scholars have started to examine the persuasion
                        techniques used in conspiracy messages such as
                        uncertainty and fear yet, little is understood about the
                        visual narratives, especially how visual narratives
                        differ in videos that debunk conspiracies versus those
                        that propagate conspiracies. This paper addresses this
                        gap in understanding visual framing in conspiracy videos
                        through analyzing millions of frames from conspiracy and
                        counter-conspiracy YouTube videos using computational
                        methods. We found that conspiracy videos tended to use
                        lower color variance and brightness, especially in
                        thumbnails and earlier parts of the videos. This paper
                        also demonstrates how researchers can integrate textual
                        and visual features in machine learning modelsto study
                        conspiracies on social mediaand discusses the
                        implications of computational modeling for scholars
                        interested in studying visual manipulation in the digital
                        era. The analysis of visual and textual features
                        presented in this paper could be useful for future
                        studies focused on designing systems to identify
                        conspiracy content on the Internet.},
            copyright = {Copyright (c) 2022 Kaiping Chen, Sang Jung Kim,
                         Qiantong Gao, Sebastian Raschka},
            langid = {english},
            keywords = {color and brightness,computer vision,conspiracy,machine
                        learning, text analysis,YouTube},
            file = {/Users/matpi832/Zotero/storage/T5X5LY3A/Chen et al. - 2022 -
                    Visual Framing of Science Conspiracy Videos.pdf},
}

@article{costaOverlappingCommunitiesRoles2022,
            title = {Overlapping Communities and Roles in Networks with Node
                     Attributes: { {Probabilistic}} Graphical Modeling, {{
                     Bayesian}} Formulation and Variational Inference},
            shorttitle = {Overlapping Communities and Roles in Networks with
                          Node Attributes},
            author = {Costa, Gianni and Ortale, Riccardo},
            year = {2022},
            month = jan,
            journal = {Artificial Intelligence},
            volume = {302},
            pages = {103580},
            issn = {0004-3702},
            doi = {10.1016/j.artint.2021.103580},
            urldate = {2023-04-24},
            abstract = {Community and role discovery are key tasks in network
                        analysis. The former unveils the organization of a
                        network, whereas the latter highlights the social
                        functions of nodes. The integration of community
                        discovery and role analysis has been investigated, to
                        gain a deeper understanding of topology, i.e., the social
                        functions fulfilled by nodes to pursue community
                        purposes. However, hitherto, node attributes and
                        behavioral role patterns have been ignored in the
                        combination of both tasks. In this manuscript, we study
                        the seamless integration of community discovery and
                        behavioral role analysis, in the domain of networks with
                        node attributes. In particular, we focus on unifying the
                        two tasks, by explicitly harnessing node attributes and
                        behavioral role patterns in a principled manner. To this
                        end, we propose two Bayesian probabilistic generative
                        models of networks, whose novelty consists in the
                        interrelationship of overlapping communities, roles,
                        their behavioral patterns and node attributes. The
                        devised models allow for a variety of exploratory,
                        descriptive and predictive tasks. These are carried out
                        through mean-field variational inference, which is in
                        turn mathematically derived and implemented into a
                        coordinate-ascent algorithm. A wide spectrum of
                        experiments is designed, to validate the devised models
                        against three classes of state-of-the-art competitors
                        using various real-world benchmark data sets from
                        different social networking services. Our models are
                        found to be more accurate in community detection, link
                        prediction and attribute prediction. Notably, the gain in
                        accuracy is robust to perturbations in the form of noise
                        or lack of observations in either network structure or
                        node attributes. Beside accuracy, scalability is also
                        comparatively investigated. Finally, a qualitative
                        demonstration of the tasks enabled by our models is
                        developed, in which node roles are intuitively explained
                        through an unprecedented visual representation.},
            langid = {english},
            keywords = {Attribute prediction,Bayesian probabilistic network
                        modeling, Community discovery,Link prediction,Role
                        analysis},
            file = {/Users/matpi832/Zotero/storage/YFVLYHYE/Costa and Ortale -
                    2022 - Overlapping communities and roles in networks
                    with.pdf;/Users/matpi832/Zotero/storage/6TS2G3VG/S0004370221001314.html
                    },
}

@article{cranmerNavigatingRangeStatistical2017,
            title = {Navigating the {{Range}} of {{Statistical Tools}} for {{
                     Inferential Network Analysis}}},
            author = {Cranmer, Skyler J. and Leifeld, Philip and McClurg, Scott
                      D. and Rolfe, Meredith},
            year = {2017},
            journal = {American Journal of Political Science},
            volume = {61},
            number = {1},
            pages = {237--251},
            issn = {1540-5907},
            doi = {10.1111/ajps.12263},
            urldate = {2023-03-02},
            abstract = {The last decade has seen substantial advances in
                        statistical techniques for the analysis of network data,
                        as well as a major increase in the frequency with which
                        these tools are used. These techniques are designed to
                        accomplish the same broad goal, statistically valid
                        inference in the presence of highly interdependent
                        relationships, but important differences remain between
                        them. We review three approaches commonly used for
                        inferential network analysis\textemdash the quadratic
                        assignment procedure, exponential random graph models,
                        and latent space network models\textemdash highlighting
                        the strengths and weaknesses of the techniques relative
                        to one another. An illustrative example using climate
                        change policy network data shows that all three network
                        models outperform standard logit estimates on multiple
                        criteria. This article introduces political scientists to
                        a class of network techniques beyond simple descriptive
                        measures of network structure, and it helps researchers
                        choose which model to use in their own research.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/C8WL7JX4/Cranmer et al. -
                    2017 - Navigating the Range of Statistical Tools for
                    Infe.pdf;/Users/matpi832/Zotero/storage/42PHFGSW/ajps.html},
}

@article{daneshSurveyClusteringLarge,
            title = {A Survey of Clustering Large Probabilistic Graphs: {{
                     Techniques}}, Evaluations, and Applications},
            shorttitle = {A Survey of Clustering Large Probabilistic Graphs},
            author = {Danesh, Malihe and Dorrigiv, Morteza and Yaghmaee, Farzin},
            journal = {Expert Systems},
            volume = {n/a},
            number = {n/a},
            pages = {e13248},
            issn = {1468-0394},
            doi = {10.1111/exsy.13248},
            urldate = {2023-03-06},
            abstract = {Given the growth of uncertainty in the real world,
                        analysing probabilistic graphs is crucial. Clustering is
                        one of the most fundamental methods of mining
                        probabilistic graphs to discover the hidden patterns in
                        them. This survey examines an extensive and organized
                        analysis of the clustering techniques of large
                        probabilistic graphs proposed in the literature. First,
                        the definition of probabilistic graphs and modelling them
                        are introduced. Second, the clustering of such graphs and
                        their challenges, such as uncertainty of edges, high
                        dimensions, and the impossibility of applying certain
                        graph clustering techniques directly, are expressed. Then
                        , a taxonomy of clustering approaches is discussed in two
                        main categories: threshold-based and possible
                        worlds-based methods. The techniques presented in each
                        category are explained and examined. Here, these methods
                        are evaluated on real datasets, and their performance is
                        compared with each other. Finally, the survey is
                        summarized by describing some of the applications of
                        probabilistic graph clustering and future research
                        directions.},
            langid = {english},
            keywords = {clustering,possible worlds-based methods,probabilistic
                        graph, threshold-based methods},
            file = {/Users/matpi832/Zotero/storage/B3ZUZ5LB/Danesh et al. - A
                    survey of clustering large probabilistic
                    graphs.pdf;/Users/matpi832/Zotero/storage/5A85XEZU/exsy.html},
}

@article{dennyTextPreprocessingUnsupervised2018,
            title = {Text {{Preprocessing For Unsupervised Learning}}: {{Why It
                     Matters}}, {{When It Misleads}}, {{And What To Do About It}}
                     },
            shorttitle = {Text {{Preprocessing For Unsupervised Learning}}},
            author = {Denny, Matthew J. and Spirling, Arthur},
            year = {2018},
            month = apr,
            journal = {Political Analysis},
            volume = {26},
            number = {2},
            pages = {168--189},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1017/pan.2017.44},
            urldate = {2023-03-08},
            abstract = {Despite the popularity of unsupervised techniques for
                        political science text-as-data research, the importance
                        and implications of preprocessing decisions in this
                        domain have received scant systematic attention. Yet, as
                        we show, such decisions have profound effects on the
                        results of real models for real data. We argue that
                        substantive theory is typically too vague to be of use
                        for feature selection, and that the supervised literature
                        is not necessarily a helpful source of advice. To aid
                        researchers working in unsupervised settings, we
                        introduce a statistical procedure and software that
                        examines the sensitivity of findings under alternate
                        preprocessing regimes. This approach complements a
                        researcher's substantive understanding of a problem by
                        providing a characterization of the variability changes
                        in preprocessing choices may induce when analyzing a
                        particular dataset. In making scholars aware of the
                        degree to which their results are likely to be sensitive
                        to their preprocessing decisions, it aids replication
                        efforts.},
            langid = {english},
            keywords = {descriptive statistics,statistical analysis of texts,
                        unsupervised learning},
            file = {/Users/matpi832/Zotero/storage/GRPCS3SB/Denny and Spirling -
                    2018 - Text Preprocessing For Unsupervised Learning Why .pdf},
}

@inproceedings{dueckNonmetricAffinityPropagation2007,
            title = {Non-Metric Affinity Propagation for Unsupervised Image
                     Categorization },
            booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{
                         Computer Vision}}},
            author = {Dueck, Delbert and Frey, Brendan J.},
            year = {2007},
            month = oct,
            pages = {1--8},
            issn = {2380-7504},
            doi = {10.1109/ICCV.2007.4408853},
            abstract = {Unsupervised categorization of images or image parts is
                        often needed for image and video summarization or as a
                        preprocessing step in supervised methods for
                        classification, tracking and segmentation. While many
                        metric-based techniques have been applied to this problem
                        in the vision community, often, the most natural measures
                        of similarity (e.g., number of matching SIFT features)
                        between pairs of images or image parts is non-metric.
                        Unsupervised categorization by identifying a subset of
                        representative exemplars can be efficiently performed
                        with the recently-proposed 'affinity propagation'
                        algorithm. In contrast to k-centers clustering, which
                        iteratively refines an initial randomly-chosen set of
                        exemplars, affinity propagation simultaneously considers
                        all data points as potential exemplars and iteratively
                        exchanges messages between data points until a good
                        solution emerges. When applied to the Olivetti face data
                        set using a translation-invariant non-metric similarity,
                        affinity propagation achieves a much lower reconstruction
                        error and nearly halves the classification error rate,
                        compared to state-of-the-art techniques. For the more
                        challenging problem of unsupervised categorization of
                        images from the CaltechlOl data set, we derived
                        non-metric similarities between pairs of images by
                        matching SIFT features. Affinity propagation successfully
                        identifies meaningful categories, which provide a natural
                        summarization of the training images and can be used to
                        classify new input images.},
            keywords = {Clustering algorithms,Data preprocessing,Educational
                        institutions, Error analysis,Euclidean distance,Face
                        detection,Image reconstruction,Image segmentation,
                        Iterative algorithms,Machine learning},
            file = {/Users/matpi832/Zotero/storage/VU7JZVE8/Dueck and Frey -
                    2007 - Non-metric affinity propagation for unsupervised i.pdf
                    },
}

@article{duqueRecognizingInternationalStatus2018,
            title = {Recognizing {{International Status}}: {{A Relational
                     Approach}}},
            shorttitle = {Recognizing {{International Status}}},
            author = {Duque, Marina G},
            year = {2018},
            month = sep,
            journal = {International Studies Quarterly},
            volume = {62},
            number = {3},
            pages = {577--592},
            issn = {0020-8833},
            doi = {10.1093/isq/sqy001},
            urldate = {2023-03-20},
            abstract = {How do states achieve status? Although we rely on status
                        to explain important phenomena in international politics
                        \textemdash such as wars and the foreign policy of
                        emerging powers\textemdash we still do not understand
                        what status is or where it comes from. Previous research
                        treats status as a function of state attributes, such as
                        wealth and military capability. Following Weber, I argue
                        that status depends on social recognition: it concerns
                        identification processes in which an actor gains
                        admission into a club once they follow the rules of
                        membership. Therefore, systematic social processes, which
                        cannot be reduced to state attributes, influence status.
                        In particular, status is self-reinforcing. Moreover,
                        social closure influences status \textemdash which
                        implies that (1) a state's existing relations influence
                        its ability to achieve status and (2) states recognize
                        similar states rather than states with the most
                        impressive portfolio of certain attributes. To
                        investigate the determinants of international status, I
                        move beyond ranking states based on attributes to examine
                        quantitatively how status emerges from state relations.
                        Leveraging inferential network analysis, I examine state
                        practices that express recognition\textemdash
                        specifically, the network of embassies. The analysis
                        indicates that self-reinforcing dynamics and social
                        closure, rather than state attributes directly, drive
                        status recognition.},
            file = {/Users/matpi832/Zotero/storage/LTQB4MEC/4962448.html},
}

@misc{egamiHowMakeCausal2018,
            title = {How to {{Make Causal Inferences Using Texts}}},
            author = {Egami, Naoki and Fong, Christian J. and Grimmer, Justin
                      and Roberts, Margaret E. and Stewart, Brandon M.},
            year = {2018},
            month = feb,
            number = {arXiv:1802.02163},
            eprint = {1802.02163},
            primaryclass = {cs, stat},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.1802.02163},
            urldate = {2023-03-17},
            abstract = {New text as data techniques offer a great promise: the
                        ability to inductively discover measures that are useful
                        for testing social science theories of interest from
                        large collections of text. We introduce a conceptual
                        framework for making causal inferences with discovered
                        measures as a treatment or outcome. Our framework enables
                        researchers to discover high-dimensional textual
                        interventions and estimate the ways that observed
                        treatments affect text-based outcomes. We argue that
                        nearly all text-based causal inferences depend upon a
                        latent representation of the text and we provide a
                        framework to learn the latent representation. But
                        estimating this latent representation, we show, creates
                        new risks: we may introduce an identification problem or
                        overfit. To address these risks we describe a
                        split-sample framework and apply it to estimate causal
                        effects from an experiment on immigration attitudes and a
                        study on bureaucratic response. Our work provides a
                        rigorous foundation for text-based causal inferences.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Computation and Language,Statistics -
                        Machine Learning,Statistics - Methodology},
            file = {/Users/matpi832/Zotero/storage/38T3IMN8/Egami et al. - 2018
                    - How to Make Causal Inferences Using
                    Texts.pdf;/Users/matpi832/Zotero/storage/8WXSQWCQ/Egami et
                    al. - 2018 - How to Make Causal Inferences Using
                    Texts.pdf;/Users/matpi832/Zotero/storage/S5UXE6Z6/1802.html},
}

@article{estivill-castroWhyManyClustering2002,
            title = {Why so Many Clustering Algorithms: A Position Paper},
            shorttitle = {Why so Many Clustering Algorithms},
            author = {{Estivill-Castro}, Vladimir},
            year = {2002},
            month = jun,
            journal = {ACM SIGKDD Explorations Newsletter},
            volume = {4},
            number = {1},
            pages = {65--75},
            issn = {1931-0145},
            doi = {10.1145/568574.568575},
            urldate = {2023-04-28},
            abstract = {We argue that there are many clustering algorithms,
                        because the notion of "cluster" cannot be precisely
                        defined. Clustering is in the eye of the beholder, and as
                        such, researchers have proposed many induction principles
                        and models whose corresponding optimization problem can
                        only be approximately solved by an even larger number of
                        algorithms. Therefore, comparing clustering algorithms,
                        must take into account a careful understanding of the
                        inductive principles involved.},
            keywords = {clustering,clustering criterion,inductive principle},
}

@inproceedings{fongDiscoveryTreatmentsText2016,
            title = {Discovery of {{Treatments}} from {{Text Corpora}}},
            author = {Fong, Christian and Grimmer, Justin},
            year = {2016},
            month = jan,
            pages = {1600--1609},
            doi = {10.18653/v1/P16-1151},
            file = {/Users/matpi832/Zotero/storage/5XCKDX2T/Fong and Grimmer -
                    2016 - Discovery of Treatments from Text Corpora.pdf},
}

@misc{FrameworkUnsupervisedSemisupervisedanalysis,
            title = {A Framework for the Unsupervised and
                     Semi-Supervisedanalysis of Visual Frames},
            journal = {Dropbox},
            urldate = {2023-03-01},
            abstract = {Shared with Dropbox},
            howpublished = {https://www.dropbox.com/s/otps2cqpqtqb3js/PA\_BoVW
                            \_main\_V4 \_RnR.pdf?dl=0},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/LLIT9YCA/A framework for the
                    unsupervised and
                    semi-supervis.pdf;/Users/matpi832/Zotero/storage/QJGL2CSG/PA_BoVW_main_V4_RnR.html
                    },
}

@article{gerlachNetworkApproachTopic2018,
            title = {A Network Approach to Topic Models},
            author = {Gerlach, Martin and Peixoto, Tiago P. and Altmann, Eduardo
                      G.},
            year = {2018},
            month = jul,
            journal = {Science Advances},
            volume = {4},
            number = {7},
            pages = {eaaq1360},
            publisher = {{American Association for the Advancement of Science}},
            doi = {10.1126/sciadv.aaq1360},
            urldate = {2023-03-25},
            abstract = {One of the main computational and scientific challenges
                        in the modern age is to extract useful information from
                        unstructured texts. Topic models are one popular
                        machine-learning approach that infers the latent topical
                        structure of a collection of documents. Despite their
                        success\textemdash particularly of the most widely used
                        variant called latent Dirichlet allocation (LDA)
                        \textemdash and numerous applications in sociology,
                        history, and linguistics, topic models are known to
                        suffer from severe conceptual and practical problems, for
                        example, a lack of justification for the Bayesian priors,
                        discrepancies with statistical properties of real texts,
                        and the inability to properly choose the number of
                        topics. We obtain a fresh view of the problem of
                        identifying topical structures by relating it to the
                        problem of finding communities in complex networks. We
                        achieve this by representing text corpora as bipartite
                        networks of documents and words. By adapting existing
                        community-detection methods (using a stochastic block
                        model (SBM) with nonparametric priors), we obtain a more
                        versatile and principled framework for topic modeling
                        (for example, it automatically detects the number of
                        topics and hierarchically clusters both the words and
                        documents). The analysis of artificial and real corpora
                        demonstrates that our SBM approach leads to better topic
                        models than LDA in terms of statistical model selection.
                        Our work shows how to formally relate methods from
                        community detection and topic modeling, opening the
                        possibility of cross-fertilization between these two
                        fields.},
            file = {/Users/matpi832/Zotero/storage/TSG66C7W/Gerlach et al. -
                    2018 - A network approach to topic models.pdf},
}

@article{grimmerGeneralPurposeComputerassisted2011,
            title = {General Purpose Computer-Assisted Clustering and
                     Conceptualization},
            author = {Grimmer, Justin and King, Gary},
            year = {2011},
            month = feb,
            journal = {Proceedings of the National Academy of Sciences},
            volume = {108},
            number = {7},
            pages = {2643--2650},
            publisher = {{Proceedings of the National Academy of Sciences}},
            doi = {10.1073/pnas.1018067108},
            urldate = {2023-03-13},
            abstract = {We develop a computer-assisted method for the discovery
                        of insightful conceptualizations, in the form of
                        clusterings (i.e., partitions) of input objects. Each of
                        the numerous fully automated methods of cluster analysis
                        proposed in statistics, computer science, and biology
                        optimize a different objective function. Almost all are
                        well defined, but how to determine before the fact which
                        one, if any, will partition a given set of objects in an
                        ``insightful'' or ``useful'' way for a given user is
                        unknown and difficult, if not logically impossible. We
                        develop a metric space of partitions from all existing
                        cluster analysis methods applied to a given dataset
                        (along with millions of other solutions we add based on
                        combinations of existing clusterings) and enable a user
                        to explore and interact with it and quickly reveal or
                        prompt useful or insightful conceptualizations. In
                        addition, although it is uncommon to do so in
                        unsupervised learning problems, we offer and implement
                        evaluation designs that make our computer-assisted
                        approach vulnerable to being proven suboptimal in
                        specific data types. We demonstrate that our approach
                        facilitates more efficient and insightful discovery of
                        useful information than expert human coders or many
                        existing fully automated methods.},
            file = {/Users/matpi832/Zotero/storage/4ML77YEE/Grimmer and King -
                    2011 - General purpose computer-assisted clustering and c.pdf
                    },
}

@article{grimmerMachineLearningSocial2021,
            title = {Machine {{Learning}} for {{Social Science}}: {{An Agnostic
                     Approach}} },
            shorttitle = {Machine {{Learning}} for {{Social Science}}},
            author = {Grimmer, Justin and Roberts, Margaret E. and Stewart,
                      Brandon M.},
            year = {2021},
            journal = {Annual Review of Political Science},
            volume = {24},
            number = {1},
            pages = {395--419},
            doi = {10.1146/annurev-polisci-053119-015921},
            urldate = {2023-03-09},
            abstract = {Social scientists are now in an era of data abundance,
                        and machine learning tools are increasingly used to
                        extract meaning from data sets both massive and small. We
                        explain how the inclusion of machine learning in the
                        social sciences requires us to rethink not only
                        applications of machine learning methods but also best
                        practices in the social sciences. In contrast to the
                        traditional tasks for machine learning in computer
                        science and statistics, when machine learning is applied
                        to social scientific data, it is used to discover new
                        concepts, measure the prevalence of those concepts,
                        assess causal effects, and make predictions. The
                        abundance of data and resources facilitates the move away
                        from a deductive social science to a more sequential,
                        interactive, and ultimately inductive approach to
                        inference. We explain how an agnostic approach to machine
                        learning methods focused on the social science tasks
                        facilitates progress across a wide range of questions.},
            keywords = {machine learning,research design,text as data},
            file = {/Users/matpi832/Zotero/storage/AQPEUSBC/Grimmer et al. -
                    2021 - Machine Learning for Social Science An Agnostic A.pdf},
}

@article{grimmerTextDataPromise2013,
            title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{
                     Automatic Content Analysis Methods}} for {{Political Texts}}
                     },
            shorttitle = {Text as {{Data}}},
            author = {Grimmer, Justin and Stewart, Brandon M.},
            year = {2013/ed},
            journal = {Political Analysis},
            volume = {21},
            number = {3},
            pages = {267--297},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1093/pan/mps028},
            urldate = {2023-03-08},
            abstract = {Politics and political conflict often occur in the
                        written and spoken word. Scholars have long recognized
                        this, but the massive costs of analyzing even moderately
                        sized collections of texts have hindered their use in
                        political science research. Here lies the promise of
                        automated text analysis: it substantially reduces the
                        costs of analyzing large collections of text. We provide
                        a guide to this exciting new area of research and show
                        how, in many instances, the methods have already obtained
                        part of their promise. But there are pitfalls to using
                        automated methods\textemdash they are no substitute for
                        careful thought and close reading and require extensive
                        and problem-specific validation. We survey a wide range
                        of new methods, provide guidance on how to validate the
                        output of the models, and clarify misconceptions and
                        errors in the literature. To conclude, we argue that for
                        automated text methods to become a standard tool for
                        political scientists, methodologists must contribute new
                        methods and new methods of validation.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/BQU43ZSN/Grimmer and Stewart
                    - 2013 - Text as Data The Promise and Pitfalls of
                    Automati.pdf},
}

@inproceedings{grimmerUnreliabilityMeasuresIntercoder2015,
            title = {The {{Unreliability}} of {{Measures}} of {{Intercoder
                     Reliability}} , and {{What}} to Do {{About}} It},
            author = {Grimmer, Justin and King, Gary and Superti, Chiara},
            year = {2015},
            urldate = {2023-03-08},
            abstract = {In both automated and traditional text analysis, human
                        coders are regularly tasked with categorizing documents.
                        Researchers then evaluate the success of this crucial
                        step in the research process via one of many measures of
                        intercoder reliability, such as Cronbachs alpha. They
                        then improve coding practices until this measure reaches
                        some arbitrary threshold, at which point remaining
                        disagreements are resolved in arbitrary ways and ignored
                        in subsequent analyses. We show that this common practice
                        can generate severely biased estimates and misleading
                        conclusions. The problem is the focus on measures of
                        intercoder reliability which, except at the extreme, are
                        unrelated to the quantities of interest, such as the
                        proportion of documents in each category. We thus develop
                        an approach that enables scholars to directly incorporate
                        coding uncertainty into statistical estimation. The
                        method offers an interval estimate which we prove
                        contains the true proportion of documents in each
                        category, under reasonable assumptions. We then extend
                        this method to situations with multiple coders, when one
                        coder is trusted more than another, and when the
                        resulting document codes are used as inputs to another
                        statistical model. We offer easy-to-use software that
                        implements all our suggestions. {${_\ast} $}Department of
                        Political Science, Stanford University, JustinGrimmer.org
                        , jgrimmer@stanford.edu. \textdagger Institute for
                        Quantitative Social Science, Harvard University;
                        GaryKing.org, king@harvard.edu, (617) 500-7570.
                        \textdaggerdbl Institute for Quantitative Social Science,
                        Harvard University, scholar.harvard.edu/csuperti,
                        csuperti@fas.harvard.edu 1},
            file = {/Users/matpi832/Zotero/storage/JIQIZ2SL/Grimmer et al. -
                    2015 - The Unreliability of Measures of Intercoder Reliab.pdf
                    },
}

@misc{guerinCNNFeaturesAre2018,
            title = {{{CNN}} Features Are Also Great at Unsupervised
                     Classification},
            author = {Gu{\'e}rin, Joris and Gibaru, Olivier and Thiery, St{\'e}
                      phane and Nyiri, Eric},
            year = {2018},
            month = sep,
            number = {arXiv:1707.01700},
            eprint = {1707.01700},
            primaryclass = {cs},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.1707.01700},
            urldate = {2023-03-21},
            abstract = {This paper aims at providing insight on the
                        transferability of deep CNN features to unsupervised
                        problems. We study the impact of different pretrained CNN
                        feature extractors on the problem of image set clustering
                        for object classification as well as fine-grained
                        classification. We propose a rather straightforward
                        pipeline combining deep-feature extraction using a CNN
                        pretrained on ImageNet and a classic clustering algorithm
                        to classify sets of images. This approach is compared to
                        state-of-the-art algorithms in image-clustering and
                        provides better results. These results strengthen the
                        belief that supervised training of deep CNN on large
                        datasets, with a large variability of classes, extracts
                        better features than most carefully designed engineering
                        approaches, even for unsupervised tasks. We also validate
                        our approach on a robotic application, consisting in
                        sorting and storing objects smartly based on clustering.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Artificial Intelligence,Computer
                        Science - Computer Vision and Pattern Recognition,
                        Computer Science - Machine Learning},
            file = {/Users/matpi832/Zotero/storage/UHBCXG3Q/Guérin et al. - 2018
                    - CNN features are also great at unsupervised
                    classi.pdf;/Users/matpi832/Zotero/storage/ZZ63CU4M/1707.html},
}

@article{hohmannQuantifyingIdeologicalPolarization2023,
            title = {Quantifying Ideological Polarization on a Network Using
                     Generalized { {Euclidean}} Distance},
            author = {Hohmann, Marilena and Devriendt, Karel and Coscia, Michele
                      },
            year = {2023},
            month = mar,
            journal = {Science Advances},
            volume = {9},
            number = {9},
            pages = {eabq2044},
            publisher = {{American Association for the Advancement of Science}},
            doi = {10.1126/sciadv.abq2044},
            urldate = {2023-03-02},
            abstract = {An intensely debated topic is whether political
                        polarization on social media is on the rise. We can
                        investigate this question only if we can quantify
                        polarization, by taking into account how extreme the
                        opinions of the people are, how much they organize into
                        echo chambers, and how these echo chambers organize in
                        the network. Current polarization estimates are
                        insensitive to at least one of these factors: They cannot
                        conclusively clarify the opening question. Here, we
                        propose a measure of ideological polarization that can
                        capture the factors we listed. The measure is based on
                        the generalized Euclidean distance, which estimates the
                        distance between two vectors on a network, e.g.,
                        representing people's opinion. This measure can fill the
                        methodological gap left by the state of the art and leads
                        to useful insights when applied to real-world debates
                        happening on social media and to data from the U.S.
                        Congress.},
            file = {/Users/matpi832/Zotero/storage/IVR7R8PJ/Hohmann et al. -
                    2023 - Quantifying ideological polarization on a network .pdf
                    },
}

@article{hongComputingDistributionFunction2013,
            title = {On Computing the Distribution Function for the {{Poisson}}
                     Binomial Distribution},
            author = {Hong, Yili},
            year = {2013},
            month = mar,
            journal = {Computational Statistics \& Data Analysis},
            volume = {59},
            pages = {41--51},
            issn = {0167-9473},
            doi = {10.1016/j.csda.2012.10.006},
            urldate = {2023-03-06},
            abstract = {The Poisson binomial distribution is the distribution of
                        the sum of independent and non-identically distributed
                        random indicators. Each indicator follows a Bernoulli
                        distribution and the individual probabilities of success
                        vary. When all success probabilities are equal, the
                        Poisson binomial distribution is a binomial distribution.
                        The Poisson binomial distribution has many applications
                        in different areas such as reliability, actuarial science
                        , survey sampling, econometrics, etc. The computing of
                        the cumulative distribution function (cdf) of the Poisson
                        binomial distribution, however, is not straightforward.
                        Approximation methods such as the Poisson approximation
                        and normal approximations have been used in literature.
                        Recursive formulae also have been used to compute the cdf
                        in some areas. In this paper, we present a simple
                        derivation for an exact formula with a closed-form
                        expression for the cdf of the Poisson binomial
                        distribution. The derivation uses the discrete Fourier
                        transform of the characteristic function of the
                        distribution. We develop an algorithm that efficiently
                        implements the exact formula. Numerical studies were
                        conducted to study the accuracy of the developed
                        algorithm and approximation methods. We also studied the
                        computational efficiency of different methods. The paper
                        is concluded with a discussion on the use of different
                        methods in practice and some suggestions for
                        practitioners.},
            langid = {english},
            keywords = {-out-of- system,Characteristic function,Longevity risk,
                        Normal approximation,Sum of independent random indicators
                        ,Warranty returns },
            file = {/Users/matpi832/Zotero/storage/LK3X5D2R/Hong - 2013 - On
                    computing the distribution function for the
                    Poi.pdf;/Users/matpi832/Zotero/storage/WLI7DBG7/S0167947312003568.html
                    },
}

@article{huWhatWeInstagram2014,
            title = {What We Instagram: 8th {{International Conference}} on {{
                     Weblogs}} and {{Social Media}}, {{ICWSM}} 2014},
            shorttitle = {What We Instagram},
            author = {Hu, Yuheng and Manikonda, Lydia and Kambhampati, Subbarao},
            year = {2014},
            month = jan,
            journal = {Proceedings of the 8th International Conference on
                       Weblogs and Social Media, ICWSM 2014},
            series = {Proceedings of the 8th {{International Conference}} on {{
                      Weblogs}} and {{Social Media}}, {{ICWSM}} 2014},
            pages = {595--598},
            publisher = {{The AAAI Press}},
            urldate = {2023-03-21},
            abstract = {Instagram is a relatively new form of communication
                        where users can easily share their updates by taking
                        photos and tweaking them using filters. It has seen rapid
                        growth in the number of users as well as uploads since it
                        was launched in October 2010. In spite of the fact that
                        it is the most popular photo capturing and sharing
                        application, it has attracted relatively less attention
                        from the research community. In this paper, we present
                        both qualitative and quantitative analysis on Instagram.
                        We use computer vision techniques to examine the photo
                        content. Based on that, we identify the different types
                        of active users on Instagram using clustering. Our
                        results reveal several insights about Instagram which
                        were never studied before, that include: 1) Eight popular
                        photos categories, 2) Five distinct types of Instagram
                        users in terms of their posted photos, and 3) A user's
                        audience (number of followers) is independent of his/her
                        shared photos on Instagram. To our knowledge, this is the
                        first in-depth study of content and users on Instagram.},
            file = {/Users/matpi832/Zotero/storage/SPR2Z2FV/Hu et al. - 2014 -
                    What we instagram 8th International Conference on.pdf},
}

@article{jerzakImprovedMethodAutomated2023,
            title = {An {{Improved Method}} of {{Automated Nonparametric Content
                     Analysis} } for {{Social Science}}},
            author = {Jerzak, Connor T. and King, Gary and Strezhnev, Anton},
            year = {2023},
            month = jan,
            journal = {Political Analysis},
            volume = {31},
            number = {1},
            pages = {42--58},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1017/pan.2021.36},
            urldate = {2023-03-16},
            abstract = {Some scholars build models to classify documents into
                        chosen categories. Others, especially social scientists
                        who tend to focus on population characteristics, instead
                        usually estimate the proportion of documents in each
                        category\textemdash using either parametric
                        ``classify-and-count'' methods or ``direct''
                        nonparametric estimation of proportions without
                        individual classification. Unfortunately,
                        classify-and-count methods can be highly model-dependent
                        or generate more bias in the proportions even as the
                        percent of documents correctly classified increases.
                        Direct estimation avoids these problems, but can suffer
                        when the meaning of language changes between training and
                        test sets or is too similar across categories. We develop
                        an improved direct estimation approach without these
                        issues by including and optimizing continuous text
                        features, along with a form of matching adapted from the
                        causal inference literature. Our approach substantially
                        improves performance in a diverse collection of 73
                        datasets. We also offer easy-to-use software that
                        implements all ideas discussed herein.},
            langid = {english},
            keywords = {natural language processing,non-parametric statistics,
                        quantification},
            file = {/Users/matpi832/Zotero/storage/LN5CPX8M/Jerzak et al. - 2023
                    - An Improved Method of Automated Nonparametric Cont.pdf},
}

@article{jooImageDataAutomated2022,
            title = {Image as {{Data}}: {{Automated Content Analysis}} for {{
                     Visual Presentations}} of {{Political Actors}} and {{Events}
                     }},
            shorttitle = {Image as {{Data}}},
            author = {Joo, Jungseock and {Steinert-Threlkeld}, Zachary C.},
            year = {2022},
            month = feb,
            journal = {Computational Communication Research},
            volume = {4},
            number = {1},
            publisher = {{Amsterdam University Press}},
            issn = {2665-9085},
            doi = {10.5117/CCR2022.1.001.JOO},
            urldate = {2023-03-01},
            abstract = {Abstract Images matter because they help individuals
                        evaluate policies, primarily through emotional resonance,
                        and can help researchers from a variety of fields measure
                        otherwise difficult to estimate quantities. The lack of
                        scalable analytic methods, however , has prevented
                        researchers from incorporating large scale image data in
                        studies. This article offers an in-depth overview of
                        automated methods for image analysis and explains their
                        usage and implementation. It elaborates on how these
                        methods and results can be validated and interpreted and
                        discusses ethical concerns. Two examples then highlight
                        approaches to systematically understanding visual
                        presentations of political actors and events from large
                        scale image datasets collected from social media. The
                        first study examines gender and party differences in the
                        self-presentation of the U.S. politicians through their
                        Facebook photographs, using an off-the-shelf computer
                        vision model, Google's Label Detection API. The second
                        study develops image classifiers based on convolutional
                        neural networks to detect custom labels from images of
                        protesters shared on Twitter to understand how protests
                        are framed on social media. These analyses demonstrate
                        advantages of computer vision and deep learning as a
                        novel analytic tool that can expand the scope and size of
                        traditional visual analysis to thousands of features and
                        millions of images. The paper also provides comprehensive
                        technical details and practices to help guide political
                        communication scholars and practitioners.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/JJQ96CS5/Joo and
                    Steinert-Threlkeld - 2022 - Image as Data Automated Content
                    Analysis for Visu.pdf},
}

@incollection{kangUnderstandingPoliticalCommunication2020a,
            title = {Understanding {{Political Communication Styles}} in {{
                     Televised Debates}} via {{Body Movements}}},
            booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2020 {{
                         Workshops}}},
            author = {Kang, Zhiqi and Indudhara, Christina and Mahorker, Kaushik
                      and Bucy, Erik P. and Joo, Jungseock},
            editor = {Bartoli, Adrien and Fusiello, Andrea},
            year = {2020},
            volume = {12535},
            pages = {788--793},
            publisher = {{Springer International Publishing}},
            address = {{Cham}},
            doi = {10.1007/978-3-030-66415-2_55},
            urldate = {2023-03-21},
            abstract = {Televised political debates have received much attention
                        by scholars in political communication and social
                        psychology who study nonverbal cues in interpersonal
                        communication and their impact on candidate evaluations.
                        An abundance of political multimedia and new platforms
                        have required leaders to develop an effective and unique
                        communication ``style'' which may rely on nonverbal
                        devices such as face and body. Emotions conveyed by
                        expressive gestures of candidates during debates have
                        been shown to elicit stronger reactions from the public
                        than rhetorical statements alone. Candidates, for example
                        , may exploit assertive and aggressive gestures to
                        communicate their confidence and attract supporters.
                        Existing studies, however, are based largely on manual
                        coding of human gestures, which may not be scalable or
                        reproducible. The main objectives of our paper are to
                        investigate the role of body movements of candidates
                        using a systematic and automated approach as well as
                        understand the context and effects of gestures. For this
                        analysis, we collected a dataset of political debate
                        videos from the 2020 Democratic presidential primaries
                        and analyzed facial expressions and gestures of
                        candidates. Our preliminary analysis demonstrates that
                        candidates employ gestures to varying extents, and the
                        amount of body movement is correlated with emotions
                        conveyed in the candidates' facial expressions. We
                        discuss our dataset, preliminary results, and future
                        directions in the following sections.},
            isbn = {978-3-030-66414-5 978-3-030-66415-2},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/5N58UR6P/Kang et al. - 2020 -
                    Understanding Political Communication Styles in Te.pdf},
}

@article{kingComputerAssistedKeywordDocument2017,
            title = {Computer-{{Assisted Keyword}} and {{Document Set Discovery}
                     } from {{ Unstructured Text}}},
            author = {King, Gary and Lam, Patrick and Roberts, Margaret E.},
            year = {2017},
            journal = {American Journal of Political Science},
            volume = {61},
            number = {4},
            pages = {971--988},
            issn = {1540-5907},
            doi = {10.1111/ajps.12291},
            urldate = {2023-03-09},
            abstract = {The (unheralded) first step in many applications of
                        automated text analysis involves selecting keywords to
                        choose documents from a large text corpus for further
                        study. Although all substantive results depend on this
                        choice, researchers usually pick keywords in ad hoc ways
                        that are far from optimal and usually biased. Most seem
                        to think that keyword selection is easy, since they do
                        Google searches every day, but we demonstrate that humans
                        perform exceedingly poorly at this basic task. We offer a
                        better approach, one that also can help with following
                        conversations where participants rapidly innovate
                        language to evade authorities, seek political advantage,
                        or express creativity; generic web searching; eDiscovery;
                        look-alike modeling; industry and intelligence analysis;
                        and sentiment and topic analysis. We develop a
                        computer-assisted (as opposed to fully automated or
                        human-only) statistical approach that suggests keywords
                        from available text without needing structured data as
                        inputs. This framing poses the statistical problem in a
                        new way, which leads to a widely applicable algorithm.
                        Our specific approach is based on training classifiers,
                        extracting information from (rather than correcting)
                        their mistakes, and summarizing results with
                        easy-to-understand Boolean search strings. We illustrate
                        how the technique works with analyses of English texts
                        about the Boston Marathon bombings, Chinese social media
                        posts designed to evade censorship, and others.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/754QYSEJ/King et al. - 2017 -
                    Computer-Assisted Keyword and Document Set
                    Discove.pdf;/Users/matpi832/Zotero/storage/S48GY9BH/ajps.html
                    },
}

@article{knoxTestingCausalTheories2022,
            title = {Testing {{Causal Theories}} with {{Learned Proxies}}},
            author = {Knox, Dean and Lucas, Christopher and Cho, Wendy K. Tam},
            year = {2022},
            journal = {Annual Review of Political Science},
            volume = {25},
            number = {1},
            pages = {419--441},
            doi = {10.1146/annurev-polisci-051120-111443},
            urldate = {2023-03-16},
            abstract = {Social scientists commonly use computational models to
                        estimate proxies of unobserved concepts, then incorporate
                        these proxies into subsequent tests of their theories.
                        The consequences of this practice, which occurs in over
                        two-thirds of recent computational work in political
                        science, are underappreciated. Imperfect proxies can
                        reflect noise and contamination from other concepts,
                        producing biased point estimates and standard errors. We
                        demonstrate how analysts can use causal diagrams to
                        articulate theoretical concepts and their relationships
                        to estimated proxies, then apply straightforward rules to
                        assess which conclusions are rigorously supportable. We
                        formalize and extend common heuristics for ``signing the
                        bias''\textemdash a technique for reasoning about
                        unobserved confounding\textemdash to scenarios with
                        imperfect proxies. Using these tools, we demonstrate how,
                        in often-encountered research settings, proxy-based
                        analyses allow for valid tests for the existence and
                        direction of theorized effects. We conclude with
                        best-practice recommendations for the rapidly growing
                        literature using learned proxies to test causal theories.
                        },
            keywords = {causal inference,machine learning,measurement,proxies,
                        supervised learning},
            file = {/Users/matpi832/Zotero/storage/2GADAYMD/Knox et al. - 2022 -
                    Testing Causal Theories with Learned Proxies.pdf},
}

@article{kolliosClusteringLargeProbabilistic2013,
            title = {Clustering {{Large Probabilistic Graphs}}},
            author = {Kollios, George and Potamias, Michalis and Terzi, Evimaria
                      },
            year = {2013},
            month = feb,
            journal = {IEEE Transactions on Knowledge and Data Engineering},
            volume = {25},
            number = {2},
            pages = {325--336},
            issn = {1558-2191},
            doi = {10.1109/TKDE.2011.243},
            abstract = {We study the problem of clustering probabilistic graphs.
                        Similar to the problem of clustering standard graphs,
                        probabilistic graph clustering has numerous applications,
                        such as finding complexes in probabilistic
                        protein-protein interaction (PPI) networks and
                        discovering groups of users in affiliation networks. We
                        extend the edit-distance-based definition of graph
                        clustering to probabilistic graphs. We establish a
                        connection between our objective function and correlation
                        clustering to propose practical approximation algorithms
                        for our problem. A benefit of our approach is that our
                        objective function is parameter-free. Therefore, the
                        number of clusters is part of the output. We also develop
                        methods for testing the statistical significance of the
                        output clustering and study the case of noisy
                        clusterings. Using a real protein-protein interaction
                        network and ground-truth data, we show that our methods
                        discover the correct number of clusters and identify
                        established protein relationships. Finally, we show the
                        practicality of our techniques using a large social
                        network of Yahoo! users consisting of one billion edges.},
            keywords = {Approximation algorithms,Approximation methods,
                        clustering algorithms,Clustering algorithms,Data mining,
                        Partitioning algorithms,probabilistic databases,
                        probabilistic graphs, Probabilistic logic,Uncertain data,
                        Uncertainty},
            file = {/Users/matpi832/Zotero/storage/KQRLTK7B/Kollios et al. -
                    2013 - Clustering Large Probabilistic
                    Graphs.pdf;/Users/matpi832/Zotero/storage/EY8DIXBS/6095551.html
                    },
}

@article{kozlowskiGeometryCultureAnalyzing2019,
            title = {The {{Geometry}} of {{Culture}}: {{Analyzing}} the {{
                     Meanings}} of {{ Class}} through {{Word Embeddings}}},
            shorttitle = {The {{Geometry}} of {{Culture}}},
            author = {Kozlowski, Austin C. and Taddy, Matt and Evans, James A.},
            year = {2019},
            month = oct,
            journal = {American Sociological Review},
            volume = {84},
            number = {5},
            pages = {905--949},
            publisher = {{SAGE Publications Inc}},
            issn = {0003-1224},
            doi = {10.1177/0003122419877135},
            urldate = {2023-03-07},
            abstract = {We argue word embedding models are a useful tool for the
                        study of culture using a historical analysis of shared
                        understandings of social class as an empirical case. Word
                        embeddings represent semantic relations between words as
                        relationships between vectors in a high-dimensional space
                        , specifying a relational model of meaning consistent
                        with contemporary theories of culture. Dimensions induced
                        by word differences (rich ? poor) in these spaces
                        correspond to dimensions of cultural meaning, and the
                        projection of words onto these dimensions reflects widely
                        shared associations, which we validate with surveys.
                        Analyzing text from millions of books published over 100
                        years, we show that the markers of class continuously
                        shifted amidst the economic transformations of the
                        twentieth century, yet the basic cultural dimensions of
                        class remained remarkably stable. The notable exception
                        is education, which became tightly linked to affluence
                        independent of its association with cultivated taste.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/TSIU2ZXC/Kozlowski et al. -
                    2019 - The Geometry of Culture Analyzing the Meanings of.pdf},
}

@book{leeuwenHandbookVisualAnalysis2000,
            title = {The {{Handbook}} of {{Visual Analysis}}},
            author = {Leeuwen, Theo Van and Jewitt, Carey},
            year = {2000},
            month = oct,
            publisher = {{SAGE}},
            abstract = {The Handbook of Visual Analysis is a rich methodological
                        resource for students, academics, researchers and
                        professionals interested in investigating the visual
                        representation of socially significant issues. The
                        Handbook: {$\cdot$} Offers a wide-range of methods for
                        visual analysis: content analysis, historical analysis,
                        structuralist analysis, iconography, psychoanalysis,
                        social semiotic analysis, film analysis and
                        ethnomethodology {$\cdot$} Shows how each method can be
                        applied for the purposes of specific research projects. {
                        $\cdot$} Exemplifies each approach through detailed
                        analyses of a variety of data, including, newspaper
                        images , family photos, drawings, art works and cartoons.
                        {$\cdot$} Includes examples from the authors{${'}$} own
                        research and professional practice. The Handbook of
                        Visual Analysis which demonstrates the importance of
                        visual data within the social sciences offers an
                        essential guide to those working in a range of
                        disciplines including: media and communication studies,
                        sociology, anthropology, education, psychoanalysis, and
                        health studies.},
            isbn = {978-1-4462-0537-2},
            langid = {english},
            keywords = {Language Arts \& Disciplines / Communication Studies,
                        Social Science / Anthropology / Cultural \& Social,Social
                        Science / Popular Culture},
}

@inproceedings{loweObjectRecognitionLocal1999,
            title = {Object Recognition from Local Scale-Invariant Features},
            booktitle = {Proceedings of the {{Seventh IEEE International
                         Conference}} on { {Computer Vision}}},
            author = {Lowe, D.G.},
            year = {1999},
            month = sep,
            volume = {2},
            pages = {1150-1157 vol.2},
            doi = {10.1109/ICCV.1999.790410},
            abstract = {An object recognition system has been developed that
                        uses a new class of local image features. The features
                        are invariant to image scaling, translation, and rotation
                        , and partially invariant to illumination changes and
                        affine or 3D projection. These features share similar
                        properties with neurons in inferior temporal cortex that
                        are used for object recognition in primate vision.
                        Features are efficiently detected through a staged
                        filtering approach that identifies stable points in scale
                        space. Image keys are created that allow for local
                        geometric deformations by representing blurred image
                        gradients in multiple orientation planes and at multiple
                        scales. The keys are used as input to a nearest neighbor
                        indexing method that identifies candidate object matches.
                        Final verification of each match is achieved by finding a
                        low residual least squares solution for the unknown model
                        parameters. Experimental results show that robust object
                        recognition can be achieved in cluttered partially
                        occluded images with a computation time of under 2
                        seconds.},
            keywords = {Computer science,Electrical capacitance tomography,
                        Filters,Image recognition,Layout,Lighting,Neurons,Object
                        recognition,Programmable logic arrays,Reactive power},
            file = {/Users/matpi832/Zotero/storage/D5KTQLEN/Lowe - 1999 - Object
                    recognition from local scale-invariant feat.pdf},
}

@article{luPervasivePresenceChinese2022,
            title = {The {{Pervasive Presence}} of {{Chinese Government Content}
                     } on {{ Douyin Trending Videos}}},
            author = {Lu, Yingdan and Pan, Jennifer},
            year = {2022},
            month = feb,
            journal = {Computational Communication Research},
            volume = {4},
            number = {1},
            publisher = {{Amsterdam University Press}},
            issn = {2665-9085},
            doi = {10.5117/CCR2022.2.002.LU},
            urldate = {2023-03-01},
            abstract = {Abstract As audiences have moved to digital media, so
                        too have governments around the world. While previous
                        research has focused on how authoritarian regimes employ
                        strategies such as the use of fabricated accounts and
                        content to boost their reach, this paper reveals two
                        different tactics the Chinese government uses on Douyin ,
                        the Chinese version of the video-sharing platform TikTok,
                        to compete for audience attention. We use a multi-modal
                        approach that combines analysis of video, text, and
                        meta-data to examine a novel dataset of Douyin videos. We
                        find that a large share of trending videos are produced
                        by accounts affiliated with the Chinese government. These
                        videos contain visual characteristics designed to
                        maximize attention such as high levels of brightness and
                        entropy and very short duration, and are more visually
                        similar to content produced by celebrities and ordinary
                        users than to content from non-official media accounts.
                        We also find that the majority of videos produced by
                        regime-affiliated accounts do not fit traditional
                        definitions of propaganda but rather contain stories and
                        topics unrelated to any aspect of the government, the
                        Chinese Communist Party, policies, or politics.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/VMNLESC9/CCR2022.2.002.html},
}

@misc{MachineLearningPredictions,
            title = {Machine {{Learning Predictions}} as {{Regression Covariates
                     }} | {{ Political Analysis}} | {{Cambridge Core}}},
            urldate = {2023-03-08},
            howpublished = {
                            https://www.cambridge.org/core/journals/political-analysis/article/abs/machine-learning-predictions-as-regression-covariates/462A74A46A97C20A17CF640BDA72B826
                            },
            file = {
                    /Users/matpi832/Zotero/storage/TG57WGJY/462A74A46A97C20A17CF640BDA72B826.html
                    },
}

@inproceedings{manikondaModelingUnderstandingVisual2017a,
            title = {Modeling and {{Understanding Visual Attributes}} of {{
                     Mental Health Disclosures}} in {{Social Media}}},
            booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human
                         Factors}} in {{Computing Systems}}},
            author = {Manikonda, Lydia and De Choudhury, Munmun},
            year = {2017},
            month = may,
            pages = {170--181},
            publisher = {{ACM}},
            address = {{Denver Colorado USA}},
            doi = {10.1145/3025453.3025932},
            urldate = {2023-03-21},
            abstract = {Content shared on social media platforms has been
                        identified to be valuable in gaining insights into
                        people's mental health experiences. Although there has
                        been widespread adoption of photo-sharing platforms such
                        as Instagram in recent years, the role of visual imagery
                        as a mechanism of self-disclosure is less understood. We
                        study the nature of visual attributes manifested in
                        images relating to mental health disclosures on
                        Instagram. Employing computer vision techniques on a
                        corpus of thousands of posts, we extract and examine
                        three visual attributes: visual features (e.g., color),
                        themes, and emotions in images. Our findings indicate the
                        use of imagery for unique self-disclosure needs,
                        quantitatively and qualitatively distinct from those
                        shared via the textual modality: expressions of emotional
                        distress, calls for help, and explicit display of
                        vulnerability. We discuss the relationship of our
                        findings to literature in visual sociology, in mental
                        health self-disclosure, and implications for the design
                        of health interventions.},
            isbn = {978-1-4503-4655-9},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/9AJ5AMZD/Manikonda and De
                    Choudhury - 2017 - Modeling and Understanding Visual
                    Attributes of Me.pdf},
}

@article{nelsonComputationalGroundedTheory2020,
            title = {Computational {{Grounded Theory}}: {{A Methodological
                     Framework}}},
            shorttitle = {Computational {{Grounded Theory}}},
            author = {Nelson, Laura K.},
            year = {2020},
            month = feb,
            journal = {Sociological Methods \& Research},
            volume = {49},
            number = {1},
            pages = {3--42},
            publisher = {{SAGE Publications Inc}},
            issn = {0049-1241},
            doi = {10.1177/0049124117729703},
            urldate = {2023-03-21},
            abstract = {This article proposes a three-step methodological
                        framework called computational grounded theory, which
                        combines expert human knowledge and hermeneutic skills
                        with the processing power and pattern recognition of
                        computers, producing a more methodologically rigorous but
                        interpretive approach to content analysis. The first,
                        pattern detection step, involves inductive computational
                        exploration of text, using techniques such as
                        unsupervised machine learning and word scores to help
                        researchers to see novel patterns in their data. The
                        second, pattern refinement step, returns to an
                        interpretive engagement with the data through qualitative
                        deep reading or further exploration of the data. The
                        third, pattern confirmation step, assesses the
                        inductively identified patterns using further
                        computational and natural language processing techniques.
                        The result is an efficient, rigorous, and fully
                        reproducible computational grounded theory. This
                        framework can be applied to any qualitative text as data,
                        including transcribed speeches, interviews, open-ended
                        survey data, or ethnographic field notes, and can address
                        many potential research questions.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/LPTAY962/Nelson - 2020 -
                    Computational Grounded Theory A Methodological Fr.pdf},
}

@article{nelsonFutureCodingComparison2021,
            title = {The {{Future}} of {{Coding}}: {{A Comparison}} of {{
                     Hand-Coding}} and {{Three Types}} of {{Computer-Assisted
                     Text Analysis Methods}}},
            shorttitle = {The {{Future}} of {{Coding}}},
            author = {Nelson, Laura K. and Burk, Derek and Knudsen, Marcel and
                      McCall, Leslie},
            year = {2021},
            month = feb,
            journal = {Sociological Methods \& Research},
            volume = {50},
            number = {1},
            pages = {202--237},
            publisher = {{SAGE Publications Inc}},
            issn = {0049-1241},
            doi = {10.1177/0049124118769114},
            urldate = {2023-03-21},
            abstract = {Advances in computer science and computational
                        linguistics have yielded new, and faster, computational
                        approaches to structuring and analyzing textual data.
                        These approaches perform well on tasks like information
                        extraction, but their ability to identify complex,
                        socially constructed, and unsettled theoretical
                        concepts?a central goal of sociological content
                        analysis?has not been tested. To fill this gap, we
                        compare the results produced by three common
                        computer-assisted approaches?dictionary, supervised
                        machine learning (SML), and unsupervised machine
                        learning?to those produced through a rigorous hand-coding
                        analysis of inequality in the news (N = 1,253 articles).
                        Although we find that SML methods perform best in
                        replicating hand-coded results, we document and clarify
                        the strengths and weaknesses of each approach, including
                        how they can complement one another. We argue that
                        content analysts in the social sciences would do well to
                        keep all these approaches in their toolkit, deploying
                        them purposefully according to the task at hand. },
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/76E5283T/Nelson et al. - 2021
                    - The Future of Coding A Comparison of Hand-Coding .pdf},
}

@inproceedings{ngBotBasedEmotionBehavior2021,
            title = {Bot-{{Based Emotion Behavior Differences}} in {{Images
                     During Kashmir Black Day Event}}},
            booktitle = {Social, {{Cultural}}, and {{Behavioral Modeling}}},
            author = {Ng, Lynnette Hui Xian and Carley, Kathleen M.},
            editor = {Thomson, Robert and Hussain, Muhammad Nihal and Dancy,
                      Christopher and Pyke, Aryn},
            year = {2021},
            series = {Lecture {{Notes}} in {{Computer Science}}},
            pages = {184--194},
            publisher = {{Springer International Publishing}},
            address = {{Cham}},
            doi = {10.1007/978-3-030-80387-2_18},
            abstract = {A picture speaks a thousand words. Images are extremely
                        effective at evoking emotions and presents a potentially
                        damaging force to the health of digital discourse. While
                        text-based emotion analysis has been studied, little work
                        has examined the emotions images invoke on social media
                        platforms. This work analyzes bot-based emotion behavior
                        differences in the images surrounding the 2020 Kashmir
                        Black Day event. Through Twitter data, we observed at
                        least half the agents in the conversation are bots, which
                        dominate image conversations calling for action, e.g.
                        ``Be The Voice of Kashmir''. Sadness and trust dominates
                        the emotions in images. We further analyze a sub-dataset
                        as a case study and discern the role of digital media in
                        heightening online conflicts.},
            isbn = {978-3-030-80387-2},
            langid = {english},
            keywords = {Bot analysis,Emotion analysis,Social cybersecurity},
            file = {/Users/matpi832/Zotero/storage/VC2LYGYP/Ng and Carley - 2021
                    - Bot-Based Emotion Behavior Differences in Images D.pdf},
}

@misc{ngCoordinatedAWebImages2022,
            title = {Coordinated through {{aWeb}} of {{Images}}: {{Analysis}} of
                     {{ Image-based Influence Operations}} from {{China}}, {{Iran
                     }}, {{Russia} }, and {{Venezuela}}},
            shorttitle = {Coordinated through {{aWeb}} of {{Images}}},
            author = {Ng, Lynnette Hui Xian and Moffitt, J. D. and Carley,
                      Kathleen M.},
            year = {2022},
            month = jun,
            number = {arXiv:2206.03576},
            eprint = {2206.03576},
            primaryclass = {cs},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.2206.03576},
            urldate = {2023-03-01},
            abstract = {State-sponsored online influence operations typically
                        consist of coordinated accounts exploiting the online
                        space to influence public opinion. Accounts associated
                        with these operations use images and memes as part of
                        their content generation and dissemination strategy to
                        increase the effectiveness and engagement of the content.
                        In this paper, we present a study of images from the
                        PhoMemes 2022 Challenge originating from the countries
                        China, Iran, Russia, and Venezuela. First, we analyze the
                        coordination of images within and across each country by
                        quantifying image similarity. Then, we construct
                        Image-Image networks and image clusters to identify key
                        themes in the image influence operations. We derive the
                        corresponding Account-Account networks to visualize the
                        interaction between participating accounts within each
                        country. Finally, we interpret the image content and
                        network structure in the broader context of the
                        organization and structure of influence operations in
                        each country.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Social and Information Networks},
            file = {/Users/matpi832/Zotero/storage/8T3NFIZQ/Ng et al. - 2022 -
                    Coordinated through aWeb of Images Analysis of
                    Im.pdf;/Users/matpi832/Zotero/storage/JAPG5UQN/2206.html},
}

@misc{PapersCodeHateCLIPper,
            title = {Papers with {{Code}} - {{Hate-CLIPper}}: {{Multimodal
                     Hateful Meme Classification}} Based on {{Cross-modal
                     Interaction}} of {{CLIP Features}}},
            shorttitle = {Papers with {{Code}} - {{Hate-CLIPper}}},
            urldate = {2023-03-07},
            abstract = {🏆 SOTA for Meme Classification on Tamil Memes (Micro-F1
                        metric)},
            howpublished = {
                            https://paperswithcode.com/paper/hate-clipper-multimodal-hateful-meme
                            },
            langid = {english},
            file = {
                    /Users/matpi832/Zotero/storage/MUNI4RG2/hate-clipper-multimodal-hateful-meme.html
                    },
}

@inproceedings{parkImprovingUnsupervisedImage2021,
            title = {Improving {{Unsupervised Image Clustering With Robust
                     Learning}}},
            booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{
                         Computer Vision}} and {{Pattern Recognition}}},
            author = {Park, Sungwon and Han, Sungwon and Kim, Sundong and Kim,
                      Danu and Park, Sungkyu and Hong, Seunghoon and Cha,
                      Meeyoung},
            year = {2021},
            pages = {12278--12287},
            urldate = {2023-03-17},
            langid = {english},
}

@article{peelStatisticalInferenceLinks2022,
            title = {Statistical Inference Links Data and Theory in Network
                     Science},
            author = {Peel, Leto and Peixoto, Tiago P. and De Domenico, Manlio},
            year = {2022},
            month = nov,
            journal = {Nature Communications},
            volume = {13},
            number = {1},
            pages = {6794},
            issn = {2041-1723},
            doi = {10.1038/s41467-022-34267-9},
            urldate = {2023-02-27},
            abstract = {Abstract The number of network science applications
                        across many different fields has been rapidly increasing.
                        Surprisingly, the development of theory and
                        domain-specific applications often occur in isolation,
                        risking an effective disconnect between theoretical and
                        methodological advances and the way network science is
                        employed in practice. Here we address this risk
                        constructively, discussing good practices to guarantee
                        more successful applications and reproducible results. We
                        endorse designing statistically grounded methodologies to
                        address challenges in network science. This approach
                        allows one to explain observational data in terms of
                        generative models, naturally deal with intrinsic
                        uncertainties, and strengthen the link between theory and
                        applications.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/VVLMYISG/Peel et al. - 2022 -
                    Statistical inference links data and theory in net.pdf},
}

@article{pengWhatMakesPoliticians2021,
            title = {What {{Makes Politicians}}' {{Instagram Posts Popular}}? {{
                     Analyzing Social Media Strategies}} of {{Candidates}} and {{
                     Office Holders}} with {{Computer Vision}}},
            shorttitle = {What {{Makes Politicians}}' {{Instagram Posts Popular}
                          }?},
            author = {Peng, Yilang},
            year = {2021},
            month = jan,
            journal = {The International Journal of Press/Politics},
            volume = {26},
            number = {1},
            pages = {143--166},
            publisher = {{SAGE Publications Inc}},
            issn = {1940-1612},
            doi = {10.1177/1940161220964769},
            urldate = {2023-03-01},
            abstract = {Previous research on the success of politicians?
                        messages on social media has so far focused on a limited
                        number of platforms, especially Facebook and Twitter, and
                        predominately studied the effects of textual content.
                        This research reported here applies computer vision
                        analysis to a total of 59,020 image posts published by
                        172 Instagram accounts of U.S. politicians, both
                        candidates and office holders, and examines how visual
                        attributes influence audience engagement such as likes
                        and comments. In particular, this study introduces an
                        unsupervised approach that combines transfer learning and
                        clustering techniques to discover hidden categories from
                        large-scale visual data. The results reveal that
                        different self-personalization strategies in visual media
                        , for example, images featuring politicians in private,
                        nonpolitical settings, showing faces, and displaying
                        emotions, generally increase audience engagement. Yet, a
                        significant portion of politician?s Instagram posts still
                        fell into the traditional, ?politics-as-usual? type of
                        political communication, showing professional settings
                        and activities. The analysis explains how
                        self-personalization is embodied in specific visual
                        portrayals and how different self-presentation strategies
                        affect audience engagement on a popular but less studied
                        social media platform.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/Q8KA5H7W/Peng - 2021 - What
                    Makes Politicians’ Instagram Posts Popular A.pdf},
}

@inproceedings{perozziDeepWalkOnlineLearning2014,
            title = {{{DeepWalk}}: {{Online Learning}} of {{Social
                     Representations}}},
            shorttitle = {{{DeepWalk}}},
            booktitle = {Proceedings of the 20th {{ACM SIGKDD}} International
                         Conference on {{Knowledge}} Discovery and Data Mining},
            author = {Perozzi, Bryan and {Al-Rfou}, Rami and Skiena, Steven},
            year = {2014},
            month = aug,
            eprint = {1403.6652},
            primaryclass = {cs},
            pages = {701--710},
            doi = {10.1145/2623330.2623732},
            urldate = {2023-03-02},
            abstract = {We present DeepWalk, a novel approach for learning
                        latent representations of vertices in a network. These
                        latent representations encode social relations in a
                        continuous vector space, which is easily exploited by
                        statistical models. DeepWalk generalizes recent
                        advancements in language modeling and unsupervised
                        feature learning (or deep learning) from sequences of
                        words to graphs. DeepWalk uses local information obtained
                        from truncated random walks to learn latent
                        representations by treating walks as the equivalent of
                        sentences. We demonstrate DeepWalk's latent
                        representations on several multi-label network
                        classification tasks for social networks such as
                        BlogCatalog, Flickr, and YouTube. Our results show that
                        DeepWalk outperforms challenging baselines which are
                        allowed a global view of the network, especially in the
                        presence of missing information. DeepWalk's
                        representations can provide \$F\_1\$ scores up to 10\%
                        higher than competing methods when labeled data is
                        sparse. In some experiments, DeepWalk's representations
                        are able to outperform all baseline methods while using
                        60\% less training data. DeepWalk is also scalable. It is
                        an online learning algorithm which builds useful
                        incremental results, and is trivially parallelizable.
                        These qualities make it suitable for a broad class of
                        real world applications such as network classification,
                        and anomaly detection. },
            archiveprefix = {arxiv},
            keywords = {Computer Science - Machine Learning,Computer Science -
                        Social and Information Networks,H.2.8,I.2.6,I.5.1},
            file = {/Users/matpi832/Zotero/storage/7TC6SEDL/Perozzi et al. -
                    2014 - DeepWalk Online Learning of Social
                    Representation.pdf;/Users/matpi832/Zotero/storage/BP5X5RCJ/1403.html
                    },
}

@misc{quEvolutionHatefulMemes2022,
            title = {On the {{Evolution}} of ({{Hateful}}) {{Memes}} by {{Means}
                     } of {{ Multimodal Contrastive Learning}}},
            author = {Qu, Yiting and He, Xinlei and Pierson, Shannon and Backes,
                      Michael and Zhang, Yang and Zannettou, Savvas},
            year = {2022},
            month = dec,
            number = {arXiv:2212.06573},
            eprint = {2212.06573},
            primaryclass = {cs},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.2212.06573},
            urldate = {2023-03-01},
            abstract = {The dissemination of hateful memes online has adverse
                        effects on social media platforms and the real world.
                        Detecting hateful memes is challenging, one of the
                        reasons being the evolutionary nature of memes; new
                        hateful memes can emerge by fusing hateful connotations
                        with other cultural ideas or symbols. In this paper, we
                        propose a framework that leverages multimodal contrastive
                        learning models, in particular OpenAI's CLIP, to identify
                        targets of hateful content and systematically investigate
                        the evolution of hateful memes. We find that semantic
                        regularities exist in CLIP-generated embeddings that
                        describe semantic relationships within the same modality
                        (images) or across modalities (images and text).
                        Leveraging this property, we study how hateful memes are
                        created by combining visual elements from multiple images
                        or fusing textual information with a hateful image. We
                        demonstrate the capabilities of our framework for
                        analyzing the evolution of hateful memes by focusing on
                        antisemitic memes, particularly the Happy Merchant meme.
                        Using our framework on a dataset extracted from 4chan, we
                        find 3.3K variants of the Happy Merchant meme, with some
                        linked to specific countries, persons, or organizations.
                        We envision that our framework can be used to aid human
                        moderators by flagging new variants of hateful memes so
                        that moderators can manually verify them and mitigate the
                        problem of hateful content online.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Computers and Society,Computer
                        Science - Cryptography and Security,Computer Science -
                        Machine Learning, Computer Science - Social and
                        Information Networks},
            file = {/Users/matpi832/Zotero/storage/MQI5ABP6/Qu et al. - 2022 -
                    On the Evolution of (Hateful) Memes by Means of
                    Mu.pdf;/Users/matpi832/Zotero/storage/5LU8DFIP/2212.html},
}

@article{quinnHowAnalyzePolitical2010,
            title = {How to {{Analyze Political Attention}} with {{Minimal
                     Assumptions}} and {{Costs}}},
            author = {Quinn, Kevin M. and Monroe, Burt L. and Colaresi, Michael
                      and Crespin, Michael H. and Radev, Dragomir R.},
            year = {2010},
            journal = {American Journal of Political Science},
            volume = {54},
            number = {1},
            pages = {209--228},
            issn = {1540-5907},
            doi = {10.1111/j.1540-5907.2009.00427.x},
            urldate = {2023-03-22},
            abstract = {Previous methods of analyzing the substance of political
                        attention have had to make several restrictive
                        assumptions or been prohibitively costly when applied to
                        large-scale political texts. Here, we describe a topic
                        model for legislative speech, a statistical learning
                        model that uses word choices to infer topical categories
                        covered in a set of speeches and to identify the topic of
                        specific speeches. Our method estimates, rather than
                        assumes, the substance of topics, the keywords that
                        identify topics, and the hierarchical nesting of topics.
                        We use the topic model to examine the agenda in the U.S.
                        Senate from 1997 to 2004. Using a new database of over
                        118,000 speeches (70,000,000 words) from the
                        Congressional Record, our model reveals speech topic
                        categories that are both distinctive and meaningfully
                        interrelated and a richer view of democratic agenda
                        dynamics than had previously been possible.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/4FKILV46/Quinn et al. - 2010
                    - How to Analyze Political Attention with Minimal
                    As.pdf;/Users/matpi832/Zotero/storage/78WFD9DE/j.1540-5907.2009.00427.html
                    },
}

@misc{radfordLearningTransferableVisual2021,
            title = {Learning {{Transferable Visual Models From Natural Language
                     Supervision}}},
            author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and
                      Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and
                      Sastry, Girish and Askell, Amanda and Mishkin, Pamela and
                      Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
            year = {2021},
            month = feb,
            number = {arXiv:2103.00020},
            eprint = {2103.00020},
            primaryclass = {cs},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.2103.00020},
            urldate = {2023-03-02},
            abstract = {State-of-the-art computer vision systems are trained to
                        predict a fixed set of predetermined object categories.
                        This restricted form of supervision limits their
                        generality and usability since additional labeled data is
                        needed to specify any other visual concept. Learning
                        directly from raw text about images is a promising
                        alternative which leverages a much broader source of
                        supervision. We demonstrate that the simple pre-training
                        task of predicting which caption goes with which image is
                        an efficient and scalable way to learn SOTA image
                        representations from scratch on a dataset of 400 million
                        (image, text) pairs collected from the internet. After
                        pre-training, natural language is used to reference
                        learned visual concepts (or describe new ones) enabling
                        zero-shot transfer of the model to downstream tasks. We
                        study the performance of this approach by benchmarking on
                        over 30 different existing computer vision datasets,
                        spanning tasks such as OCR, action recognition in videos,
                        geo-localization, and many types of fine-grained object
                        classification. The model transfers non-trivially to most
                        tasks and is often competitive with a fully supervised
                        baseline without the need for any dataset specific
                        training. For instance, we match the accuracy of the
                        original ResNet-50 on ImageNet zero-shot without needing
                        to use any of the 1.28 million training examples it was
                        trained on. We release our code and pre-trained model
                        weights at https://github.com/OpenAI/CLIP.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Computer Vision and Pattern
                        Recognition, Computer Science - Machine Learning},
            file = {/Users/matpi832/Zotero/storage/ERIAH6BG/Radford et al. -
                    2021 - Learning Transferable Visual Models From Natural
                    L.pdf;/Users/matpi832/Zotero/storage/PC7NKNLA/Radford et al.
                    - 2021 - Learning Transferable Visual Models From Natural
                    L.pdf;/Users/matpi832/Zotero/storage/LJR65YF3/2103.html},
}

@article{ralundMeasurementErrorModel2022,
            title = {Measurement Error and Model Instability in Automated Text
                     Analysis: The Case of Topic Models},
            shorttitle = {Measurement Error and Model Instability in Automated
                          Text Analysis},
            author = {Ralund, Snorre and Carlsen, Hjalmar Bang and Klemmensen,
                      Robert and Lassen, David Dreyer},
            year = {2022},
            publisher = {{SocArXiv}},
            file = {/Users/matpi832/Zotero/storage/Z9WRGUGD/Ralund et al. - 2022
                    - Measurement error and model instability in automat.pdf},
}

@article{robertsStmPackageStructural2019,
            title = {Stm: {{An R Package}} for {{Structural Topic Models}}},
            shorttitle = {Stm},
            author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley,
                      Dustin},
            year = {2019},
            month = oct,
            journal = {Journal of Statistical Software},
            volume = {91},
            pages = {1--40},
            issn = {1548-7660},
            doi = {10.18637/jss.v091.i02},
            urldate = {2023-03-03},
            abstract = {This paper demonstrates how to use the R package stm for
                        structural topic modeling. The structural topic model
                        allows researchers to flexibly estimate a topic model
                        that includes document-level metadata. Estimation is
                        accomplished through a fast variational approximation.
                        The stm package provides many useful features, including
                        rich ways to explore topics, estimate uncertainty, and
                        visualize quantities of interest.},
            copyright = {Copyright (c) 2019 Margaret E. Roberts, Brandon M.
                         Stewart, Dustin Tingley},
            langid = {english},
            keywords = {LDA,R,stm,structural topic model,text analysis},
            file = {/Users/matpi832/Zotero/storage/CLKT4XXB/Roberts et al. -
                    2019 - stm An R Package for Structural Topic Models.pdf},
}

@article{robertsStructuralTopicModels2014,
            title = {Structural {{Topic Models}} for {{Open-Ended Survey
                     Responses}}},
            author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley,
                      Dustin and Lucas, Christopher and {Leder-Luis}, Jetson and
                      Gadarian, Shana Kushner and Albertson, Bethany and Rand,
                      David G.},
            year = {2014},
            journal = {American Journal of Political Science},
            volume = {58},
            number = {4},
            pages = {1064--1082},
            issn = {1540-5907},
            doi = {10.1111/ajps.12103},
            urldate = {2023-03-08},
            abstract = {Collection and especially analysis of open-ended survey
                        responses are relatively rare in the discipline and when
                        conducted are almost exclusively done through human
                        coding. We present an alternative, semiautomated approach
                        , the structural topic model (STM) (Roberts, Stewart, and
                        Airoldi 2013; Roberts et al. 2013), that draws on recent
                        developments in machine learning based analysis of
                        textual data. A crucial contribution of the method is
                        that it incorporates information about the document, such
                        as the author's gender, political affiliation, and
                        treatment assignment (if an experimental study). This
                        article focuses on how the STM is helpful for survey
                        researchers and experimentalists. The STM makes analyzing
                        open-ended responses easier, more revealing, and capable
                        of being used to estimate treatment effects. We
                        illustrate these innovations with analysis of text from
                        surveys and experiments.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/SUZZ8LTI/Roberts et al. -
                    2014 - Structural Topic Models for Open-Ended Survey
                    Resp.pdf;/Users/matpi832/Zotero/storage/NKI7L9PW/ajps.html},
}

@article{rousseeuwSilhouettesGraphicalAid1987,
            title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and
                     Validation of Cluster Analysis},
            shorttitle = {Silhouettes},
            author = {Rousseeuw, Peter J.},
            year = {1987},
            month = nov,
            journal = {Journal of Computational and Applied Mathematics},
            volume = {20},
            pages = {53--65},
            issn = {0377-0427},
            doi = {10.1016/0377-0427(87)90125-7},
            urldate = {2023-03-09},
            abstract = {A new graphical display is proposed for partitioning
                        techniques. Each cluster is represented by a so-called
                        silhouette, which is based on the comparison of its
                        tightness and separation. This silhouette shows which
                        objects lie well within their cluster, and which ones are
                        merely somewhere in between clusters. The entire
                        clustering is displayed by combining the silhouettes into
                        a single plot, allowing an appreciation of the relative
                        quality of the clusters and an overview of the data
                        configuration. The average silhouette width provides an
                        evaluation of clustering validity, and might be used to
                        select an `appropriate' number of clusters.},
            langid = {english},
            keywords = {classification,cluster analysis,clustering validity,
                        Graphical display},
            file = {/Users/matpi832/Zotero/storage/JEVR47DS/Rousseeuw - 1987 -
                    Silhouettes A graphical aid to the
                    interpretation.pdf;/Users/matpi832/Zotero/storage/CGX7GK9M/0377042787901257.html
                    },
}

@article{ruleLexicalShiftsSubstantive2015,
            title = {Lexical Shifts, Substantive Changes, and Continuity in {{
                     State}} of the {{Union}} Discourse, 1790\textendash 2014},
            author = {Rule, Alix and Cointet, Jean-Philippe and Bearman, Peter
                      S.},
            year = {2015},
            month = sep,
            journal = {Proceedings of the National Academy of Sciences},
            volume = {112},
            number = {35},
            pages = {10837--10844},
            publisher = {{Proceedings of the National Academy of Sciences}},
            doi = {10.1073/pnas.1512221112},
            urldate = {2023-03-02},
            abstract = {This study reveals that the entry into World War I in
                        1917 indexed the decisive transition to the modern period
                        in American political consciousness, ushering in new
                        objects of political discourse, a more rapid pace of
                        change of those objects, and a fundamental reframing of
                        the main tasks of governance. We develop a strategy for
                        identifying meaningful categories in textual corpora that
                        span long historic dur\'ees, where terms, concepts, and
                        language use changes. Our approach is able to account for
                        the fluidity of discursive categories over time, and to
                        analyze their continuity by identifying the discursive
                        stream as the object of interest.},
            file = {/Users/matpi832/Zotero/storage/H9UFJ4XX/Rule et al. - 2015 -
                    Lexical shifts, substantive changes, and continuit.pdf},
}

@article{russakovskyImageNetLargeScale2015,
            title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
            author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause,
                      Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang,
                      Zhiheng and Karpathy, Andrej and Khosla, Aditya and
                      Bernstein, Michael and Berg, Alexander C. and {Fei-Fei}, Li
                      },
            year = {2015},
            month = dec,
            journal = {International Journal of Computer Vision},
            volume = {115},
            number = {3},
            pages = {211--252},
            issn = {1573-1405},
            doi = {10.1007/s11263-015-0816-y},
            urldate = {2023-03-22},
            abstract = {The ImageNet Large Scale Visual Recognition Challenge is
                        a benchmark in object category classification and
                        detection on hundreds of object categories and millions
                        of images. The challenge has been run annually from 2010
                        to present, attracting participation from more than fifty
                        institutions. This paper describes the creation of this
                        benchmark dataset and the advances in object recognition
                        that have been possible as a result. We discuss the
                        challenges of collecting large-scale ground truth
                        annotation, highlight key breakthroughs in categorical
                        object recognition, provide a detailed analysis of the
                        current state of the field of large-scale image
                        classification and object detection, and compare the
                        state-of-the-art computer vision accuracy with human
                        accuracy. We conclude with lessons learned in the 5~years
                        of the challenge, and propose future directions and
                        improvements.},
            langid = {english},
            keywords = {Benchmark,Dataset,Large-scale,Object detection,Object
                        recognition},
}

@misc{schwemmerAutomatedImageAnalysis2022,
            title = {Automated {{Image Analysis}} for {{Studying Online
                     Behaviour}}},
            author = {Schwemmer, Carsten and Unger, Sa{\"i}d and Heiberger,
                      Raphael},
            year = {2022},
            month = apr,
            publisher = {{SocArXiv}},
            doi = {10.31235/osf.io/t62sd},
            urldate = {2023-03-01},
            abstract = {Digitization led to an enormous increase in the
                        availability of visual data. As images are an important
                        aspect of human communication, decades of social science
                        research have analysed images, yet in mostly manual
                        fashion with limited scaling capacities. In this work, we
                        outline how recent advances in computer vision enable
                        automated image analysis, allowing researchers to further
                        unlock the potential of digital behavioural data. We
                        introduce the field of computational social science and
                        conduct a literature review of early studies using image
                        recognition. We also highlight important aspects to be
                        considered, such as computational demands and biases of
                        computer vision models. Furthermore, in a case study, we
                        examine the online behaviour of U.S. Members of Congress
                        during the early COVID-19 pandemic in 2020. In particular
                        , we focus on sharing images showing face masks as they
                        are a crucial aspect of health and safety measures during
                        the pandemic. Using Instagram data and models for
                        detecting face masks, we find that temporal dynamics and
                        party affiliation play a substantial role in the
                        likelihood of sharing images of people wearing face
                        masks: images with masks are more often posted after the
                        introduction of mask mandates and Democratic party
                        members are more likely to share images with masks. In
                        addition, we find somewhat weaker to no differences
                        regarding the age and gender of politicians.},
            langid = {american},
            keywords = {Social and Behavioral Sciences,Sociology},
            file = {/Users/matpi832/Zotero/storage/GYBDIAUS/Schwemmer et al. -
                    2022 - Automated Image Analysis for Studying Online Behav.pdf
                    },
}

@inproceedings{terragniOCTISComparingOptimizing2021,
            title = {{{OCTIS}}: {{Comparing}} and {{Optimizing Topic}} Models Is
                     {{Simple} }!},
            shorttitle = {{{OCTIS}}},
            booktitle = {Proceedings of the 16th {{Conference}} of the {{
                         European Chapter} } of the {{Association}} for {{
                         Computational Linguistics}}: {{ System Demonstrations}}},
            author = {Terragni, Silvia and Fersini, Elisabetta and Galuzzi,
                      Bruno Giovanni and Tropeano, Pietro and Candelieri, Antonio
                      },
            year = {2021},
            month = apr,
            pages = {263--270},
            publisher = {{Association for Computational Linguistics}},
            address = {{Online}},
            doi = {10.18653/v1/2021.eacl-demos.31},
            urldate = {2023-03-21},
            abstract = {In this paper, we present OCTIS, a framework for
                        training, analyzing, and comparing Topic Models, whose
                        optimal hyper-parameters are estimated using a Bayesian
                        Optimization approach. The proposed solution integrates
                        several state-of-the-art topic models and evaluation
                        metrics. These metrics can be targeted as objective by
                        the underlying optimization procedure to determine the
                        best hyper-parameter configuration. OCTIS allows
                        researchers and practitioners to have a fair comparison
                        between topic models of interest, using several benchmark
                        datasets and well-known evaluation metrics, to integrate
                        novel algorithms, and to have an interactive
                        visualization of the results for understanding the
                        behavior of each model. The code is available at the
                        following link: https://github.com/MIND-Lab/OCTIS.},
}

@article{torresLearningSeeConvolutional2022,
            title = {Learning to {{See}}: {{Convolutional Neural Networks}} for
                     the {{ Analysis}} of {{Social Science Data}}},
            shorttitle = {Learning to {{See}}},
            author = {Torres, Michelle and Cant{\'u}, Francisco},
            year = {2022},
            month = jan,
            journal = {Political Analysis},
            volume = {30},
            number = {1},
            pages = {113--131},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1017/pan.2021.9},
            urldate = {2023-03-08},
            abstract = {We provide an introduction of the functioning,
                        implementation, and challenges of convolutional neural
                        networks (CNNs) to classify visual information in social
                        sciences. This tool can help scholars to make more
                        efficient the tedious task of classifying images and
                        extracting information from them. We illustrate the
                        implementation and impact of this methodology by coding
                        handwritten information from vote tallies. Our paper not
                        only demonstrates the contributions of CNNs to both
                        scholars and policy practitioners, but also presents the
                        practical challenges and limitations of the method,
                        providing advice on how to deal with these issues.},
            langid = {english},
            keywords = {computer vision,deep learning,Image analysis,neural
                        network},
            file = {/Users/matpi832/Zotero/storage/PYBK4KQB/Torres and Cantú -
                    2022 - Learning to See Convolutional Neural Networks for.pdf},
}

@article{uppalaContagionConfoundingCausality2023,
            title = {Contagion, {{Confounding}}, and {{Causality}}: {{
                     Confronting}} the {{ Three C}}'s of {{Observational
                     Political Networks Research}}},
            shorttitle = {Contagion, {{Confounding}}, and {{Causality}}},
            author = {Uppala, Medha and Desmarais, Bruce A.},
            year = {2023},
            month = jan,
            journal = {Political Analysis},
            pages = {1--8},
            publisher = {{Cambridge University Press}},
            issn = {1047-1987, 1476-4989},
            doi = {10.1017/pan.2022.35},
            urldate = {2023-03-02},
            abstract = {Contagion across various types of connections is a
                        central process in the study of many political phenomena
                        (e.g., democratization, civil conflict, and voter
                        turnout). Over the last decade, the methodological
                        literature addressing the challenges in causally
                        identifying contagion in networks has exploded. In one of
                        the foundational works in this literature, Shalizi and
                        Thomas (2011, Sociological Methods and Research 40, 211
                        \textendash 239.) propose a permutation test for
                        contagion in longitudinal network data that is not
                        confounded by selection (e.g., homophily). We illustrate
                        the properties of this test via simulation. We assess its
                        statistical power under various conditions of the data,
                        including the nature of the contagion, the structure of
                        the network through which contagion occurs, and the
                        number of time periods included in the data. We then
                        apply this test to an example domain that is commonly
                        considered in the context of observational research on
                        contagion \textemdash the international spread of
                        democracy. We find evidence of international contagion of
                        democracy. We conclude with a discussion of the practical
                        applicability of the Shalizi and Thomas test to the study
                        of contagion in political networks.},
            langid = {english},
            keywords = {contagion,homophily,social networks},
            file = {/Users/matpi832/Zotero/storage/UF2CTHAD/Uppala and Desmarais
                    - 2023 - Contagion, Confounding, and Causality
                    Confronting.pdf},
}

@article{waggonerUnsupervisedMachineLearning2020,
            title = {Unsupervised {{Machine Learning}} for {{Clustering}} in {{
                     Political}} and {{Social Research}}},
            author = {Waggoner, Philip D.},
            year = {2020},
            month = dec,
            journal = {Elements in Quantitative and Computational Methods for
                       the Social Sciences},
            publisher = {{Cambridge University Press}},
            doi = {10.1017/9781108883955},
            urldate = {2023-03-21},
            abstract = {Cambridge Core - Research Methods In Politics -
                        Unsupervised Machine Learning for Clustering in Political
                        and Social Research},
            isbn = {9781108883955 9781108793384},
            langid = {english},
            file = {
                    /Users/matpi832/Zotero/storage/3GHHXRBK/BF62D1E8F6DB3237D5CE524FBFCBA33A.html
                    },
}

@article{wangCVAPValidationCluster2009,
            title = {{{CVAP}}: {{Validation}} for {{Cluster Analyses}}},
            shorttitle = {{{CVAP}}},
            author = {Wang, Kaijun and Wang, Baijie and Peng, Liuqing},
            year = {2009},
            journal = {Data Science Journal},
            volume = {8},
            pages = {88--93},
            doi = {10.2481/dsj.007-020},
            abstract = {Evaluation of clustering results (or cluster validation)
                        is an important and necessary step in cluster analysis,
                        but it is often time-consuming and complicated work. We
                        present a visual cluster validation tool, the Cluster
                        Validity Analysis Platform (CVAP), to facilitate cluster
                        validation. The CVAP provides necessary methods (e.g.,
                        many validity indices, several clustering algorithms and
                        procedures) and an analysis environment for clustering,
                        evaluation of clustering results, estimation of the
                        number of clusters, and performance comparison among
                        different clustering algorithms. It can help users
                        accomplish their clustering tasks faster and easier and
                        help achieve good clustering quality when there is little
                        prior knowledge about the cluster structure of a data
                        set.},
            keywords = {Cluster validation,Validity indices,Visual cluster
                        analysis environment},
            file = {/Users/matpi832/Zotero/storage/3K86PIK5/Wang et al. - 2009 -
                    CVAP Validation for Cluster
                    Analyses.pdf;/Users/matpi832/Zotero/storage/UJR9TBHY/ja.html},
}

@article{wilkersonLargeScaleComputerizedText2017,
            title = {Large-{{Scale Computerized Text Analysis}} in {{Political
                     Science}}: {{Opportunities}} and {{Challenges}}},
            shorttitle = {Large-{{Scale Computerized Text Analysis}} in {{
                          Political Science}}},
            author = {Wilkerson, John and Casas, Andreu},
            year = {2017},
            journal = {Annual Review of Political Science},
            volume = {20},
            number = {1},
            pages = {529--544},
            doi = {10.1146/annurev-polisci-052615-025542},
            urldate = {2023-03-08},
            abstract = {Text has always been an important data source in
                        political science. What has changed in recent years is
                        the feasibility of investigating large amounts of text
                        quantitatively. The internet provides political
                        scientists with more data than their mentors could have
                        imagined, and the research community is providing
                        accessible text analysis software packages, along with
                        training and support. As a result, text-as-data research
                        is becoming mainstream in political science. Scholars are
                        tapping new data sources, they are employing more diverse
                        methods, and they are becoming critical consumers of
                        findings based on those methods. In this article, we
                        first describe the four stages of a typical text-as-data
                        project. We then review recent political science
                        applications and explore one important methodological
                        challenge\textemdash topic model instability\textemdash
                        in greater detail.},
            keywords = {automatic coding,computational social sciences,machine
                        learning, text as data},
            file = {/Users/matpi832/Zotero/storage/83JIAEFW/Wilkerson and Casas
                    - 2017 - Large-Scale Computerized Text Analysis in
                    Politica.pdf},
}

@article{williamsImagesDataSocial2020,
            title = {Images as {{Data}} for {{Social Science Research}}: {{An
                     Introduction }} to {{Convolutional Neural Nets}} for {{Image
                     Classification}}},
            shorttitle = {Images as {{Data}} for {{Social Science Research}}},
            author = {Williams, Nora Webb and Casas, Andreu and Wilkerson, John
                      D.},
            year = {2020},
            month = jul,
            journal = {Elements in Quantitative and Computational Methods for
                       the Social Sciences},
            publisher = {{Cambridge University Press}},
            doi = {10.1017/9781108860741},
            urldate = {2023-03-02},
            abstract = {Cambridge Core - Research Methods in Politics - Images
                        as Data for Social Science Research},
            isbn = {9781108860741 9781108816854},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/VKRG8LTS/Williams et al. -
                    2020 - Images as Data for Social Science Research An
                    Int.pdf;/Users/matpi832/Zotero/storage/M39DRY2R/0376EE8A7A21F5B47FC4EC24DF07EFE9.html
                    },
}

@misc{wortsmanRobustFinetuningZeroshot2022,
            title = {Robust Fine-Tuning of Zero-Shot Models},
            author = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook
                      and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and
                      {Gontijo-Lopes}, Raphael and Hajishirzi, Hannaneh and
                      Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
            year = {2022},
            month = jun,
            number = {arXiv:2109.01903},
            eprint = {2109.01903},
            primaryclass = {cs},
            publisher = {{arXiv}},
            doi = {10.48550/arXiv.2109.01903},
            urldate = {2023-03-02},
            abstract = {Large pre-trained models such as CLIP or ALIGN offer
                        consistent accuracy across a range of data distributions
                        when performing zero-shot inference (i.e., without
                        fine-tuning on a specific dataset). Although existing
                        fine-tuning methods substantially improve accuracy on a
                        given target distribution, they often reduce robustness
                        to distribution shifts. We address this tension by
                        introducing a simple and effective method for improving
                        robustness while fine-tuning: ensembling the weights of
                        the zero-shot and fine-tuned models (WiSE-FT). Compared
                        to standard fine-tuning, WiSE-FT provides large accuracy
                        improvements under distribution shift, while preserving
                        high accuracy on the target distribution. On ImageNet and
                        five derived distribution shifts, WiSE-FT improves
                        accuracy under distribution shift by 4 to 6 percentage
                        points (pp) over prior work while increasing ImageNet
                        accuracy by 1.6 pp. WiSE-FT achieves similarly large
                        robustness gains (2 to 23 pp) on a diverse set of six
                        further distribution shifts, and accuracy gains of 0.8 to
                        3.3 pp compared to standard fine-tuning on seven commonly
                        used transfer learning datasets. These improvements come
                        at no additional computational cost during fine-tuning or
                        inference.},
            archiveprefix = {arxiv},
            keywords = {Computer Science - Computer Vision and Pattern
                        Recognition, Computer Science - Machine Learning},
            file = {/Users/matpi832/Zotero/storage/2EG3Z93L/Wortsman et al. -
                    2022 - Robust fine-tuning of zero-shot
                    models.pdf;/Users/matpi832/Zotero/storage/GCXDFUM9/2109.html},
}

@article{xiUnderstandingPoliticalIdeology2020,
            title = {Understanding the {{Political Ideology}} of {{Legislators}}
                     from {{ Social Media Images}}},
            author = {Xi, Nan and Ma, Di and Liou, Marcus and {
                      Steinert-Threlkeld}, Zachary C. and Anastasopoulos, Jason
                      and Joo, Jungseock},
            year = {2020},
            month = may,
            journal = {Proceedings of the International AAAI Conference on Web
                       and Social Media},
            volume = {14},
            pages = {726--737},
            issn = {2334-0770},
            doi = {10.1609/icwsm.v14i1.7338},
            urldate = {2023-03-02},
            abstract = {In this paper, we seek to understand how politicians use
                        images to express ideological rhetoric through Facebook
                        images posted by members of the U.S. House and Senate. In
                        the era of social media, politics has become saturated
                        with imagery, a potent and emotionally salient form of
                        political rhetoric which has been used by politicians and
                        political organizations to influence public sentiment and
                        voting behavior for well over a century. To date, however
                        , little is known about how images are used as political
                        rhetoric. Using deep learning techniques to automatically
                        predict Republican or Democratic party affiliation solely
                        from the Facebook photographs of the members of the 114th
                        U.S. Congress, we demonstrate that predicted class
                        probabilities from our model function as an accurate
                        proxy of the political ideology of images along a left
                        \textendash right (liberal\textendash conservative)
                        dimension. After controlling for the gender and race of
                        politicians , our method achieves an accuracy of 59.28\%
                        from single photographs and 82.35\% when aggregating
                        scores from multiple photographs (up to 150) of the same
                        person. To better understand image content distinguishing
                        liberal from conservative images, we also perform
                        in-depth content analyses of the photographs. Our
                        findings suggest that conservatives tend to use more
                        images supporting status quo political institutions and
                        hierarchy maintenance, featuring individuals from
                        dominant social groups, and displaying greater happiness
                        than liberals.},
            copyright = {Copyright (c) 2020 Association for the Advancement of
                         Artificial Intelligence},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/W6BG9B6C/Xi et al. - 2020 -
                    Understanding the Political Ideology of Legislator.pdf},
}

@article{zannettouCharacterizingUseImages2020,
            title = {Characterizing the {{Use}} of {{Images}} in {{
                     State-Sponsored Information Warfare Operations}} by {{
                     Russian Trolls}} on {{Twitter}}},
            author = {Zannettou, Savvas and Caulfield, Tristan and Bradlyn,
                      Barry and Cristofaro, Emiliano De and Stringhini, Gianluca
                      and Blackburn, Jeremy},
            year = {2020},
            month = may,
            journal = {Proceedings of the International AAAI Conference on Web
                       and Social Media},
            volume = {14},
            pages = {774--785},
            issn = {2334-0770},
            doi = {10.1609/icwsm.v14i1.7342},
            urldate = {2023-03-08},
            abstract = {State-sponsored organizations are increasingly linked to
                        efforts aimed to exploit social media for information
                        warfare and manipulating public opinion. Typically, their
                        activities rely on a number of social network accounts
                        they control, aka trolls, that post and interact with
                        other users disguised as ``regular'' users. These
                        accounts often use images and memes, along with textual
                        content, in order to increase the engagement and the
                        credibility of their posts.In this paper, we present the
                        first study of images shared by state-sponsored accounts
                        by analyzing a ground truth dataset of 1.8M images posted
                        to Twitter by accounts controlled by the Russian Internet
                        Research Agency. First, we analyze the content of the
                        images as well as their posting activity. Then, using
                        Hawkes Processes, we quantify their influence on popular
                        Web communities like Twitter, Reddit, 4chan's Politically
                        Incorrect board (/pol/), and Gab, with respect to the
                        dissemination of images. We find that the extensive image
                        posting activity of Russian trolls coincides with
                        real-world events (e.g., the Unite the Right rally in
                        Charlottesville), and shed light on their targets as well
                        as the content disseminated via images. Finally, we show
                        that the trolls were more effective in disseminating
                        politics-related imagery than other images.},
            copyright = {Copyright (c) 2020 Association for the Advancement of
                         Artificial Intelligence},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/J6L7VC8K/Zannettou et al. -
                    2020 - Characterizing the Use of Images in State-Sponsore.pdf
                    },
}

@article{zhangFrameworkDeepConstrained2021,
            title = {A Framework for Deep Constrained Clustering},
            author = {Zhang, Hongjing and Zhan, Tianyang and Basu, Sugato and
                      Davidson, Ian},
            year = {2021},
            month = mar,
            journal = {Data Mining and Knowledge Discovery},
            volume = {35},
            number = {2},
            pages = {593--620},
            issn = {1573-756X},
            doi = {10.1007/s10618-020-00734-4},
            urldate = {2023-04-24},
            abstract = {The area of constrained clustering has been extensively
                        explored by researchers and used by practitioners.
                        Constrained clustering formulations exist for popular
                        algorithms such as k-means, mixture models, and spectral
                        clustering but have several limitations. A fundamental
                        strength of deep learning is its flexibility, and here we
                        explore a deep learning framework for constrained
                        clustering and in particular explore how it can extend
                        the field of constrained clustering. We show that our
                        framework can not only handle standard together/apart
                        constraints (without the well documented negative effects
                        reported earlier) generated from labeled side information
                        but more complex constraints generated from new types of
                        side information such as continuous values and high-level
                        domain knowledge. Furthermore, we propose an efficient
                        training paradigm that is generally applicable to these
                        four types of constraints. We validate the effectiveness
                        of our approach by empirical results on both image and
                        text datasets. We also study the robustness of our
                        framework when learning with noisy constraints and show
                        how different components of our framework contribute to
                        the final performance. Our source code is available at:
                        http://github.com/blueocean92.},
            langid = {english},
            keywords = {Constrained clustering,Deep learning,Representation
                        learning, Semi-supervised learning},
            file = {/Users/matpi832/Zotero/storage/A5REE6YH/Zhang et al. - 2021
                    - A framework for deep constrained clustering.pdf},
}

@misc{zhangHowUsingMachine2021,
            title = {How {{Using Machine Learning Classification}} as a {{
                     Variable}} in {{ Regression Leads}} to {{Attenuation Bias}}
                     and {{What}} to {{Do About It}}},
            author = {Zhang, Han},
            year = {2021},
            month = may,
            publisher = {{SocArXiv}},
            doi = {10.31235/osf.io/453jk},
            urldate = {2023-03-08},
            abstract = {Social scientists have increasingly been applying
                        machine learning algorithms to "big data" to measure
                        theoretical concepts they cannot easily measure before,
                        and then been using these machine-predicted variables in
                        a regression. This article first demonstrates that
                        directly inserting binary predictions (i.e.,
                        classification) without regard for prediction error will
                        generally lead to attenuation biases of either slope
                        coefficients or marginal effect estimates. We then
                        propose several estimators to obtain consistent estimates
                        of coefficients. The estimators require the existence of
                        validation data, of which researchers have both machine
                        prediction and true values. This validation data is
                        either automatically available during training algorithms
                        or can be easily obtained. Monte Carlo simulations
                        demonstrate the effectiveness of the proposed estimators.
                        Finally, we summarize the usage pattern of machine
                        learning predictions in 18 recent publications in top
                        social science journals, apply our proposed estimators to
                        two of them, and offer some practical recommendations.},
            langid = {american},
            keywords = {Econometrics,Economics,Methodology,Models and Methods,
                        Political Science,Social and Behavioral Sciences,Social
                        Statistics,Sociology},
            file = {/Users/matpi832/Zotero/storage/IC7SKJQF/Zhang - 2021 - How
                    Using Machine Learning Classification as a Var.pdf},
}

@article{zhangImageClusteringUnsupervised2022,
            title = {Image {{Clustering}}: {{An Unsupervised Approach}} to {{
                     Categorize Visual Data}} in {{Social Science Research}}},
            shorttitle = {Image {{Clustering}}},
            author = {Zhang, Han and Peng, Yilang},
            year = {2022},
            month = apr,
            journal = {Sociological Methods \& Research},
            pages = {00491241221082603},
            publisher = {{SAGE Publications Inc}},
            issn = {0049-1241},
            doi = {10.1177/00491241221082603},
            urldate = {2023-03-01},
            abstract = {Automated image analysis has received increasing
                        attention in social scientific research, yet existing
                        scholarship has mostly covered the application of
                        supervised learning to classify images into predefined
                        categories. This study focuses on the task of
                        unsupervised image clustering, which aims to
                        automatically discover categories from unlabelled image
                        data. We first review the steps to perform image
                        clustering and then focus on one key challenge in this
                        task?finding intermediate representations of images. We
                        present several methods of extracting intermediate image
                        representations, including the bag-of-visual-words model,
                        self-supervised learning, and transfer learning (in
                        particular, feature extraction with pretrained models).
                        We compare these methods using various visual datasets,
                        including images related to protests in China from Weibo,
                        images about climate change on Instagram, and profile
                        images of the Russian Internet Research Agency on
                        Twitter. In addition, we propose a systematic way to
                        interpret and validate clustering solutions. Results show
                        that transfer learning significantly outperforms the
                        other methods. The dataset used in the pretrained model
                        critically determines what categories the algorithms can
                        discover.},
            langid = {english},
            file = {/Users/matpi832/Zotero/storage/DKMRGM2L/Zhang and Peng -
                    2022 - Image Clustering An Unsupervised Approach to Cate.pdf},
}

@inproceedings{zeiler2014visualizing,
            title = {Visualizing and understanding convolutional networks},
            author = {Zeiler, Matthew D and Fergus, Rob},
            booktitle = {Computer Vision--ECCV 2014: 13th European Conference,
                         Zurich, Switzerland, September 6-12, 2014, Proceedings,
                         Part I 13},
            pages = {818--833},
            year = {2014},
            organization = {Springer},
}

@article{rousseeuw1987silhouettes,
            title = {Silhouettes: a graphical aid to the interpretation and
                     validation of cluster analysis},
            author = {Rousseeuw, Peter J},
            journal = {Journal of computational and applied mathematics},
            volume = {20},
            pages = {53--65},
            year = {1987},
            publisher = {Elsevier},
}

@article{meilua2007comparing,
            title = {Comparing clusterings—an information based distance},
            author = {Meil{\u{a}}, Marina},
            journal = {Journal of multivariate analysis},
            volume = {98},
            number = {5},
            pages = {873--895},
            year = {2007},
            publisher = {Elsevier},
}

@article{sammon1969nonlinear,
            title = {A nonlinear mapping for data structure analysis},
            author = {Sammon, John W},
            journal = {IEEE Transactions on computers},
            volume = {100},
            number = {5},
            pages = {401--409},
            year = {1969},
            publisher = {Ieee},
}

