{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Start","text":"<p> <p></p> <p></p> <p></p>"},{"location":"#group-exercise-computer-assisted-image-clustering","title":"Group Exercise: Computer-Assisted Image Clustering","text":"<p>By: Matias Piqueras, Alexandra Segerberg, Matteo Magnani and Victoria Yantseva</p> <p></p> <p>Get started!</p> <p></p> <p></p>"},{"location":"clusterings/clusterings/","title":"Clusterings","text":"Clustering 1 Clustering 2 Clustering 3 Clustering 4 Clustering 5 Clustering 6"},{"location":"clusterings/clusterings/#actors-and-counteractors","title":"Actors and counteractors","text":"Counteractors Actors"},{"location":"extras/background/","title":"Background","text":"<p>Grouping objects such as text documents and images into categories of substantive scientific relevance is as central as it is important to social science research. Without some sort of classification, it would be difficult make advancements in our conceptualization and measurement of the social phenomena we study 12.  The availability to new kinds of data at a scale previosuly unimaginable to the social scientist warrants the need to develop new methods to make sense of it. In this context, unsupervised clustering methods provide an interesting way for scholars to learn patterns and extract knowledge from unstructured data, such as images 3. It has several benefits compared to completely supervised methods. First of all, it is much less costly, since it does not require a training set of images to be annotated with corresponding categories. Secondly, unsupervised methods are well suited for an inductive research agenda when the goal is also to discover new categories 4. </p> <p>A principal challenge with unsupervised methods such as clustering is that validation is very difficult. How can we know that the clusters are \"correct\" or meaningful for our specific substantive question, if we have no ground truth to compare them to? Clustering is inherently subjective (there is rarely a single true clustering), so it is also necessarily model dependent, since different algorithms encode and optimize notions about distance and similarity differently. How to know which algorithm will be suitable (if any) and produce valid results for our specific task is to a large extent an open question 52. While unsupervised methods applied to images in the social science is still in its infancy, this question of validity has been studied and discussed extensively in the context of text data and in particular unsupervised topic models 6789.  We can hopefully draw and learn from this literature, while keeping in mind that images are fundamentally different from text, i.e. the atomic unit of text is a word which caries meaning, while in images it is a pixel which without context provides little to no information.</p> <p>In this tab we will briefly detail how the clustering of the images was performed (see next section), as well as discuss additional validation strategies that can complement and guide the more direct type of validation we performed in the exercise by looking at image collocations (see section). In doing this, we will focus on intuition, try to skip technical details and instead provide references where relevant. We also want to stress that this is not part of the exercise\u2014this is purely intended for you to look at in case you are interested in some additional background and information.</p> <ol> <li> <p>Bailey, K. D. (1994). Typologies and Taxonomies: An Introduction to Classification Techniques. SAGE.\u00a0\u21a9</p> </li> <li> <p>Grimmer, J., &amp; King, G. (2011). General purpose computer-assisted clustering and conceptualization. Proceedings of the National Academy of Sciences, 108(7), 2643\u20132650. https://doi.org/10.1073/pnas.1018067108 \u21a9\u21a9</p> </li> <li> <p>Zhang, H., &amp; Peng, Y. (2022). Image Clustering: An Unsupervised Approach to Categorize Visual Data in Social Science Research. Sociological Methods   &amp; Research, 00491241221082603. https://doi.org/10.1177/00491241221082603 \u21a9</p> </li> <li> <p>Grimmer, J., Roberts, M. E., &amp; Stewart, B. M. (2021). Machine Learning for Social Science: An Agnostic Approach. Annual Review of Political Science, 24(1), 395\u2013419. https://doi.org/10.1146/annurev-polisci-053119-015921 \u21a9</p> </li> <li> <p>Estivill-Castro, V. (2002). Why so many clustering algorithms: A position paper. ACM SIGKDD Explorations Newsletter, 4(1), 65\u201375. https://doi.org/10.1145/568574.568575 \u21a9</p> </li> <li> <p>Roberts, M. E., Stewart, B. M., Tingley, D., Lucas, C., Leder-Luis, J., Gadarian, S. K., \u2026 Rand, D. G. (2014). Structural Topic Models for Open-Ended Survey Responses. American Journal of Political Science, 58(4), 1064\u20131082. https://doi.org/10.1111/ajps.12103 \u21a9</p> </li> <li> <p>Quinn, K. M., Monroe, B. L., Colaresi, M., Crespin, M. H., &amp; Radev, D. R. (2010). How to Analyze Political Attention with Minimal Assumptions and Costs. American Journal of Political Science, 54(1), 209\u2013228. https://doi.org/10.1111/j.1540-5907.2009.00427.x \u21a9</p> </li> <li> <p>Grimmer, J., &amp; Stewart, B. M. (n.d.). Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts. Political Analysis, 21(3), 267\u2013297. https://doi.org/10.1093/pan/mps028 \u21a9</p> </li> <li> <p>Denny, M. J., &amp; Spirling, A. (2018). Text Preprocessing For Unsupervised Learning: Why It Matters, When It Misleads, And What To Do About It. Political Analysis, 26(2), 168\u2013189. https://doi.org/10.1017/pan.2017.44 \u21a9</p> </li> </ol>"},{"location":"extras/clustering/","title":"How the clustering was done","text":"<p>This section provides a by no means complete description of how the clustering was performed for clusterings 1-5. Clustering 6 was performed by Luca.</p>"},{"location":"extras/clustering/#image-feature-extraction","title":"Image Feature Extraction","text":"<p>Automated methods for clustering on the computer work with numbers that are assumed to directly capture the similarity or distance in some relevant way, between the objects being clustered. For example, say that we want to group people based on their age into three distinct cluster. In this case, we could record their age in years and perhaps we do so for eight persons and put it in a list <code>age_list = [4, 90, 45, 76, 9, 43, 2, 87]</code>. A reasonable clustering based on this list would be <code>cluster_1 = [2, 4]</code>, <code>cluster_2 = [45, 43]</code> and <code>cluster_3 = [76, 87, 90]</code>. Note that we could have represented age differently using e.g. the date the person formatted as <code>1978 jan 21</code> but in this case we would have to tell the computer how the distance between two dates, formatted in this particular way, is calculated. Heuristically, clustering works if the absolute value you get when subtracting one of the objects being clustered from the other is small if they are  similar and large if they are different.</p>"},{"location":"extras/clustering/#image-representation-in-computers","title":"Image Representation in Computers","text":"<p>In computers images are represented as grids of pixels, in which each cell of the grid (also called matrix) corresponds to the amount of brightness of that particular pixel. The number of pixels along the rows and columns of the grid corresponds to the resolution and aspect ratio. For example your laptop might be able to display 1920 (width)\u2009\u00d7\u20091080 (height) = 2,073,600 pixels.</p> <p>If the image is gray-scale, then the convention is that the value 0 is completely black, 255 is completely white and everything in between are different shades of gray. For example the number 8 can be represented in a 16 \u00d7\u200924 grid as seen in the image below 1.</p> <p></p> A grayscale image of the number 8 <p>For color images we follow the same principle but instead stack three grids for the primary colors Red, Green. and Blue (RGB) as shown in the image below 1.</p> <p></p> A color image of a dog <p>Given that images are represented in this way as numbers, we might think that we can cluster this representation directly. As we will see this is unfortunately rarely a good idea if we want to compute some form of similarity or distance between the images, since it assumes that individual pixel locations in represent relevant and comparable aspects of the image. This makes comparisons highly sensitive to things like rotation, scale, resolution, aspect ratio, exact position and that the things we are interested in always look the same across images. Let us look at two examples from the <code>PolarVis</code> data. As humans we can clearly and immediately see that this picture of Obama at COP21</p> <p></p> Obama at COP21 <p>is the same as the one below. The only difference being that the second picture has been flipped.</p> <p></p> Flipped Obama at COP21 <p>Remembering our heuristic for when we are able to cluster, we can try subtracting the second image of Obama from the first one. Provided that these two are essentially the same image (in any relevant sense) we would hope the resulting image to be completely black, since the pixel values should be 0. In other words, we want the representation to be invariant to rotations of the same image. As we see in the image below\u2014this is certainly not the case.</p> <p></p> Obama-flipped Obama at COP21 <p>We can look at a second example from the <code>PolarVis</code> data. This time we take two completely different images but that are substantively similar. </p> <p></p> Map 1 <p>Both images show a map of the world and seem to highlight something about the emissions of each country.</p> <p></p> Map 2 <p>Subtracting one from the other again leads to nonsensical results and if taken at face value\u2014that the images are very different from one another when most people would probably say that they are closely related.</p> <p></p> Map 1 - Map 2 <p>One way to solve the issue presented here is to instead compare relevant features of the images that are invariant to all of the challenges we saw in the examples above. Many methods exist for the task of finding relevant features, also called feature extraction. In principle, this is what we did when encoding age as a numeric value corresponding to the number of years of the person, and it is not dissimilar to what we would do when designing a coding scheme. To see that comparing the features of images at least in principles makes it possible to cluster images we could define the binary feature, <code>map</code> that takes the value 1 if the image has a map and 0 otherwise, and we can also define <code>emission</code> which again takes the value 1 if the image is somehow related to global emissions and 0 otherwise. We can now calculate the distance between the images and see that they are indeed very similar according to our definition of relevant features.</p> <p>$$ dist(img_1, img_2) = map_{img1} - map_{img2} + emission_{img1} - emission_{img2} = |1-1| + |1-1| = 0 $$</p>"},{"location":"extras/clustering/#automatic-feature-extraction","title":"Automatic Feature Extraction","text":"<p>In the previous example, we defined the relevant features as two binary variables <code>map</code> and <code>emission</code> manually. Doing this for all relevant features, in a large dataset is often times unfeasible and defeats the purpose of automated clustering. For this reason, the features for clustering in this workshop were extracted automatically. The dominant approach (also used here) to this in modern image analysis is using Deep Learning. The key innovation is that a deep learning model is able to learn which features are relevant, not by us imposing assumptions about what they should be, but rather through us defining a task, by which the model must learn what features are important in order to perform well. The task could for example be for the model to predict whether an image is about a protest or not. The reason why deep learning models are sometimes referred to as black boxes is that these features are not always directly interpretable or meaningful for us humans. As such, it can be difficult understanding why a model has produced a particular result\u2014emphasising the need to rigorously validate any result in part produced by a deep learning model. The field of Explainable AI tries to open up the black box in order to better understand the inner workings of the model. In early work by 1, they introduce a method for analyzing how the different layers in a neural network are \"activated\", which can give us some insights into what kind of features are being learned. An example from the paper is shown in the figure below which shows how the second layer (left panel) picks up the patterns of the input images (right panel).</p> <p></p> <p>For a more comprehensive introduction to deep learning for image analysis from a social science perspective you can read the paper by Torres and Cant\u00fa 2.</p>"},{"location":"extras/clustering/#transfer-learning","title":"Transfer Learning","text":"<p>In this workshop we used a so called pretrained version of a deep learning model named CLIP to extract a feature representation of the 150 COP21 images 3. Transfer learning means that we can repurpose a model trained for a particular purpose on a new or similar task. This is very practical since Deep learning is very expensive in the sense that it generally needs a lot of data and compute power to perform well AKA learning good and relevant features. This particular version has been pretrained on dataset called LAION-5B which contains 5,85 billion image-text pairs. The share amount of images </p>"},{"location":"extras/clustering/#k-means-clustering","title":"K-Means Clustering","text":"<p>K-Means Clustering is one of the simplest and also one of the most popular clustering algorithms. After extracting the feature vector as described above, this is what has been used to actually generate the clusters 1-5. The steps of the algorithm are:</p> <p>K-Means algorithm</p> <ol> <li>Randomly select a chosen number of images from the dataset to be    \"cluster centers\" (also called centroids). The number of cluster centers    is specified a priori by the researcher.</li> <li>Calculate the Euclidean    distance between the    centers and all other images. Assign each image to the cluster for which    the distance to the center is the smallest.</li> <li>Calculate a new centers for each cluster by taking the means value of    all its images.</li> <li>Repeat steps 2 and 3 until images have stopped being reassigned, i.e.    the clusters have stabilized.</li> </ol> <p>One important </p> <ol> <li> <p>Zeiler, M. D., &amp; Fergus, R. (2014). Visualizing and understanding convolutional networks. Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part i 13, 818\u2013833. Springer.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Torres, M., &amp; Cant\u00fa, F. (2022). Learning to See: Convolutional Neural Networks for the Analysis of Social Science Data. Political Analysis, 30(1), 113\u2013131. https://doi.org/10.1017/pan.2021.9 \u21a9</p> </li> <li> <p>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., \u2026 Sutskever, I. (2021). Learning Transferable Visual Models From Natural Language Supervision. arXiv. https://doi.org/10.48550/arXiv.2103.00020 \u21a9</p> </li> </ol>"},{"location":"extras/validation_strategies/","title":"Additional validation strategies","text":"<p>In this exercise, we clustered a limited number of images. This made it perfectly feasible to visually inspect each image and cluster, but how should we do when the size of dataset makes this impossible? This section suggests three strategies for quantitatively evaluating the quality of a clustering, as well as comparing several clusterings to each other. These methods can also be informative in terms of understanding which images we should sample and focus our attention to during validation. I want to stress that these are by no means the only ways in which we can understand clustering results quantitatively and that this kind of analysis is likely never going to replace the need of human validation and qualitative interpretation.</p>"},{"location":"extras/validation_strategies/#understanding-the-distribution-of-clusters","title":"Understanding the distribution of clusters","text":"<p>As a first step, we may want look at the cluster distribution. This provides a simple view of the number of images that have been assigned to each of the clusters as shown in the figure below. The x-axis shows the cluster id and y-axis the number of images assigned to the cluster. This can help us understand if for example some clusters are very small or large and potentially should be split or merged.</p> <p>"},{"location":"extras/validation_strategies/#analyzing-the-distinctiveness-of-clusters","title":"Analyzing the distinctiveness of clusters","text":"<p>A commonly used method for analyzing and interpreting how distinct the clusters are, is visualizing a Silhouette plot 1 as shown in the left panels in the figure below. Here, each image is given a value ranging from -1 to 1 where a higher value should be understood as the favorable assigned by which the image is similar to its neighbors in the same cluster as well as distinct from other clusters. A very low value instead indicates that the image lays in the middle of two or more clusters. Based on this knowledge we might for example choose to inspect images from neighboring clusters with low scores, as this could be indicative if them being similar.</p> <p>Silhouette plots should nonetheless be interpreted with caution. In particular, it will tend to favor clustering methods that use the same distance metric as the one used to calculate the Silhouette scores. This might lead one to incorrectly consider one clustering method superior to the other. For example, in this exercise clustering methods 1-5 use the same distance metric (Euclidean distance) as was used to calculate the silhouettes, whereas clustering method 6 does not. Just looking at the Silhouette for clustering 6, it seems to perform very badly, but this does not have mean that the clustering is bad. It still be that the way the distance is measured in clustering 6 yields a better and more insightful partition of the images.</p> <p> </p>"},{"location":"extras/validation_strategies/#comparing-the-similarity-of-different-clusterings","title":"Comparing the similarity of different clusterings","text":"<p>A method for comparing different clusterings by visualizing their relative similarity was proposed in 2. It consists of two main steps. First the distance between two clusterings is computed using the variation of information (VI) metric 3. Intuitively, VI is a measure of the number of pair-wise disagreements between two clusterings. A low score means that for most pairs, the two clustering methods being compared agree on that the two images should either be in same cluster or not. VI has some desirable properties for such as the number of clusters may be different between the clusterings being compared.</p> <p>Once the similarity between each clustering has been calculated using VI, 2 suggest using a dimensionality reduction technique called Sammon mapping to visualize the clusterings 4. Dimensionality reduction means that we attempt to reduce a high-dimensional space down to a lower dimensional space that best describes the variation in the data. In this specific case, the original space is equivalent to the number of clustering methods being compared (6) which we reduce to two dimensions so that we can easily visualize the results as shown in the figure below. It is rarely very informative to look at the exact value of the x and y-axis, instead, we should probably focus on the relative position of the clusterings. Just as with clustering there exists a plethora of dimensionality reduction methods. In 2, argue that Sammon mapping is suitable for this purpose since it is good at preserving small distances between the clusterings, i.e. showing us which methods yield similar results. However, this also implies that we should be careful about interpreting distant clusterings as necessarily very different.</p> <p></p> <ol> <li> <p>Rousseeuw, P. J. (1987). Silhouettes: A graphical aid to the interpretation and validation of cluster analysis. Journal of Computational and Applied Mathematics, 20, 53\u201365.\u00a0\u21a9</p> </li> <li> <p>Grimmer, J., &amp; King, G. (2011). General purpose computer-assisted clustering and conceptualization. Proceedings of the National Academy of Sciences, 108(7), 2643\u20132650. https://doi.org/10.1073/pnas.1018067108 \u21a9\u21a9\u21a9</p> </li> <li> <p>Meil\u0103, M. (2007). Comparing clusterings\u2014an information based distance. Journal of Multivariate Analysis, 98(5), 873\u2013895.\u00a0\u21a9</p> </li> <li> <p>Sammon, J. W. (1969). A nonlinear mapping for data structure analysis. IEEE Transactions on Computers, 100(5), 401\u2013409.\u00a0\u21a9</p> </li> </ol>"},{"location":"instructions/instructions/","title":"Instructions","text":"<p>When analysing the content and usage of images in online political communication, a natural first step (and potential end goal) is to group similar images together, such that the groups operationalize some themes or categories of relevance to the present study. This task is difficult for many reasons, one of them being that if done manually by the researcher, it may be very time consuming or even infeasible for large datasets. In this context, an automated and computational method called clustering might be interesting\u2014not only as a way to assign images to categories, but also as a tool for inductively exploring what categories may exist in the data. In general, the objective of clustering methods is to create a partition of the data into groups that are internally coherent and distinct from each other. Exactly how this is achieved, differs between methods in e.g. by how the distance or similarity between the objects being clustered is measured. An important task, independent of what clustering method is used, is to assess the validity of the results. </p> <p>The task</p> <p>In this exercise, we have prepared six different and fully automated clusterings of 150 images from the COP21 conference, collected as part of the PolarVis project. The images were taken from tweets by Swedish accounts containing the hashtag <code>#COP21</code>. An account was defined as Swedish if it had at least one <code>#COP21</code> Tweet, where Twitter had classified the language as Swedish. A clustering is the resulting assignment of images into clusters produced by one particular clustering method and set of hyperparameters 1. </p> <p>The goal of this exercise is for you to explore the different clusterings, evaluate their quality and discuss the potential usefullness of these methods for discovery and measurement in your research. This will be done by inpsecting the images and how they are placed in different clusters here.</p> <p>Practicalities</p> <p>Timetable</p> Content Time Intro to exercise 10.15-10:25 Work on exercise in groups 10.25-11:10 Discussion in plenum 11:10-11:30 <p>Groups</p> <ul> <li>Group 1: VY, F\u00c5, LR, NR, SM</li> <li>Group 2: MM, EK, LA, ND, AW</li> <li>Group 3: AS, KU, ML, PT</li> </ul> <p>Important Links</p> <ul> <li>Questionarie for Q1 (individual exercise): https://doit.medfarm.uu.se/bin/kurt3/kurt/92173</li> <li>Padlet for Q2 and Q3 (group exercise).<ul> <li>Group 1: https://padlet.com/matiaspiqueras/group-1-vyhfrjhk6hwbhq0k</li> <li>Group 2: https://padlet.com/matiaspiqueras/group-2-5tlbez5cs85e8s1d</li> <li>Group 3: https://padlet.com/matiaspiqueras/group-3-grvnjywdpvhd2dkh</li> </ul> </li> <li>Collective padlet for plenum discussion: https://padlet.com/vyantseva/padlet-ihyaitbw25m3yr0a</li> </ul> <p>Questions</p> <p>Below you will find a set of questions that we ask you to answer either individually (Q1) or in your groups (Q2 and Q3). Note that Q1 is also included in questionaire and Q2 and Q3 are in the group padlets (see important links).</p> <ol> <li> <p>Based on your experience and understanding of the COP21 dataset:</p> <ol> <li>What are the different themes that you expect to see in the images?</li> <li>Do you expect some themes to be more or less prominent than    others? Which ones and why?</li> </ol> </li> <li> <p>Out of the six clusterings, select the one that you as a group think    is best and answer the following questions:</p> <ol> <li>Why did you select this particular clustering? What implicit or    explicit criteria did you use to make your decision?</li> <li>Try to interpret each cluster from the selected clustering and    if possible try to provide a label for each cluster. What    concepts do they operationalize? Are they scientifically    relevant?</li> </ol> </li> <li> <p>Cluster quality can be improved by bringing the researcher into the    loop and providing input to the clustering methods. This can nudge    the algorithms to better consider your particular research    objective, prior knowledge and domain expertise. </p> <ol> <li>For the selected clustering, what would you change (if    anything)? You could think in terms of individual images that    are misplaced or more broadly e.g. that some theme important    to you is missing.</li> <li>In general, what kind of human input do you think would be    valuable to be able to provide?</li> </ol> </li> </ol> <ol> <li> <p>A hyperparameter is a value that is set prior to fitting the clustering method to the data and that controls or affects some aspect of learning from the data. In the context of clustering, the most important hyperparameter is typically the number of clusters (groups).\u00a0\u21a9</p> </li> </ol>"}]}